<!DOCTYPE html>
<html lang="en-us">
    <head><meta charset='utf-8'>
<meta name='viewport' content='width=device-width, initial-scale=1'><meta name='description' content='Redis数据结构、架构、常见常见、持久化、主从架构'><title>Redis</title>

<link rel='canonical' href='http://nixum.cc/p/redis/'>

<link rel="stylesheet" href="/scss/style.min.92530ae6146419b2553c7da1866a1ac352d4c1a4d2f985110524bd60c6094d8c.css"><meta property='og:title' content='Redis'>
<meta property='og:description' content='Redis数据结构、架构、常见常见、持久化、主从架构'>
<meta property='og:url' content='http://nixum.cc/p/redis/'>
<meta property='og:site_name' content='Nixum Blog'>
<meta property='og:type' content='article'><meta property='article:section' content='Post' /><meta property='article:tag' content='Redis' /><meta property='article:tag' content='主从架构' /><meta property='article:tag' content='缓存' /><meta property='article:published_time' content='2020-08-09T00:00:00&#43;00:00'/><meta property='article:modified_time' content='2020-08-09T00:00:00&#43;00:00'/>
<meta name="twitter:title" content="Redis">
<meta name="twitter:description" content="Redis数据结构、架构、常见常见、持久化、主从架构">
    <link rel="shortcut icon" href="/img/favicon.ico" />

<script async src="https://www.googletagmanager.com/gtag/js?id=G-2D1N64V8VB"></script>
<script>
var doNotTrack = false;
if (!doNotTrack) {
	window.dataLayer = window.dataLayer || [];
	function gtag(){dataLayer.push(arguments);}
	gtag('js', new Date());
	gtag('config', 'G-2D1N64V8VB', { 'anonymize_ip': false });
}
</script>

    </head>
    <body class="
    article-page has-toc
">
    <script>
        (function() {
            const colorSchemeKey = 'StackColorScheme';
            if(!localStorage.getItem(colorSchemeKey)){
                localStorage.setItem(colorSchemeKey, "auto");
            }
        })();
    </script><script>
    (function() {
        const colorSchemeKey = 'StackColorScheme';
        const colorSchemeItem = localStorage.getItem(colorSchemeKey);
        const supportDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches === true;

        if (colorSchemeItem == 'dark' || colorSchemeItem === 'auto' && supportDarkMode) {
            

            document.documentElement.dataset.scheme = 'dark';
        } else {
            document.documentElement.dataset.scheme = 'light';
        }
    })();
</script>
<div class="container main-container flex 
    
        extended
    
">
    
        <div id="article-toolbar">
            <a href="/" class="back-home">
                <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-chevron-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <polyline points="15 6 9 12 15 18" />
</svg>



                <span>Back</span>
            </a>









        </div>
    
<main class="main full-width">
    <article class="main-article">
    <header class="article-header">

    <div class="article-details">
    
    <header class="article-category">
        
            <a href="/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/" >
                数据库
            </a>
        
    </header>
    

    <h2 class="article-title">
        <a href="/p/redis/">Redis</a>
    </h2>

    
    <h3 class="article-subtitle">
        Redis数据结构、架构、常见常见、持久化、主从架构
    </h3>
    

    
    <footer class="article-time">
        
            <div>
                <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <path d="M11.795 21h-6.795a2 2 0 0 1 -2 -2v-12a2 2 0 0 1 2 -2h12a2 2 0 0 1 2 2v4" />
  <circle cx="18" cy="18" r="4" />
  <path d="M15 3v4" />
  <path d="M7 3v4" />
  <path d="M3 11h16" />
  <path d="M18 16.496v1.504l1 1" />
</svg>
                <time class="article-time--published">Aug 09, 2020</time>
            </div>
        

        
            <div>
                <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="12" cy="12" r="9" />
  <polyline points="12 7 12 12 15 15" />
</svg>



                <time class="article-time--reading">
                    5 minute read
                </time>
            </div>
        
    </footer>
    
</div>
</header>

    <section class="article-content">
    <p>[TOC]</p>
<h1 id="数据类型及结构">数据类型及结构</h1>
<p>Redis里存的key和value都是二进制数据，即 byte数组，本身是二进制安全的（二进制安全的意思是，存进去怎么样，取出来就是怎么样，程序不会对原始数据进行任意的操作）</p>
<h2 id="数据类型">数据类型</h2>
<p>具体的分为5种基本类型和3种特殊类型：</p>
<p>String、List(一般当成队列，尽量少使用随机读写)、Hash、Set、ZSet</p>
<ul>
<li>
<p><strong>String</strong>：简单动态字符串(SDS)</p>
<p>场景：缓存（可以使用json、protobuf等进行序列化反序列化、也可以通过key来分离缓存对象的属性，实现hash的效果，只是是单字段罢了）、token、限流、分布式id</p>
</li>
<li>
<p><strong>List</strong>：压缩列表（元素数量小于512，且所有元素的长度都小于64字节） + 双向链表，高版本是快表（其他情况使用）</p>
<p>场景：用户消息时间线、消息队列</p>
</li>
<li>
<p><strong>Hash</strong>：压缩列表（元素数量小于512，且key和value字符串长度都小于64字节） + 哈希表（其他情况使用）</p>
<p>场景：存储对象缓存（可以更方便get、set对应字段）、根据key进行统计</p>
</li>
<li>
<p><strong>Set</strong>：数组（带有编码类型字段，所以元素可以使用整型表示，少于512个时使用）+ 哈希表（key为set中的元素，value为null，其他情况使用）</p>
<p>场景：交集、并集、点赞、签到、随机弹出获取元素</p>
</li>
<li>
<p><strong>ZSet</strong>：压缩列表（元素小于128个，且所有元素的长度小于64字节时使用） + 跳表 （其他情况使用）</p>
<p>场景：排行榜</p>
</li>
</ul>
<p>另外三种扩展类型：</p>
<ul>
<li>
<p><strong>Bitmap</strong>：位存储，基于String，原理：String类型会保存二进制字节数组，只有0和1两个值，对于这个字节数组的每个bit来表示一个元素的二值状态；</p>
<p>场景：二值统计，如签到统计、记录每个月签到情况、判断用户登录状态</p>
</li>
<li>
<p><strong>HyperLogLog</strong>：基数统计，类似set，不断往里add值，然后判断有总数量；主要作用是使用少量固定的内存（12KB内存即可统计2^64个不同元素）去存储并识别有大量元素的集合中的唯一元素，能快速算出集合内的元素个数，误差率0.81%；版本2.8.9之后才有</p>
<p>场景：百万级别网络的UV计数</p>
</li>
<li>
<p><strong>Geo</strong>：推算地理位置，比如两地之间的距离，方圆几里的人；版本3.2之后才有</p>
</li>
<li>
<p><strong>Stream</strong>：5.0之后的版本才有，Stream会在第一次使用 <code>xadd</code> 指令追加消息时自动创建。</p>
<ul>
<li><code>Consumer Group</code>：消费组，一个消费组有多个消费者，这些消费者是竞争关系；</li>
<li><code>Last_delivered_id</code>：游标，每个消费组的游标，组内任意一个消费者读取了消息都会使游标向前移动；</li>
<li><code>pending_ids</code>：消费者的状态变量，用于维护消费者未确认的id，记录当前已经被客户端读取但还没有被ACK的消息。如果客户端没有ACK，这个变量里面的消息ID会越来越多，一旦某个消息被ACK，它就开始减少，用来确保客户端至少消费了消息一次，而不会在网络传输的中途丢失了没处理。</li>
<li>消息ID：组成方式<code>毫秒级时间戳 - 序号</code>，消息ID也可以自定义，但必须是整数-整数，且能后面加入的消息ID要大于前面的消息ID。Redis本身会记录 <code>lastest_generated_id</code>，防止时间回拨导致ID问题；</li>
<li>消息内容：键值对，类似Hash的结构；</li>
</ul>
</li>
</ul>
<p><figure 
	>
	<a href="https://github.com/Nixum/Java-Note/raw/master/picture/Redis_Stream.png" >
		<img src="https://github.com/Nixum/Java-Note/raw/master/picture/Redis_Stream.png"
			
			
			
			loading="lazy"
			>
	</a>
	
</figure></p>
<h2 id="底层数据结构">底层数据结构</h2>
<p>Redis所有类型有一个顶层的数据结构叫RedisObject，这个RedisObject底层对应着具体对象类型和其编码方式。</p>
<p>之所以有RedisObject对象，是因为每种不同的数据类型有不同的编码方式和结构，Redis必须让每个键都带有类型信息，使得程序可以检查键的类型，还需要根据数据类型的不同编码进行<strong>多态</strong>处理。</p>
<p>比如：SADD命令只能用于Set，LPUSH命令只能用于List，而DEL、TTL又能用于所有键，要正确实现这些命令，就需要为不同类型的键设置不同的处理方式；另外，同一种数据类型可能由不同的数据结构实现，比如List，底层可能是压缩列表或者双向链表，因此还需要知道数据类型的编码方式。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c" data-lang="c"><span class="k">typedef</span> <span class="k">struct</span> <span class="n">redisObject</span> <span class="p">{</span>
    <span class="c1">// 类型，如String、List
</span><span class="c1"></span>    <span class="kt">unsigned</span> <span class="nl">type</span><span class="p">:</span><span class="mi">4</span><span class="p">;</span>
    <span class="c1">// 编码方式：如SDS、压缩列表、跳表等
</span><span class="c1"></span>    <span class="kt">unsigned</span> <span class="nl">encoding</span><span class="p">:</span><span class="mi">4</span><span class="p">;</span>
    <span class="c1">// LRU - 24位, 记录最后一次访问时间（相对于lru_clock）; 或者 LFU（最少使用的数据：8位频率，16位访问时间）
</span><span class="c1"></span>    <span class="kt">unsigned</span> <span class="nl">lru</span><span class="p">:</span><span class="n">LRU_BITS</span><span class="p">;</span> <span class="c1">// LRU_BITS: 24
</span><span class="c1"></span>    <span class="c1">// 引用计数，新创建对象时值为1，当对该对象进行共享时值+1，使用完一个对象后值-1，=0时被GC回收
</span><span class="c1"></span>    <span class="kt">int</span> <span class="n">refcount</span><span class="p">;</span>
    <span class="c1">// 指向底层数据结构实例，具体的实例，由type和encoding决定
</span><span class="c1"></span>    <span class="kt">void</span> <span class="o">*</span><span class="n">ptr</span><span class="p">;</span>

<span class="p">}</span> <span class="n">robj</span><span class="p">;</span>
</code></pre></td></tr></table>
</div>
</div><blockquote>
<p><strong>当执行一个处理数据类型命令的时候，redis执行以下步骤</strong></p>
<ol>
<li>根据给定的key，在数据库字典中查找和他相对应的redisObject，如果没找到，就返回NULL；</li>
<li>检查redisObject的type属性和执行命令所需的类型是否相符，如果不相符，返回类型错误；</li>
<li>根据redisObject的encoding属性所指定的编码，选择合适的操作函数来处理底层的数据结构；</li>
<li>返回数据结构的操作结果作为命令的返回值</li>
</ol>
</blockquote>
<p>Redis本身还会预分配一些值对象，比如响应结果OK、ERROR，还有包括0在内，所有小于REDIS_SHARED_INTEGERS（默认值是10k，<code>[0 - 9999]</code>）的所有整数，共享对象只能被字典或双向链表这类带有指针的数据结果使用。</p>
<p><figure 
	>
	<a href="https://github.com/Nixum/Java-Note/raw/master/picture/RedisObject.png" >
		<img src="https://github.com/Nixum/Java-Note/raw/master/picture/RedisObject.png"
			
			
			
			loading="lazy"
			>
	</a>
	
</figure></p>
<h3 id="简单动态字符串---sds">简单动态字符串 - SDS</h3>
<p>Redis的String类型底层有两种保存形式，当保存的是64位有符号整数时，String类型会保存为一个9字节的Long类型整数；当保存的数据包含字符时，String类型就会用简单动态字符串SDS。</p>
<p>简单动态字符串SDS由三个部分组成：</p>
<ul>
<li><code>buf</code>：是字节数组，保存实际数据，结束标志位是&quot;/0&quot;；</li>
<li><code>len</code>：表示buf已用长度，占4字节；SDS不使用 &ldquo;/0&rdquo; 来判断字符串是否结束，而是通过 <code>len</code> 来判断；<code>len</code> 同时也能防止缓冲区溢出；</li>
<li><code>alloc</code>：表示buf的实际分配长度，一般大于len；</li>
</ul>
<p><code>len</code>和<code>alloc</code>两个属性，对于修改字符串SDS实现了空间预分配和惰性空间释放两种策略：</p>
<ul>
<li>
<p>空间预分配：当字符串进行扩展时，扩展的内存会比实际需要的多，减少连续字符串增长带来的内存频繁分配。</p>
<p>当字符串长度小于 1M 时，扩容时双倍扩容，如果超过 1M，扩容一次只会多扩 1M 的空间，默认的最大长度是 512M，可通过配置文件修改。</p>
<p>执行Append命令的字符串会带有预分配的空间，这些预分配的空间不会被释放，除非对应的key被删除，或者重启后重新载入，才会删除预分配的空间，如果有存在大量预分配的字符串，可以修改配置使其定时释放预分配的空间，更有效的使用内存。</p>
</li>
<li>
<p>惰性空间释放：当字符串进行缩短时，不会使用内存重新分配的方式来回收多余字节，而只是用<code>alloc</code> 记录这些字节的数量，等待后续使用。</p>
</li>
</ul>
<p>RedisObject包含了8个字节的元数据和一个8字节指针，指针指向具体的数据类型的实际数据所在，</p>
<p>对于String类型的RedisObject：</p>
<ul>
<li>当保存的是Long类型整数时，RedisObject中的指针直接就是整数数据，不用额外的指针指向整数；</li>
<li>当保存的是字符串时，如果字符串&lt;=44字节，RedisObject中元数据，指针和SDS是一块连续的内存区域，避免内存碎片；</li>
<li>当保存的是字符串时，如果字符串&gt;44字节，RedisObject会给SDS分配独立的空间，并用指针指向SDS；</li>
</ul>
<p><figure 
	>
	<a href="https://github.com/Nixum/Java-Note/raw/master/picture/Redis_String_RedisObject.png" >
		<img src="https://github.com/Nixum/Java-Note/raw/master/picture/Redis_String_RedisObject.png"
			
			
			
			loading="lazy"
			alt="Redis String RedisObject">
	</a>
	
	<figcaption>Redis String RedisObject</figcaption>
	
</figure></p>
<p>当使用String类型时，且value的类型是String时，如果value的长度太小，可能会出现元数据的大小比数据本身的大小还大，造成额外的内存开销，如果能替换成Long类型，实际存储的大小会大大降低。</p>
<h3 id="哈希表---dict">哈希表 - Dict</h3>
<p><figure 
	>
	<a href="https://github.com/Nixum/Java-Note/raw/master/picture/Redis_%e5%85%a8%e5%b1%80%e5%93%88%e5%b8%8c%e8%a1%a8.png" >
		<img src="https://github.com/Nixum/Java-Note/raw/master/picture/Redis_%e5%85%a8%e5%b1%80%e5%93%88%e5%b8%8c%e8%a1%a8.png"
			
			
			
			loading="lazy"
			alt="Redis Dict">
	</a>
	
	<figcaption>Redis Dict</figcaption>
	
</figure></p>
<p>无论值是什么类型的，所有的键值对会保存在<strong>全局哈希表</strong>中，便于快速找到对应的Key，哈希桶只会保存键值对的指针。全局哈希表中的桶每个元素entry由三个8字节指针组成，分别为key、value、next，但实际会占32字节，因为内存分配库jemalloc会分配最接近24的2的幂次数，所以是32，以减少频繁的分配次数。</p>
<p>因此，即使Redis里存在大量数据，也不影响查找的速度，毕竟都是根据Key进行hash就能找到对应的Value，真正有影响的是哈希表的在解决哈希冲突和rehash时带来的阻塞。</p>
<p><strong>Redis的哈希表使用拉链法解决哈希冲突，并通过两个全局哈希表加快rehash的操作。</strong></p>
<p><figure 
	>
	<a href="https://github.com/Nixum/Java-Note/raw/master/picture/Redis_Dict.png" >
		<img src="https://github.com/Nixum/Java-Note/raw/master/picture/Redis_Dict.png"
			
			
			
			loading="lazy"
			alt="Redis Dict">
	</a>
	
	<figcaption>Redis Dict</figcaption>
	
</figure></p>
<p>处理全局哈希表有这种操作，Hash的数据结构也是这样的操作，本质是一样的。</p>
<h4 id="rehash触发条件">rehash触发条件</h4>
<p>当Redis生成RDB和AOF重写时，哈希表不会进行rehash。</p>
<p>装载因子：哈希表中所有entry的个数 除以 哈希表的哈希桶个数。</p>
<ul>
<li>
<p>当装载因子&gt;= 1，且哈希表被允许rehash，即此时没有进行RDB和AOF重写，即没有执行或正在执行 <code>BGSAVE</code> 命令或者 <code>BGREWRITEAOF</code> 命令</p>
</li>
<li>
<p>当装载因子&gt;= 5，因为此时数据量已远远大于哈希桶的个数了，此时会立马进行rehash，不管是否有没有在执行RDB快照或AOF重写，都会强制进行rehash操作；</p>
</li>
</ul>
<h4 id="rehash过程">rehash过程</h4>
<ol>
<li>
<p>默认使用哈希表1，此时哈希表2还没有被分配空间</p>
</li>
<li>
<p>当数据增多至需要rehash时，为哈希表2分配空间，大小会比哈希表1大，比如<strong>大两倍</strong></p>
</li>
<li>
<p>把哈希表1中的数据重新映射并拷贝到哈希表2中</p>
<p><strong>渐进式rehash</strong>：解决大量数据在哈希表1和2之间拷贝，会导致Redis线程阻塞的问题（因为单线程)。</p>
<p>3.1 拷贝数据时，Redis仍然正常处理客户端请求，每处理一个请求时，从哈希表1中的第一个索引位置开始，顺便将该索引位置上的所有entries拷贝到哈希表2中；</p>
<p>3.2 等待处理下一个请求时，再顺带拷贝哈希表1中该索引下一个索引位置的entries到哈希表2中；</p>
<p>通过这两种方式，将一次性的大量拷贝分散到每次请求和等待间隙中。</p>
<p>3.3 此外Redis本身也有一个<strong>定时任务</strong>在执行rehash，发生在空闲时间</p>
</li>
<li>
<p>释放哈希表1的空间，此时哈希表1的空间被回收，原来的哈希表2变成哈希表1，哈希表1变成哈希表2</p>
</li>
</ol>
<p>渐进式rehash过程中，如果有新的键值对存进来，Redis会把该键值对放到哈希表2中，确保哈希表1里的键值对只会减少；如果是有查询进来，则会先查询哈希表1，再查询哈希表2。</p>
<h4 id="底层的两种实现">底层的两种实现</h4>
<p>对于Hash数据类型，底层有压缩列表和哈希表两种实现，当底层使用压缩列表时，存储的时候是以key、value的顺序存储的，新增的键值对保存在表尾；使用压缩列表时，底层是无法利用index查找，只能遍历查找。</p>
<p>当Hash 集合中写入的元素个数超过了 <code>hash-max-ziplist-entries</code>，或者写入的单个元素大小超过了 <code>hash-max-ziplist-value</code>，Redis 就会自动把 Hash 类型的实现结构由压缩列表转为哈希表，且之后不可逆。</p>
<h3 id="压缩列表---ziplist">压缩列表 - ZipList</h3>
<p><figure 
	>
	<a href="https://github.com/Nixum/Java-Note/raw/master/picture/redis_%e5%8e%8b%e7%bc%a9%e5%88%97%e8%a1%a8.png" >
		<img src="https://github.com/Nixum/Java-Note/raw/master/picture/redis_%e5%8e%8b%e7%bc%a9%e5%88%97%e8%a1%a8.png"
			
			
			
			loading="lazy"
			alt="Redis Ziplist">
	</a>
	
	<figcaption>Redis Ziplist</figcaption>
	
</figure></p>
<p>本质上是一个数组，数组中每一个元素保存一个数据。压缩列表的结构：</p>
<ul>
<li>
<p>表头有三个字段：</p>
<ul>
<li><code>zlbytes</code>记录整个压缩列表占用的内存字节数，可算出列表长度；</li>
<li><code>zltail</code>记录列表最后一个<code>entry</code>的偏移量，可算出尾节点到列表起始地址的字节数，快速完成pop操作；</li>
<li><code>zllen</code>记录列表中的<code>entry</code>个数，只占用2bytes，如果压缩列表中<code>entry</code>的数目小于 65535 ，2的16次方，该字段存储的就是实际的<code>entry</code>数，如果超过或等于该值，则实际数量要遍历<code>entry</code>才能得到；</li>
</ul>
</li>
<li>
<p>每个节点元素<code>entry</code>有四个字段：<code>previous_entry_length</code>记录前一个节点的长度；<code>encoding</code>记录<code>content</code>的数据类型和长度；<code>content</code>保存元素的值；<code>len</code>表示自身长度。</p>
</li>
<li>
<p>表尾有一字段：<code>zlend</code>终止字符，用于标记列表末端。</p>
</li>
</ul>
<p>数据类型List、Hash、ZSet都有使用到压缩列表。</p>
<p>压缩列表可以存储字符串或整数，存储整数时采用整数的二进制而不是字符串形式存储，能在O(1)时间复杂度下完成 list 两端的 push 和 pop 操作，由于每次操作都需要重新分配压缩列表的内存，so实际复杂度跟其内存使用量有关。</p>
<p>压缩列表的优势在于存储结构，普通数组要求数组的每个元素的大小相同，但是当我们需要在每个元素中存储大小不同的字符串时，就会浪费存储空间，压缩列表就是会把每个元素多余的空间进行压缩，让每个元素紧密相连，再为每个元素增加一个长度，用于计算下一个元素在内存中的位置。</p>
<p>另外，在内存的地址查找时，在查找第一个和最后一个的时候有优势，可以利用表头的三个字段查到，是O(1)，但是因为存储紧凑的缘故，查找其他元素只能遍历，是O(n)。</p>
<p>压缩列表或者数组主要因为其数据结构紧凑，节省空间，避免内存碎片，提升内存利用率，线性顺序存储，对CPU高速缓存支持友好。对于查找的时间复杂度的优势提升不大。但是，由于压缩列表比较紧凑，在新增更新删除操作时可能会引发连锁更新，此时最坏为O(n^2)，但触发概率相对较低，利大于弊。</p>
<h3 id="快表---quick-list">快表 - Quick List</h3>
<p>3.2版本后才添加，之前的版本是双向链表，本质上是一个链表，只是每个节点都是一个压缩列表。</p>
<p>快表为了解决压缩列表增删元素时的连锁反应导致的性能下降，会控制每个链表节点中的压缩列表的大小或元素个数，来避免这个问题，因为压缩列表越小或元素个数越少，新增或删除时带来的影响就越小。</p>
<h3 id="跳表---skip-list">跳表 - Skip List</h3>
<p>Redis只有ZSet对象底层使用跳表，ZSet结构体里有两个数据结构，一个是跳表，一个是哈希表，哈希表只在用在获取权重，大部分操作还是通过跳表实现；</p>
<p><figure 
	>
	<a href="https://github.com/Nixum/Java-Note/raw/master/picture/rredis_%e8%b7%b3%e8%a1%a8.png" >
		<img src="https://github.com/Nixum/Java-Note/raw/master/picture/rredis_%e8%b7%b3%e8%a1%a8.png"
			
			
			
			loading="lazy"
			alt="Redis Ziplist">
	</a>
	
	<figcaption>Redis Ziplist</figcaption>
	
</figure></p>
<p>先排序分数，分数相同时，再排序元素值，默认是从小到大排。</p>
<p>跳表本质是为链表增加索引，建立多层索引，查找时从顶层的索引开始逐步往下层找，最终定位到元素，适用于范围查询的场景。跳表的相邻两层的节点数量最理想的比例是 2:1，查找的时间复杂度为O(logN)</p>
<p>但是，redis在创建跳表时，随机生成每个节点的层数，没有严格维持相邻两层节点2:1的比例，比如在创建节点时，会生成范围为[0-1]的一个随机数，如果这个随机数小于0.25，那么层数加一，然后生成下一个随机数，直到改随机数大于0.25，最终确定改节点的层数；这样做相当于每增加一层的概率不超过25%，层数越高，概率越低，层高最大限制是64；Redis 7.0 定义层高为 32，Redis 5.0 定义为 64，Redis 3.0 定义为 32</p>
<p>参考：<a class="link" href="https://www.pdai.tech/md/db/nosql-redis/db-redis-x-redis-ds.html"  target="_blank" rel="noopener"
    >Redis底层数据结构详解</a></p>
<blockquote>
<p>Skip List和各种平衡树（如AVL、红黑树等）的元素是有序排列的，而哈希表不是有序的。因此，在哈希表上只能做单个key的查找，不适宜做范围查找。</p>
<p>在做范围查找的时候，平衡树比Skip List操作要复杂。在平衡树上，我们找到指定范围的小值之后，还需要以中序遍历的顺序继续寻找其它不超过大值的节点。如果不对平衡树进行一定的改造，这里的中序遍历并不容易实现。而在skiplist上进行范围查找就非常简单，只需要在找到小值之后，对第1层链表进行若干步的遍历就可以实现。</p>
<p>平衡树的插入和删除操作可能引发子树的调整，逻辑复杂，而skiplist的插入和删除只需要修改相邻节点的指针，操作简单又快速。</p>
<p>从内存占用上来说，Skip List比平衡树更灵活一些。一般来说，平衡树每个节点包含2个指针（分别指向左右子树），而Skip List每个节点包含的指针数目平均为1/(1-p)，具体取决于参数p的大小。如果像Redis里的实现一样，取p=1/4，那么平均每个节点包含1.33个指针，比平衡树更有优势。</p>
<p>查找单个key，Skip List和平衡树的时间复杂度都为O(log n)，大体相当；而哈希表在保持较低的哈希值冲突概率的前提下，查找时间复杂度接近O(1)，性能更高一些。所以我们平常使用的各种Map或dictionary结构，大都是基于哈希表实现的。</p>
<p>参考：https://www.jianshu.com/p/8ac45fd01548</p>
</blockquote>
<h3 id="时间复杂度">时间复杂度</h3>
<p>对各种数据类型操作的时间复杂度取决于底层的数据结构，对于Set，虽然名字看起来是集合，但由于底层是哈希表 + 数组，因此在SREM、SADD、SRANDMENBER命令时，时间复杂度都是O(1)</p>
<ul>
<li>
<p>数据类型的范围查询，都需要进行遍历操作，一般都是比较耗时的。比如List的LRANGE、ZSet的ZRANGE、Set的SMEMBERS等</p>
</li>
<li>
<p>数据类型的统计查询，比如查看某数据类型的元素个数，时间复杂度是O(1)，因为数据结构本身就有记录了。</p>
</li>
</ul>
<h1 id="与memcached的区别">与Memcached的区别</h1>
<ul>
<li>
<p>Redis支持存储多种数据类型：string、list、hash、set、zset；而Memcached只支持string；</p>
</li>
<li>
<p>默认情况下，Redis key的最大上限是512M，string类型、list、hash、set、zset每个元素的value上限是512M，可以通过<code>proto_max_bulk_len</code>的值进行修改；memcached key的上限是50个字符，value最大值是1M；</p>
</li>
<li>
<p>Redis支持持久化：RDB快照和AOF日志；Memcached不支持持久化；</p>
</li>
<li>
<p>Redis支持事务，使用MULTI 和 EXEC命令，支持流水线式发送命令 ；Memcahced不支持事务，命令只能一条一条的发，当然这里的事务并不满足传统意义上的ACID；</p>
</li>
<li>
<p>Redis-Cluster 支持分布式存储，可以多台Redis服务器存储同样的数据；Memcached是以<strong>一致性哈希算法</strong>实现分布式存储，即多台Memcached服务器，Memcached根据查找的key计算出该数据在哪台服务器上；</p>
</li>
<li>
<p>在 Redis 中，并不是所有数据都一直存储在内存中，可以将一些很久没用的 value 交换到磁盘；</p>
<p>Memcached 的数据则会一直在内存中，Memcached使用固定空间分配，将内存分为一组大小不同的slab_class，每个slab_class又分为一组大小相同的slab，每个slab又包含一组大小相同的chunk，根据数据大小，放到不同的chunk里，这种管理方式避免内存碎片管理问题，但是会带来内存浪费，即每个chunk内会放小于这个chunk大小的数据，chunk里有些空间没利用到；</p>
</li>
</ul>
<p><strong>一致性哈希算法</strong>，主要解决传统哈希下节点扩容或缩容导致所有key要重新计算迁移的问题。</p>
<ol>
<li>构造一个长度为2的32次方的整数环，即0 ~ (2^32)-1的数字空间；</li>
<li>根据节点的唯一名称或者ip作为关键字进行哈希，确定节点在这个Hash环上的位置；</li>
<li>根据数据的key值计算Hash值，在Hash环上顺时针查找距离这个Key的Hash值最近的节点，完成key到节点的Hash映射查找；</li>
<li>当一个节点扩容或缩容时，只会影响到其中一个节点上的key，此时需要将该节点上的key重新计算，迁移到离它最近的一个节点，其他节点上的key则不会受影响，避免大量数据迁移，减少服务器压力。</li>
<li>为了解决负载不均衡问题（比如节点的数量很少，大量的数据就有可能都集中在上面），可以在此基础上增加一个虚拟层，对每个节点的关键字多计算几次哈希，每次计算的结果作为在环中的位置；key算完哈希值后，先在环上找到虚拟节点，再找到物理节点，将数据分散到各个节点，一般一个物理节点对应150个虚拟节点。</li>
</ol>
<p><a class="link" href="https://zhuanlan.zhihu.com/p/98030096"  target="_blank" rel="noopener"
    >一致性哈希参考</a></p>
<h1 id="redis的线程模型">Redis的线程模型</h1>
<blockquote>
<p>对于一个 DB 来说，CPU 通常不会是瓶颈，因为大多数请求不会是 CPU 密集型的，而是 I/O 密集型。具体到 Redis 的话，如果不考虑 RDB/AOF 等持久化方案，Redis 是完全的纯内存操作，执行速度是非常快的，因此这部分操作通常不会是性能瓶颈，Redis 真正的性能瓶颈在于网络 I/O，也就是客户端和服务端之间的网络传输延迟，因此 Redis 选择了单线程的 I/O 多路复用来实现它的核心网络模型。</p>
</blockquote>
<h2 id="单线程模型">单线程模型</h2>
<p><strong>Redis的单线程，指的是 网络IO 和 键值对读写 由一个线程来完成</strong>，其他的如持久化、异步删除、集群数据同步都有额外的线程完成。Redis在6.0版本后才支持IO多线程的网络模型。</p>
<p>Redis单线程之所以能处理得很快，得益于高效的数据结构，且采用了<strong>多路复用机制</strong>，在网络IO操作中能并发处理大量客户端请求，同时为了支持多种数据结构，保证并发安全，单线程模型下避免加锁解锁带来额外的开销。</p>
<p>监听 + 事件驱动 + 回调 的方式，处理易阻塞的accept和recv事件，是一个单Reactor模型，利用 epoll / select / kqueue 等多路复用技术，在单线程的事件循环中不断去处理事件（客户端请求）。</p>
<p><a class="link" href="https://zhuanlan.zhihu.com/p/57089960?utm_source=wechat_session&amp;utm_medium=social&amp;utm_oi=632939468966072320"  target="_blank" rel="noopener"
    >一文揭秘单线程的Redis为什么这么快?</a></p>
<p><a class="link" href="https://strikefreedom.top/multiple-threaded-network-model-in-redis"  target="_blank" rel="noopener"
    >Redis 多线程网络模型全面揭秘</a></p>
<p>总结一下就是：高效的数据结构和数据压缩、纯内存操作、非阻塞IO多路复用，避免频繁的上下文切换、避免同步机制的开销。</p>
<h2 id="多线程模型">多线程模型</h2>
<p>Redis 4.0之后引入多线程来做一些异步操作，比如以前<code>DEL</code>命令在删除big key和大量key时是阻塞操作，为了解决这个问题引入多线程使得部分命令支持多线程的异步操作，比如<code>UNLINK</code>、<code>FLUSHALL ASYNC</code>、<code>FLUSHDB ASYNC</code>，此时的网络IO模型仍然是单线程的（单Reactor模型）</p>
<p>Redis 6.0之后才引入多线程的网络IO模型（多Reactor模型，但不是标准的多Reactor模型），总的流程还是跟单线程模型一样，只是把读取客户端命令和回写响应数据的操作交由I/O线程去执行异步化，<strong>I/O 线程仅仅是读取和解析客户端命令而不会真正去执行命令，客户端命令的执行最终还是要在主线程上完成</strong>；</p>
<h2 id="影响性能的场景">影响性能的场景</h2>
<p>关于big key：对于字符串类型，其value的大小超过10KB；集合类类型，其元素的个数超过10k；</p>
<ul>
<li>
<p>对big key的操作，比如创建和删除，big key在分配内存和释放内存会比较耗时。big key意味着value很大，当进行全量查询返回、聚合操作、全量删除(因为要释放内存)时可能会阻塞主线程。</p>
<p>一般可以配合scan命令以及对应数据类型的scan命令来增量获取或删除。</p>
</li>
<li>
<p>一些命令对应的操作时间复杂度高，比如范围查询、keys命令。</p>
<p>一般使用scan代替keys命令，scan命令时因为使用高位进位法遍历，所以即使在扩容情况下也不会漏key，但在缩容时可能得到重复的key。</p>
</li>
<li>
<p>大量Key集中过期，Redis过期机制也在主线程中执行，大量Key集中过期会导致耗时过长，所以在设置过期时间时要加入随机数。</p>
</li>
<li>
<p>淘汰策略也是在主线程执行的，发生在执行命令之前，会影响用户命令的执行速度。当内存超过Redis内存上限后，每次写入都需要淘汰Key，也会产生耗时，如果淘汰过程中，内存不足，使用 swap 机制，也会阻塞整个主线程；</p>
</li>
<li>
<p>主从全量同步生成RDB快照，虽然采用fork子进程生成数据快照的方式，但fork瞬间也会阻塞主线程（因为涉及页表的复制和分配，虽然copy on write能减少部分影响，如果有大量写入就会出现大量复制了）</p>
<p>另外，从库在接收RDB快照后，会清空所有键值对，如果量大的话也很耗时，如果RDB文件太大，加载也耗时。</p>
</li>
<li>
<p>AOF日志同步写，因为是需要写磁盘的，比如设置为everysec可能会阻塞主线程。</p>
</li>
<li>
<p>切片集群，向其他实例传输哈希槽信息，big key数据的迁移，或者分片内存倾斜。</p>
</li>
</ul>
<p>所以big key基本上是因为占用内存过大，引发了种种问题，阻塞工作线程，导致客户端超时，造成网络阻塞，内存分布不均等。</p>
<p>改进的话，就只有删除操作和AOF日志同步写可以放在异步线程去做，Redis4.0以后才提供删除和AOF同步写的异步命令。</p>
<h2 id="使用规范和优化">使用规范和优化</h2>
<ul>
<li>
<p>String类型的数据不要超过10KB，避免BigKey，value可以使用压缩算法进行压缩来减少大小；</p>
</li>
<li>
<p>Key的长度尽量短，尽量控制在39字节以内，减少创建RedisObject内存分配次数，提升性能；</p>
</li>
<li>
<p>当big key真的无法避免时，需要对big key拆分成多个；</p>
</li>
<li>
<p>定时清理 hash 中无效的数据，Redis &gt;= 4.0 ，可以使用 unlink 命令代替 del 命令删除key，该命令会进行异步删除；Redis &gt;= 6.0 ，可以开启 lazy-free机制，执行del命令时，释放内存的操作放到后台线程执行；</p>
</li>
<li>
<p>如果需要频繁操作redis，可以使用pipeline，合并多个命令请求，减少IO次数，也就减少了 CPU上下文切换，当然，pipeline本身组装命令的个数也不能太多</p>
</li>
<li>
<p>key的过期时间加上随机值，避免key的集中过期；</p>
<p>利用Redis分区功能，将数据分散到各个分区，减轻多个Redis内存淘汰的负载压力；</p>
</li>
<li>
<p>集合类型的元素个数不超过一万个；</p>
</li>
<li>
<p>绑核，绑定在同一个物理核心的多个逻辑核心上，让他们能公用L1/L2 Cache，降低Redis在多个CPU核心之间的上下文切换带来的性能损耗，比如 可以让 主线程、后台线程、后台 RDB 进程、AOF rewrite 进程 绑定在不同的核心上；</p>
</li>
<li>
<p>Redis实例容量控制在10GB内；</p>
</li>
<li>
<p>禁用Keys、FlushAll、FlushDB命令，慎用全量操作命令、Monitor命令、复杂度过高的命令（如Sort、Sinter、SinterStore、ZUnionStore、ZInterStore）</p>
</li>
</ul>
<h2 id="监控">监控</h2>
<ul>
<li><code>redis-cli -h 127.0.0.1 -p 6379 --bigkeys -i 0.01</code>，每隔0.01秒扫描一次big key，本质是用scan命令遍历所有key，然后针对key的类型，执行<code>STRLEN, LLEN, HLEN, SCARD和ZCARD</code> 命令，来获取 String 类型的长度，容器类型（List, Hash, Set, ZSet）的元素个数，使用时，要注意对线上的影响；</li>
<li>使用 redis-rdb-tools 分析 redis rdb文件，因为是离线分析，所以对redis服务没影响</li>
<li><code>redis-cli -h 127.0.0.1 -p 6379 --hotkeys</code>，扫描hotkey，前提是需要开启 <code>allkey-LFU</code>，这样才能根据key的访问次数知道哪些是hotkey</li>
<li><code>INFO memory</code> 命令查看Redis内存碎片率</li>
</ul>
<h1 id="过期时间和数据淘汰策略">过期时间和数据淘汰策略</h1>
<h2 id="key过期删除原理">key过期删除原理</h2>
<ul>
<li>
<p>定期删除策略：Redis起定时器扫描key（默认100ms），判断key是否过期，过期则删除。虽然可以保证过期的key会被删除，但是每次都要扫描会非常消耗CPU资源，且定时器有间距，有可能出现key过期，但是此时定时器还没起，key仍保存在内存中，处理过程中会阻塞主线程；</p>
<p>抽样检查那些有过期时间的key，每次获取20个（默认），删除其中过期的key，如果占比超过25%，重复此步骤直到低于25%；</p>
</li>
<li>
<p>惰性删除策略：每次获取key的时候才判断key是否过期，过期则删除，对CPU消耗较少，只处理当前key，但如果key一直未被使用，则会一直留在内存里，浪费空间，甚至导致内存泄漏；</p>
<p>注意在Redis3.2以前，主库惰性删除后，从库不会触发数据删除，此时还能读到，3.2以后的版本才改正，返回空值，4.0后从库才会定时校验过期key。另外，expire命令在主库设置key的过期时间，到了从库可能有延迟导致过期时间比实际的长，expire命令表示执行完多久会过期，expireat/pexpireat命令表示在某一时间点会过期。</p>
</li>
<li>
<p>所以Redis会将这两种策略整合在一起，定期删除策略不在是每次都扫描全部key，而是随机抽取一部分key进行检查，在配合惰性删除策略，正好可以弥补惰性删除策略的缺点。</p>
</li>
</ul>
<h2 id="淘汰策略">淘汰策略</h2>
<p>当内存使用量超出所设置的maxmemory值时，才会执行淘汰策略。默认的淘汰策略是当内存满了之后，新写入操作会报错。maxmemory值一般设置为总数据量的15%-30%。</p>
<p>其他淘汰策略，分为两种，一种是在所有数据范围内，一种是在设置了过期时间的范围内。</p>
<ul>
<li>allkeys-random：在所有key中，随机移除某个key</li>
<li>allkeys-Lru：在所有key中，移除最近最少使用的key（<strong>优先使用</strong>）</li>
<li>allkeys-Lfu：在所有key中，移除访问次数最少的某个key</li>
<li>volatile-random：在所有有设置过期时间的key中，随机移除某个key</li>
<li>volatile-Lru：在所有有设置过期时间的key中，移除最近最少使用的key</li>
<li>volatile-ttl：在所有有设置过期时间的key中，有更早过期时间的key优先移除</li>
<li>volatile-Lfu：在所有有设置过期时间的key中，移除访问次数最少的某个key</li>
</ul>
<h3 id="淘汰策略中的lru算法">淘汰策略中的LRU算法</h3>
<p>对于LRU算法，如果一些元素被频繁使用，会导致频繁的移动，带来了额外的开销。</p>
<p>Redis的LRU算法做了简化，其只会在RedisObject中记录每个数据最近以此访问的时间戳，当出现数据淘汰时，第一次会<strong>随机</strong>选出N个数据，作为一个候选集合，比较N个数据的lru字段，把lru字段最小的元素淘汰。</p>
<p>再次淘汰时，Redis会挑选那些LRU的值小于候选集合中最小LRU值的数据，进入第一次淘汰时创建的候选集合，可能会把里面最大的换出去或者淘汰里面最小的。准备候选集和淘汰数据是两个解耦操作。</p>
<p>N的值由<code>maxmemory-samples</code>决定。</p>
<h3 id="淘汰策略中的lfu算法">淘汰策略中的LFU算法</h3>
<p>Redis的LRU算法有个问题是对于非热点数据，其访问次数很少，直到触发淘汰策略才会被删除，在被删除之前都会一直留存，造成缓存污染。LFU算法就是为了解决这个问题。</p>
<p>LFU缓存策略是在LRU策略基础上，为每个数据增加一个计数器，统计数据访问次数。当使用LFU淘汰策略筛选淘汰数据时，首先会根据访问次数进行筛选，把访问次数最低的数据淘汰出缓存，当淘汰次数相同时，才会比较时间。</p>
<p>LFU在LRU的基础上，将RedisObject中的访问时间戳拆成两半，16bit存时间，8bit存计数，但计数不是线性递增，而是采用一种计算规则，让其增长不那么快到达2^8=255次，同时也有衰减机制，减少次数对时间的影响。</p>
<h3 id="淘汰执行时机">淘汰执行时机</h3>
<p>淘汰时机和被动删除过期key的时机一样，在用户的命令真正执行之前执行淘汰策略；</p>
<h1 id="存储与持久化">存储与持久化</h1>
<h2 id="rdb快照redis-database">RDB快照（Redis DataBase）</h2>
<p>RDB快照由于保存的是数据，恢复起来会比AOF快（AOF保存的是命令），而且AOF是文本文件，RDB是二进制文件，所以RDB快照在网络传输、IO效率都比AOF好。</p>
<h3 id="相关命令和配置">相关命令和配置</h3>
<p><code>bgsave</code>：会调子进程创建快照写入磁盘，主线程继续处理其他命令请求；</p>
<p><code>save</code>：主线程创建快照写入磁盘，会阻塞其他命令请求，生产环境中比较少用；</p>
<p>redis.conf 文件里的配置：</p>
<p><code>save</code>：<code>save [时间] [次数]</code> 表示在[时间]内有[次数]写入/更新，就会触发bgsave命令</p>
<p>另外，在进行主从复制，主redis发送sync命令给从redis时，如果刚刚没有执行完bgsave，也会进行一次bgsave操作。</p>
<p><code>rdbcompression</code>：是否启用LZF算法进行压缩，压缩可以使得RDB快照落盘的文件变小，但在压缩时会消耗CPU资源。</p>
<h3 id="原理">原理</h3>
<p>将Redis中的数据全量保存在文件中，一般会异步使用子进程进行刷盘操作，不阻塞主线程，此时主线程仍然能处理命令。（<strong>先全量</strong>）</p>
<p>此外，会使用<strong>Copy on Write机制（写时复制）</strong>，解决创建快照的过程中，原有数据被修改对RDB快照的影响。当主线程对原有数据进行修改前，这块数据会被复制一份（复制引用，由bgsave子进程操作），形成副本（此时会消耗两倍内存），由子进程将该副本写入RDB文件中，由于写的是引用，主线程修改后会同步到RDB中。（<strong>后增量</strong>）</p>
<p>Copy on Write：代码是共享的，数据是私有的，子进程被创建出来后，子进程就将父进程的数据拷贝了一份给自己，如果是只读的数据，父子进程页表指向同一个物理内存，如果子进程或者父进程修改了页表，此时会分离成两份，指向不同的物理内存，让父子进程对这一块数据操作不会相互干扰；</p>
<p>从而减少分配和复制大量资源时带来的瞬时延时，缺点就是，如果写操作很多，就会产生大量的分页中断，产生大量复制，带来延时，当然，因为redis是读多写少的场景，所以还算合适。</p>
<h3 id="优点">优点</h3>
<ul>
<li>RDB文件是某个时间节点的快照，默认使用LZF算法进行压缩，压缩后的文件体积远远小于内存大小，适用于备份、全量复制等场景；</li>
<li>Redis加载RDB文件恢复数据要远远快于AOF方式；</li>
</ul>
<h3 id="潜在风险">潜在风险</h3>
<ul>
<li>风险在于快照的创建频率，快照是每隔一段时间进行创建和写入的，如果频繁创建快照，多快照写盘会影响磁盘IO，因此每次都进行全量快照并不可取。</li>
<li><strong>如果频率过低，则会导致宕机时丢失的数据过多。解决方式是RDB + AOF一起使用，在两次快照期间用AOF代替。</strong></li>
<li>当使用copy on write机制时，主线程会为其申请额外的空间，当进行频繁的写操作时，会导致内存很快被耗光。当实例系统开启了Swap机制时，超过内存使用量部分会转移到磁盘，访问磁盘的那部分就会很慢，如果没有开启Swap机制，则会触发OOM，Redis进程可能被kill或宕机；</li>
<li>另外，当出现频繁的写操作时，由于生成RDB的子进程需要CPU核运行，主线程、多个线程或后台进程会竞争使用CPU，导致性能降低；</li>
<li>实时性不够，无法做到秒级别的持久化；</li>
<li>RDB文件是二进制，没有可读性，而AOF文件可以在了解其结构后手动修改或补全；</li>
<li>版本兼容RDB文件问题</li>
</ul>
<h2 id="aofappend-only-file">AOF（Append Only File）</h2>
<h3 id="相关命令和配置-1">相关命令和配置</h3>
<p><code>bgrewriteaof</code>：执行后，Redis主进程fork子进程执行<strong>AOF重写</strong>，该子进程会创建新的AOF文件来存储重写结果，防止影响旧文件；</p>
<p>redis.conf文件里的配置：</p>
<p><code>appendonly yes</code>：aof默认是关闭的，如果要打开，设置成yes；</p>
<p><code>appendfsync</code>：</p>
<ul>
<li>no：每次命令只写内存(日志缓冲区)，刷盘记日志的操作由操作系统决定，不阻塞主线程，调用fsync，通常最多30s；</li>
<li>everysec（默认）：写命令记录到文件中，<strong>默认是每秒同步一次</strong>（调用一次fsync），所以如果发生故障，最多会丢失一秒的数据，但使用AOF保存的数据文件比RDB快照要大；<strong>Redis会使用另外的线程进行刷盘；</strong></li>
<li>always：此外AOF还能选择每接收一个写命令就追加写入到AOF文件中，虽然能避免不丢数据，<strong>但每个写命令都是在主线程上完成，且后面都跟着一个刷盘操作</strong>，对机器的负担较大，影响服务性能；</li>
</ul>
<p><code>auto-aof-rewrite-percentage 100</code>：aof文件的容量超过原来aof文件容量一倍的时候, 进行aof文件的重写，默认100；</p>
<p><code>auto-aof-rewrite-min-size 64mb</code>：执行aof重写时, aof文件的最小容量，默认64MB；</p>
<h3 id="原理-1">原理</h3>
<p>AOF时，Redis会先把命令追加近AOF内存缓冲区，然后根据<code>appendfsync</code>配置的策略将内存中的数据写入磁盘。</p>
<p>不同与MySQL的WAL机制，AOF是先执行命令将数据写入内存，再写入日志。因为AOF会记录Redis收到的每一条命令，并以文本的形式保存，如果先写日志，并不知道命令是否是正确的，因此先写内存，让系统执行成功后，才会记录到日志中，避免错误命令。</p>
<h3 id="潜在风险-1">潜在风险</h3>
<ul>
<li>执行完命令，还没来得及记录日志就宕机，此时会丢失该命令的记录和相应数据。如果使用Redis当缓存，且要保证Redis宕机时不直接读库，利用Redis的AOF机制时就要注意了。</li>
<li>AOF是在命令执行后才记录日志，所以不会阻塞当前的写操作，但由于日志的写操作也是在主线程中的，虽然避免阻塞当前操作，但可能会阻塞下一个命令操作，比如刷盘时磁盘IO过慢。</li>
</ul>
<h3 id="重写机制">重写机制</h3>
<p>一般用于<strong>避免AOF日志文件过大</strong>，毕竟如果文件太大会影响磁盘IO、重放会太耗时。</p>
<h4 id="原理-2">原理</h4>
<p>当AOF文件大小超过配置时，执行AOF重写机制。Redis会创建一个新的AOF文件，<strong>读取Redis中所有键值对</strong>后进行写入，但在重写时不是原样copy，而是<strong>会对命令进行合并，以此减小文件大小</strong>。</p>
<p>重写时，主线程会fork后台的bgrewriteiaof子进程，把<strong>主线程的内存拷贝一份给bgrewriteiaof子进程</strong>，其中也包括了Redis的最新数据，bgrewriteiaof子进程逐一写入重写日志，避免阻塞主线程。</p>
<p>因为重写是在子进程中处理的，此时主线程仍然能处理客户端的命令，当接收到客户端的写命令时，<strong>会记录到AOF日志</strong>中，<strong>同时</strong>也会写进<strong>AOF重写日志</strong>的缓冲区，等子进程将拷贝数据写完后，再把缓冲区的数据刷入，完成后即可删除旧的AOF文件，留下新的AOF重写文件。</p>
<h4 id="潜在风险-2">潜在风险</h4>
<ul>
<li>主线程fork创建bgrewriteaof子进程时，内核会把主线程的PCB内容拷贝给子进程，此时会阻塞主线程，当要拷贝的内容特别大时，fork执行的时间就会变长，阻塞主线程的时间也会变长。</li>
<li>bgrewriteaof子进程会和主线程共享内存，当主线程收到新增或修改操作时，主线程会申请新的内存空间用来保存，但是如果是bigkey，主线程就会面临申请空间过大导致耗时。</li>
</ul>
<h1 id="高可用集群">高可用集群</h1>
<p>RDB和AOF保证了数据少丢失，集群部署保证服务少中断，实现高可用。</p>
<h2 id="主从复制---保证数据一致性">主从复制 - 保证数据一致性</h2>
<p>一般采用主从读写分离，主库进行写操作，然后再同步给从服务；而读操作发生在主从库均可。最好还是读写都在主库，从库只保证高可用，原因是主从数据同步是异步的，总有可能出现网络波动等问题导致主从库数据不一致，或者主库设置过期时间，但是到从库上有延迟导致读到过期数据，主库的过期删除无法同步到从库（4.0才解决）。</p>
<blockquote>
<p>当 Redis 运行在主从模式下时，<strong>从库不会进行过期扫描，从库对过期的处理是被动的</strong>。也就是即使从库中的 key 过期了，如果有客户端访问从库时，依然可以得到 key 对应的值，像未过期的键值对一样返回。</p>
<p>从库的过期键处理依靠主服务器控制，<strong>主库在 key 到期时，会在 AOF 文件里增加一条 del 指令，同步到所有的从库</strong>，从库通过执行这条 del 指令来删除过期的 key。</p>
</blockquote>
<p>如果写操作可以发生在主从库上，会导致主从库上的数据不一致，取数据时可能会取到旧值，而如果要保持一致，则需要加锁，加锁的话效率旧太差了。</p>
<p>一般用在<strong>从节点</strong>初始化加入时使用，先进行<strong>全量同步(通过快照)</strong>，再进行<strong>增量同步(通过命令缓存同步)</strong>。</p>
<h3 id="相关命令">相关命令</h3>
<p>在从库上使用命令：Redis 5.0以前使用<code>slaveof</code>、之后使用<code>replicaof  [主库IP] [主库端口]</code></p>
<h3 id="过程">过程</h3>
<ol>
<li>
<p>主库创建RDB快照文件，发送给从库，并在发送期间使用缓冲区(replication buffer)记录之后收到的写命令。</p>
<p>快照文件发送完毕之后，开始向从库发送存储在缓冲区中的写命令；整个过程中主库不会被阻塞；</p>
</li>
<li>
<p>从库丢弃所有旧数据，载入主库发来的快照文件，之后从库开始接受主库发来的写命令；</p>
</li>
<li>
<p>主库每执行一次写命令，就向从库发送相同的写命令；</p>
</li>
</ol>
<p>一般只设置一个主节点，当负载上升时，主库可能无法很快地更新所有从库，或者重新连接和重新同步从库将导致系统超载。因为在一次主从数据同步过程中，主库有两个耗时的操作：生成RDB文件和传输RDB文件，如果从库数量过多，会导致主库忙于fork子进程生成RDB文件进行全量复制，导致阻塞主线程的正常请求，同时传输的带宽也带来了压力。</p>
<p><strong>解决办法</strong>：通过<strong>主从级联模式</strong>解决，可以设置主节点为根节点，向下延申，从节点再设置从节点的方式，形成树状的主从链，让从节点帮忙同步给其子节点的方式，降低主节点的压力。</p>
<p>同样使用命令slaveof或replicaof，只是ip换成从库的ip，这样就形成了主-从-从的模式了。</p>
<h2 id="主从库命令传播时网络中断">主从库命令传播时网络中断</h2>
<p>Redis2.8之前，如果主从库发生网络中断，重新连接时会进行全量复制，开销巨大。</p>
<p>2.8之后，会使用增量复制。断连期间，主库会把收到的写命令写入缓冲区（<code>replication buffer</code>和<code>repl_backlog_buffer</code>）。</p>
<p>断连时，会记录从库的偏移量，待重新连接后即可根据偏移量进行同步。由于<code>repl_backlog_buffer</code>是环形缓冲区，如果从库同步太慢，因此可能会出现新命令覆盖到未读取的命令，只能通过调整其大小解决，配置<code>repl_backlog_size</code>，否则，从库将进行全量复制。</p>
<p>主从模式下，从库宕机影响不大，但主库宕机就会影响从库的同步了，此时需要哨兵机制重新选举主库，保证高可用。</p>
<p><code>replication buffer</code>：主从库在进行全量复制时，主库上用于和从库连接的客户端的 buffer，非共享，每个从库对应一个。</p>
<p><code>repl_backlog_buffer</code>：主库上用于持续保存写操作的一块专用 buffer，是一个环形缓冲区， 从库共享。为了支持从库增量复制，主库会记录自己写到的偏移量(<code>master_repl_offset</code>)，而每个从库都会有自己的复制进度标志(<code>slave_repl_offset</code>)记录在上面，记录自己的写偏移量。</p>
<h2 id="哨兵机制">哨兵机制</h2>
<p>哨兵机制会解决三个问题：1.判断主库是否宕机；2.选择哪个从库为主库；3.如何把新主库的信息通知给从库和客户端。</p>
<p>使用<strong>哨兵模式</strong>（sentinel）来监听和管理Redis集群，存储集群配置，作用类似ZooKeeper，哨兵节点是一台特殊的Redis，功能有限，主要用来支持哨兵机制，哨兵节点有三个任务：<strong>监控、选主、通知</strong>。</p>
<h3 id="原理-3">原理</h3>
<p><strong>哨兵节点一般设置3个及以上的奇数个，哨兵节点间是平级的，会互相监控</strong>。</p>
<ul>
<li>所有哨兵节点都会周期性的给所有主从库发送Ping命令检测Redis的主从节点是否正常运行，当有Redis节点出现问题时，进行通知。</li>
<li>如果发生问题的节点是主节点，会从从节点中选出主节点，代替失效的主节点。</li>
<li>之后会把新主库的连接信息发给其他从库，让他们执行<code>replicaof</code>命令，和主库建立连接，并进行数据复制。同时把新主库的连接信息通知给客户端，让客户端把请求发送到新主库上。</li>
</ul>
<h3 id="如何监控如何判断主库不可用">如何监控，如何判断主库不可用</h3>
<p><strong>主观下线</strong>：每个哨兵节点每隔1s对主从节点发生心跳，当有节点在超过x秒后没有进行回复，此时该节点为主观下线，还需要进一步判断。</p>
<p><strong>客观下线</strong>：当主观下线的节点是主节点时，该哨兵节点会通过<code>sentinel is-master-down-by-addr</code>命令，向其它<code>n - 1</code>个哨兵节点询问对主节点的判断，当超过 <code>n / 2 + 1</code> 个哨兵节点认为主节点有问题时，该节点为客观下线。<strong>多这一步是为了防止误判。</strong></p>
<p>客观下线后，会从从节点中选举出主节点，前主节点重新上线后会被设置为从节点。</p>
<p>Redis没有使用什么一致性算法，仅依据<strong>Gossip协议</strong>在有效时间范围内收到其它Sentinel节点的确认。</p>
<p>另外，如果不使用哨兵模式，只使用Redis集群，也可以实现高可用，只不过是把监控和选择转移到各个节点中。</p>
<h3 id="如何选举">如何选举</h3>
<p>哨兵节点会周期性的发送心跳给主从库，在此过程中会对各个节点进行打分。之后按照一定的筛选条件和规则，选出得分最高的从库为新主库。</p>
<ul>
<li>筛选条件：从库的在线状态，之前的网络连接状态。通过设置主从库断连的最大连接超时时间（down-after-milliseconds）、断连次数（n），当超过阈值时则说明从库的网络状况不好。</li>
<li>打分规则：从库的优先级（比如不同从库的配置不一样，优先级也就不一样）、从库的复制进度（根据从库在<code>repl_backlog_buffer</code>中的偏移量，从库间比较）、从库的ID号（ID号小的分高）</li>
</ul>
<h3 id="如何通知">如何通知</h3>
<p>客户端在访问主从库时，不能写死主库地址，而是从哨兵节点中获取主库地址；当哨兵选出新的主库时，会更新自己存的新主库地址。哨兵节点通过 发布/订阅 机制，让客户端进行订阅和修改。从而也能让客户端了解整个主从切换过程。</p>
<h3 id="主从切换时可能产生脑裂">主从切换时，可能产生脑裂</h3>
<p>如果主库因为某些原因进入假死状态（但还能处理命令），被哨兵判定为客观下线，哨兵执行主从切换，但此时主库恢复正常，但此期间写操作的数据还未同步到从库，待哨兵完成主从切换后，Redis集群会短暂出现两个主库，导致客户端的写操作会发往不同的主库，或者原主库降级成从库，会清空本地数据重新载入新主库的RDB快照，导致数据不一致或丢失。</p>
<p>判断主从库数据是否不一致，可以通过对比主从库上的复制进度差值来进行判断，计算<code>matser_repl_offset</code>和<code>slave_repl_offset</code>的差值，如果从库上的<code>slave_repl_offset</code>小于原主库的<code>master_repl_offset</code>，就说明数据丢失是因为数据未同步完成导致的。</p>
<p><strong>根本原因</strong>：Redis主从集群没有使用共识算法，每个写操作没有在大多数节点写成功后才认为成功导致的。不像ZooKeeper，客户端的操作都会经过ZooKeeper的主节点，当发生脑裂时，ZooKeeper主节点无法写入大多数节点，写请求直接失败，保证数据一致性。</p>
<p><strong>解决方法</strong>：在主库上配置<code>min-slaves-to-write</code>表示主库能进行数据同步的最少从库数量；<code>min-slaves-max-lag</code>表示主从数据复制时，从库给主库发送ACK消息的最大延迟(秒)。这样当主库假死时，无法响应哨兵心跳，也不能和从库同步，确认从库的ACK命令，原主库就无法再接收客户端的写操作。</p>
<h3 id="哨兵集群的高可用">哨兵集群的高可用</h3>
<p>由于哨兵需要进行客观下线的判断，因此需要多个哨兵组成集群，集群就会涉及到高可用。</p>
<h4 id="哨兵节点间与主从库间的相互发现机制">哨兵节点间、与主从库间的相互发现机制</h4>
<ul>
<li>
<p>哨兵节点间的相互发现：正常情况下，每个哨兵都是平级的。每个哨兵节点在设置时的命令是<code>sentinel monitor &lt;master-name&gt; &lt;ip&gt; &lt;redis-port&gt; &lt;quorum&gt; </code>，并不感知其他哨兵的存在。<strong>哨兵节点间的相互发现，依赖Redis的 发布/订阅 机制</strong>。哨兵节点一旦和主库建立连接，就会把自己的连接信息(如IP、端口)发布到主库上，同时它也会订阅，从而发现其他哨兵节点。</p>
</li>
<li>
<p>哨兵节点发现从库：哨兵节点连接主库后，发送INFO命令，主库就会把从库连接信息列表发给哨兵节点，从而实现哨兵节点对从库的监控。</p>
</li>
</ul>
<h4 id="哨兵节点leader选举原理">哨兵节点Leader选举原理</h4>
<p>正常情况下哨兵集群内的每个哨兵节点是平级的，但是当触发客观下线时，需要选出一个哨兵节点Leader来执行主从库切换。重新选举主库只能由一个哨兵节点来做，如果不是，可能会出现主从库集群脑裂。另外，哨兵节点越多，选举速度越慢，风险也会增加。</p>
<p>哨兵节点Leader选举分为两个阶段：</p>
<ol>
<li>
<p>各个哨兵节点判断主/客观下线阶段：各个哨兵在判断主库是主观下线后，首先会给自己投Yes票，之后会发送<code>is-master-down-by-addr</code>命令给其他哨兵节点，其他哨兵节点会根据自己的判断情况，回复Yes / No回去。该哨兵节点收集得到的Yes票，当超过设置的quorum值时，标记主库为客观下线。</p>
</li>
<li>
<p>每个哨兵在一次选举节点只有一次投票机会，当有哨兵节点得出客观下线结论后，该哨兵再发起投票，进行Leader选举，当收集到的票数超过一半，则该哨兵节点成为Leader节点，如果没有选举成功，则等待一般是故障转移超时时间failover_timeout的2倍时间后会重新举行选举。</p>
</li>
</ol>
<p><figure 
	>
	<a href="https://github.com/Nixum/Java-Note/raw/master/picture/Redis%e5%93%a8%e5%85%b5%e4%b8%8b%e7%ba%bf%e4%b8%bb%e5%ba%93%e5%92%8cLeader%e9%80%89%e4%b8%be.png" >
		<img src="https://github.com/Nixum/Java-Note/raw/master/picture/Redis%e5%93%a8%e5%85%b5%e4%b8%8b%e7%ba%bf%e4%b8%bb%e5%ba%93%e5%92%8cLeader%e9%80%89%e4%b8%be.png"
			
			
			
			loading="lazy"
			alt="Redis哨兵下线主库和Leader选举">
	</a>
	
	<figcaption>Redis哨兵下线主库和Leader选举</figcaption>
	
</figure></p>
<h2 id="几个注意点">几个注意点</h2>
<ul>
<li>
<p>主从复制设置时，最好在主节点上开启持久化，否则可能会导致从节点的数据被清空；</p>
<p>当主节点关闭持久化后，从节点开始从主节点复制数据，如果此时主节点挂了，因为关闭了持久化，且重启速度比较快，哨兵节点没有发现，重启后主节点数据为空，当从节点在进行数据复制时发现主节点是空的，从节点上的数据也会被删除。</p>
</li>
<li>
<p>Redis支持无磁盘复制，当使用低转速的磁盘时，可能会影响复制性能，当启动无磁盘复制时，主节点子进程直接将RDB通过网络发送给从节点，不使用磁盘。</p>
</li>
</ul>
<h1 id="高可用扩展集群">高可用扩展集群</h1>
<p>一般一个Redis保存几个G内比较合适，<strong>当单个Redis实例要保存的键值对太多时，会影响Redis的主从复制、RDB快照和AOF日志的大小、影响从库重放速度、fork子进程的速度(太慢会导致阻塞主线程)</strong>，因此需要进行对单Redis实例扩展，常见的方式是对单个Redis实例进行扩展，一般分为纵向扩展和横向扩展。</p>
<p>redis中默认有编号0-15总共16个db，默认使用db0，每个数据库都有属于自己的空间。</p>
<p>在redis集群时，不可以使用select命令选择db，因为redis集群仅支持db0。</p>
<p>Redis集群最大节点个数是 <strong>16384</strong> 个，因为Redis集群没有使用一致性hash，而是哈希槽，Redis集群就有16384个哈希槽，原因是 Redis节点发送心跳包时需要把所有槽放到这个心跳包中，让节点知道当前集群信息，<code>16384 = 16k</code> 在发送心跳包时<strong>使用char进行bitmap压缩后是2k（2 * 8 (8 bit) * 1024(1k) = 16K）</strong>，因此使用 2k 空间就能创建 16k 的槽数了，尽管CRC16 算法最多课分配 <code>2 ^ 16 - 1 = 65535</code> 个槽位，压缩后也才8k，但一般来说，一个Redis集群不会超过1000个master节点，所以16k的槽位就比较合适。</p>
<h2 id="扩展">扩展</h2>
<ul>
<li>纵向扩展：升级单Redis实例的配置，如内存容量、磁盘容量、CPU等，但会影响RDB快照和AOF日志大小，网络传输等，一般用在不使用Redis持久化功能的场景。</li>
<li>横向扩展：根据key，对Redis实例进行分片，增加Redis实例个数。</li>
</ul>
<h2 id="分片">分片</h2>
<p>Redis分片的实现使用哈希槽。</p>
<h3 id="原理-4">原理</h3>
<ul>
<li>
<p>将数据分散到集群的多个机器上，Redis里使用的概念是槽Slot，每个集群的槽数固定为16 * 1024 = 16384个，使用哈希分片算法对Key进行取模，计算方法：<code>HASH_SLOT = CRC16(Key) mod 16384</code>，余数为Key所在的槽。</p>
<p>之所以会使用槽，是因为要把数据和节点解耦，如果不使用槽，而是使用key与节点的映射表，当key的数量非常庞大时，映射表也会非常大，映射表的修改和迁移的性能不高。</p>
<p>集群只需要记录槽的ID与槽节点的地址映射即可，默认情况下，当集群 16384 个槽任何一个没有指派到节点时会导致整个集群不可用，so，当有节点故障下线时，从故障发现到自动完成转移期间整个集群不可用，如果要关闭这个配置，需要在redis.conf中配置：<code>cluster-require-full-coverage no</code>，这样就只会影响故障节点了。</p>
</li>
<li>
<p>集群内每台机器会存放一些槽，在集群初始化的时候会<strong>对集群内的机器平均分配这16384个槽</strong>，使用查表法进行分配。因此，当需要扩容时，会重新计算槽的位置和迁移key，可以使用官方提供的redis-trib.rb脚本实现。</p>
</li>
<li>
<p>客户端连接分片集群后，即可获得槽与各个Redis分片节点的映射。访问时可以访问集群内的任意节点，先根据key算出在哪个槽，在查询槽和节点间的关系，找到对应的节点进行查询。</p>
<p>另外，要注意分片后，对于Keys、scan这样的扫描命令的性能就会更加差了。</p>
</li>
<li>
<p>当分片集群有增删时，槽与节点的映射也会随之修改，为了负载均衡，Redis需要把槽重新分布到各个分片上。但是客户端却不感知，当客户端发送命令时，如果节点上该槽已迁往别处，客户端会收到<code>MOVED 新槽编号 新槽所在的host</code>的错误信息，客户端将重新请求，同时修改槽与节点的映射关系。</p>
</li>
<li>
<p>如果客户端请求发生在Redis迁移槽的过程中，则会先收到<code>ASK 新槽编号 新槽所在的host</code>的错误消息，让客户端进行重试，直到Redis完成槽的迁移，重试成功。</p>
</li>
<li>
<p>HashTag，如果key的格式是 <code>user:order:{3214}</code>，由{}括起来的部分为HashTag，CRC算法在计算key在哪个槽时只会计算{}里的值，HashTag主要是让多个类型的key可以映射到同一个槽，方便范围查询。</p>
<p>但使用HashTag可能会导致数据倾斜，使得请求无法平均分到各个分片。</p>
</li>
</ul>
<p>一般的分配规模是几十个以内，不适合构建超大规模的集群，原因是去中心化设计，选举算法使用Gossip，规模越大时，传播速度越慢。如果要构建超大规模的集群，则需要增加一层代理，进行集群间的转发，例如twemproxy或者Codis这类基于代理的集群架构。</p>
<h1 id="事务">事务</h1>
<p>使用 MULTI 和 EXEC 命令将多个写操作包围起来进行发送，Redis收到后会先将命令暂存到一个队列里，当收到EXEC命令时才会一起顺序执行。</p>
<blockquote>
<p>如果客户端发送的命令为 EXEC 、 DISCARD 、 WATCH 、 MULTI 四个命令的其中一个， 那么服务器立即执行这个命令。</p>
<p>与此相反， 如果客户端发送的命令是 EXEC 、 DISCARD 、 WATCH 、 MULTI 四个命令以外的其他命令， 那么服务器并不立即执行这个命令， 而是将这个命令放入一个事务队列里面， 然后向客户端返回 QUEUED 回复。</p>
<p>WATCH: 监视一个或多个key，如果事务在执行前，这个key(或多个key)被其他命令修改，则事务被中断，不会执行事务中的任何命令，此时EXEC执行结果为null。</p>
</blockquote>
<p>pipline主要用于批量发送命令，一次性发送多个请求，一次性读取所有返回结果，目的是为了减少 <code>连接-》发送命令 -》返回结果</code> 这个过程产生的耗时，减少IO次数，减少 read() 和 write() 的系统调用次数。</p>
<p>MULTI和EXEC事务机制与Redis pipline的区别：</p>
<ul>
<li>事务中的每个命令会先发送到服务端，只会再执行；而pipline是会把命令请求缓存在客户端本地内存中，再发送请求一次性执行</li>
<li>事务中的每个命令都会先发送到服务端，请求次数多，而pipline只发送一次请求</li>
<li>一般事务和pipline会配合使用，以减少请求次数，减少网络IO，提升性能，保证多个命令发送不会被别的请求打断，保证多个事务的隔离性，</li>
</ul>
<h2 id="redis中的原子性">Redis中的原子性</h2>
<ul>
<li>更多的是为了减少客户端与服务端的通信次数。Redis本身不提供回滚机制，如果一次性传输多个命令时，当有一个命令执行失败了，剩下的命令还是会继续往下执行，无法实现事务的原子性。</li>
<li>如果命令本身有错，只有到了EXEC命令时才会报错，整个MULTI期间的命令都不会执行，此时才保证了原子性。</li>
<li>RDB不会在事务执行的时候执行，所以可以保证原子性。</li>
<li>事务执行过程中的命令，AOF日志会记录，所以如果事务执行过程中宕机了，重启前需要使用<code>redis-check-aof工具</code>检查AOF日志，去除执行到一半的事务命令，才能保证原子性。</li>
</ul>
<p><strong>Redis中的原子操作</strong></p>
<ul>
<li>Redis的 incr / decr 命令，本质上是一个<code>读取 -》修改 -》写入</code> 的过程；</li>
<li>为Redis定义新的数据结构实现原子操作，毕竟Redis本身是单线程的，本身不会有其他线程的影响；</li>
<li>Lua脚本，才能实现复杂逻辑的原子操作，使用时会先通过script load命令把脚本加载到Redis中，得到唯一摘要，再通过命令evalsha + 摘要的方式执行脚本，避免每次执行脚本都要先传输，减少网络IO；另外Lua脚本的时间复杂度不易过长，否则会阻塞主线。</li>
</ul>
<p>Demo：限制客户端每分钟访问次数不能超过20次 的Lua脚本，该脚本包含了计数、访问次数判断和过期时间设置。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-lua" data-lang="lua"><span class="o">//</span> <span class="err">客户端先获取</span><span class="n">ip对应的访问次数</span>
<span class="n">current</span> <span class="o">=</span> <span class="n">redis.call</span><span class="p">(</span><span class="s2">&#34;get&#34;</span><span class="p">,</span> <span class="n">KEYS</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="o">//</span><span class="err">如果超过访问次数超过</span><span class="mi">20</span><span class="err">次，则报错，这两步不涉及临界值的修改，因此可以不放在脚本中原子执行。</span>
<span class="n">IF</span> <span class="n">current</span> <span class="err">!</span><span class="o">=</span> <span class="n">NULL</span> <span class="n">AND</span> <span class="n">current</span> <span class="o">&gt;</span> <span class="mi">20</span> <span class="n">THEN</span>
    <span class="n">ERROR</span> <span class="s2">&#34;exceed 20 accesses per second&#34;</span>

<span class="n">Lua脚本名称</span><span class="err">：</span><span class="n">visit_restrict.script</span>
<span class="err">脚本内容</span>
    <span class="o">//</span><span class="err">如果访问次数不足</span><span class="mi">20</span><span class="err">次，增加一次访问计数</span>
    <span class="n">value</span> <span class="o">=</span> <span class="n">redis.call</span><span class="p">(</span><span class="s2">&#34;incr&#34;</span><span class="p">,</span> <span class="n">KEYS</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="o">//</span><span class="err">如果是第一次访问，将键值对的过期时间设置为</span><span class="mi">60</span><span class="n">s后</span>
    <span class="n">IF</span> <span class="n">value</span> <span class="o">==</span> <span class="mi">1</span> <span class="n">THEN</span>
        <span class="n">redis.call</span><span class="p">(</span><span class="s2">&#34;expire&#34;</span><span class="p">,</span> <span class="n">KEYS</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">60</span><span class="p">)</span>
    <span class="n">END</span>
    <span class="o">//</span><span class="err">执行其他操作</span>
    <span class="n">DO</span> <span class="n">THINGS</span>
<span class="n">END</span>
<span class="err">执行命令：</span>
<span class="n">redis</span><span class="o">-</span><span class="n">cli</span> <span class="c1">--eval visit_restrict.script keys , args</span>
</code></pre></td></tr></table>
</div>
</div><h2 id="redis中的隔离性">Redis中的隔离性</h2>
<ul>
<li>需要依赖WATCH机制，因为Redis流水线命令是在EXEC命令执行后开始的，在EXEC命令还未执行前，如果要保证隔离性，需要使用WATCH监控某个key，当EXEC命令执行时，WATCH机制就会触发，如果监控的数据被修改了，就放弃此次事务的执行。</li>
<li>如果是在EXEC命令执行后的，由于Redis是单线程的，所以并发情况下不会破坏事务隔离性。</li>
</ul>
<p>因此调用方可以利用这个特性，不断的重试这个操作，知道成功为止。</p>
<p>使用Watch的实现监控：在使用MULTI命令之前使用WATCH监控某些键值对，然后使用MULTI命令开启事务，执行各种数据结构的操作命令，此时这些命令入队列；当使用EXEC执行事务时，首先会对比WATCH所监控的键值对，如果没有发生变化，它会执行事务队列中的命令，提交事务，如果发生变化，则不执行事务中的任何命令，同时事务回滚，然后取消执行事务前的WATCH命令。</p>
<h2 id="redis中的一致性">Redis中的一致性</h2>
<p>在命令执行错误或 Redis 发生故障的情况下，Redis 事务机制对一致性属性是有保证的。</p>
<h2 id="redis中的持久性">Redis中的持久性</h2>
<p>尽管有RDB和AOF日志的支持，但是仍然有丢数据的可能。比如使用RDB模式，在一个事务执行后，而下一次的 RDB 快照还未执行前，如果发生了实例宕机，此时，事务修改的数据也是不能保证持久化的。</p>
<h1 id="应用场景">应用场景</h1>
<h2 id="聚合统计---统计每日新增用户">聚合统计 - 统计每日新增用户</h2>
<ul>
<li>使用Set类型</li>
<li>一个Set记录所有登录过的用户ID：<code>[key：user:id，value：Set&lt;userId&gt;]</code>，另一个Set记录每日登录过的用户ID<code>[key：user:id :日期，value：Set&lt;userId&gt;]</code></li>
<li>统计每日新增用户，计算每日用户 Set 和累计用户 Set 的差集，使用命令<code>SDIFFSTORE [结果key] [user:id :日期] [user:id]</code></li>
<li>弊端：Set的差集、并集、交集计算复杂度较高，当数据量较大时计算太慢会阻塞主线程，一般这种计算会在从库上做。</li>
</ul>
<h2 id="排序统计---统计最新评论排行榜时间段内在线数等">排序统计 - 统计最新评论、排行榜、时间段内在线数等</h2>
<ul>
<li>使用List，当有新元素LPush或RPush插入时，原先所有元素都会后移一位，使用Lrange读取元素时可能会读到旧数据。</li>
<li>使用ZSet，为每个元素设置权重，按权重排序，使用Zrangebyscore则不会读到旧数据。</li>
</ul>
<h2 id="二值状态统计---统计是否签到存不存在有没有问题">二值状态统计 - 统计是否签到、存不存在、有没有问题</h2>
<ul>
<li>针对值只有0 或1的场景，使用bitmap，是Redis的扩展数据类型，本身是String类型的一种特殊应用。</li>
<li>bitmap利用的是存储的String value的位。并且bitmap支持Bitop命令对多个bitmap进行按位与、或、异或操作，bitcount统计位中1的个数。</li>
</ul>
<h2 id="基数统计---统计一个集合中不重复的元素">基数统计 - 统计一个集合中不重复的元素</h2>
<ul>
<li>使用Set或Hash，但是可能会比较耗内存</li>
<li>使用HyperLogLog，专门用于基数统计，优势在于所需空间总是固定，使用<code>PFAdd key v1 v2 v3</code>命令做添加，<code>PFCount key</code>统计key的value数量，但是存在误差，误差率约为0.81%</li>
<li>一般用于统计注册的IP数、每日访问IP数、页面实时UV数、在线用户数、搜索的关键词数</li>
</ul>
<h2 id="geo---lbs应用">GEO - LBS应用</h2>
<ul>
<li>
<p>底层实现是ZSet，权重值是经纬度，但是由于ZSet的权重值只能是浮点类型，因此一般会对经纬度做GeoHash编码。</p>
</li>
<li>
<p>GeoHash编码的基本原理是：二分区间，区间编码。</p>
<ul>
<li>
<p>二分区间：比如把经度范围[-180,180]会被分成两个子区间：[-180,0) 和[0,180]，如果要编码的经度值落在左区间，则用0表示，右区间用1表示，通过不断的对区间进行分区，经过N次之后，得到一个N位数的01组合。纬度同理。</p>
<p>比如有一个点（39.923201，116.390705），以纬度为例，（-90，90）中间值为0，39.923201在（0，90）得到1，（0，90）的中间值是45，在（0，45）得到0，继续对分区进行二分和比较，最终得到一个二进制数，经度也是以同样的方式进行计算</p>
</li>
<li>
<p>区间编码：把计算过后的经纬度编码进行组合，规则：偶数位是经度编码值，奇数位是纬度编码值。</p>
</li>
<li>
<p>base32进行编码</p>
</li>
</ul>
</li>
<li>
<p>通过GeoHash编码，地图上的每个方格都能用数字进行表示，分区越多越精准。<strong>通过范围查询 + 方格周围方格的编码，即可实现搜索附近的人功能</strong>。</p>
</li>
<li>
<p>GeoHash表示一个矩形的区域，精度取决于二分的次数，次数越多越精确，经过base32编码后得到一个字符串，编码越长，范围越小，位置更精确；两个相同前缀的字符串，长度越短表示范围更大，可以通过此特性来表示两个点之间的大概距离。</p>
</li>
<li>
<p>Redis也提供了Geo的数据类型</p>
</li>
</ul>
<h2 id="保存时间序列数据">保存时间序列数据</h2>
<ul>
<li>时间序列数据的特点是插入速度要快，数据一旦插入就不变、查询模式较多。</li>
<li>可以基于Hash和ZSet实现。Hash实现插入快速和点查询，ZSet实现范围查询，但由于插入一条数据的时候需要同时操作Hash和ZSet，因此要求这个操作是原子的。</li>
<li>ZSet只能提供范围查询，聚合查询只能在让客户端查回去之后自己做，但是大量数据查询传输比较依赖网络资源，可能会导致其他操作响应速度变慢，如果想要Redis实现的话，就得依靠RedisTimeSeries。</li>
</ul>
<h2 id="消息队列">消息队列</h2>
<ul>
<li>
<p>消息队列一般要解决三个问题：顺序消费、幂等消费、消息可靠性保证</p>
</li>
<li>
<p>使用List</p>
<ul>
<li>List的每个元素除了消息的内容外还要保存消息的唯一id，用于解决重复性消费；</li>
<li>List类型有提供BRPOP供消费者阻塞读取，避免循环读取带来的消耗；</li>
<li>List类型有提供BRPOPLPUSH命令，让消费者读取时会把数据存入另一备份List中，用于避免消费者从List中移除消息读取时宕机，重启后可重新读取消息。</li>
<li>List不支持消费组实现，无法避免生产速度大于消费速度的场景。</li>
<li>通过 BLPOP 命令，在没有消息的时候，它会一直阻塞，直至有消息到来。</li>
</ul>
</li>
<li>
<p>实现延迟队列：</p>
<ul>
<li>使用ZSet，拿时间戳当score，调用ZADD命令生产消息，ZRANGEBYSOCRE命令获取N秒前的数据进行轮询处理。</li>
</ul>
</li>
<li>
<p>使用Stream类型，解决多端消费问题。</p>
<ul>
<li>Stream的XADD命令，可以为其生成全局唯一ID。</li>
<li>读取时使用命令XRead，可支持指定ID读取，也支持超时阻塞读取。</li>
<li>命令XGroup创建消费组，XREADGROUP指定组内哪个消费者进行消费。</li>
<li>Streams 会自动使用内部队列（也称为 PENDING List）留存消费组里每个消费者读取的消息，直到消费者使用 XACK 命令进行回复。如果消费不成功，它就不会给 Streams 发送 XACK 命令，消息仍然会留存。当消费者重启后，用 XPENDING 命令查看已读取、但尚未确认处理完成的消息。</li>
<li>Stream是Redis5.0以后才有的专门用来处理消息队列的。</li>
</ul>
</li>
</ul>
<h1 id="缓存可能引发的问题以及应对方法">缓存可能引发的问题以及应对方法</h1>
<p>使用Redis来构建缓存有两种模式</p>
<ul>
<li>只读缓存：加速读请求。应用读取数据，先向Redis查询，查不到再查库，然后保存到缓存中。应用写数据，先改库，删掉旧缓存数据。这种方式可以很好的保证了一致性。</li>
<li>读写缓存：同时加速读写请求。读写都会在缓存里发生，最新的数据是在Redis中，但需要严重依赖Redis的持久化。这种方式对一致性的保证就差了点，特别是在高并发下。
<ul>
<li>同步直写：优先保证数据可靠。写请求会同时修改缓存和库，等到都完成了才返回，需要保证原子性。</li>
<li>异步写回：优先保证快速响应。写请求会先在缓存中处理，等到这些增改数据要从缓存中淘汰，才会写回数据库。</li>
</ul>
</li>
</ul>
<h2 id="缓存雪崩">缓存雪崩</h2>
<p>现象：缓存大面积失效导致请求到达数据库</p>
<p>应对方案：</p>
<ul>
<li>缓存过期时间设置均匀，不能让一大片缓存在某一时间全部失效，比如设置过期时间时加入随机数，让过期时间在一个范围内波动。</li>
<li>请求时加锁(比如利用redission的rlock)，后续请求只能等到前面的查完数据库，进行缓存后，才能继续，但会造成吞吐量降低，响应时间变长，或者可以使用semaphore设置一定的信号量，不至于只有一个请求去回源数据库。</li>
<li>不设置key的过期时间，另开一个定时任务定期全量更新缓存；或者定时任务定期扫描，将快要过期的key延迟过期时间；设置多级缓存。</li>
<li>灰度发布，对缓存进行预热。</li>
<li>服务降级，当访问的数据是非核心数据，直接返回预定义数据或空值；当访问的数据是核心数据，仍允许查缓存，查库。</li>
<li>缓存标记，比如，给数据设置缓存过期时间为60分钟，标记缓存过期时间为30分钟，当时间超过缓存标记时间后，触发缓存更新，但此时实际缓存还能返回旧数据，直到缓存更新完成，才会返回新缓存。</li>
<li>如果是Redis实例发生宕机，只能在应用层中实现服务熔断或请求限流。</li>
</ul>
<h2 id="缓存击穿">缓存击穿</h2>
<p>现象：大量请求访问热点数据时，但<strong>热点数据刚好过期</strong>，此时请求击穿缓存层，直接到达数据库</p>
<p>应对方案：</p>
<ul>
<li>不给热点数据的缓存设置过期时间，一直保留，或者热点数据快要到期前，异步刷新缓存，重新设置过期时间。</li>
<li>使用互斥锁或者信号量，当有大量请求访问一个过期的热点数据时，只有一定数量的请求会到达数据库查询数据并缓存，其他请求等待缓存加载即可。</li>
</ul>
<h2 id="缓存穿透">缓存穿透</h2>
<p>现象：<strong>查询一个一定不存在的数据</strong>，导致请求一直到达数据库，数据也不在数据库中。</p>
<p>应对方案：</p>
<ul>
<li>使用布隆过滤器，将可能出现查询的值哈希到一个bitMap中，进行拦截，虽然布隆过滤有一定的误报几率，但也能一定程度的减少穿透的影响，常见的方案是配合2一起降低穿透带来的影响。</li>
<li>如果查询结果为空，也加入缓存中（可以直接设置为空，或者使用特殊标识来表示），并设置过期时间。</li>
<li>通过异步更新服务 + 消息队列的方式进行全量缓存的更新。缓存的设置还是照旧，只是当有数据更新时，触发消息交给消息队列，再由异步更新服务消费消息，实现缓存更新。</li>
<li>利用数据库的Bin Log，当数据库执行更新操作时，从数据库接收到Bin Log之后根据Bin Log更新Redis缓存，道理跟消息队列类似，只是不用担心消息发送失败问题。</li>
<li>前端预防，对请求进行检测。</li>
</ul>
<h2 id="缓存无底洞">缓存无底洞</h2>
<p>现象：增加缓存节点，性能不升反降，原因是客户端要维护大量的连接，如果key分布在不同机器，需要查多次</p>
<p>应对方案：</p>
<ul>
<li>减少网络请求，能批量查尽量批量查</li>
<li>将key进行分类，存到指定节点，查询同类的key时只需要特定的节点去查</li>
<li>并发查询</li>
</ul>
<h2 id="缓存污染">缓存污染</h2>
<p>现象：对于那些访问次数很少的数据，一直留存在缓存中，占用缓存空间。</p>
<p>应对方案：Redis的淘汰策略，一般会使用LRU、LFU、TTL的淘汰策略。</p>
<h2 id="主动更新缓存要注意的点">主动更新缓存要注意的点</h2>
<ol>
<li>
<p>不推荐先更新缓存再更新数据库（也称 Write Behind Caching 模式，更新数据时，只更新缓存，异步 / 同步 更新数据库）原因是数据库操作可能失败，导致缓存与数据库不一致；</p>
<p>这个模式也有点像Linux的PageCache算法，好处是因为直接操作内存，异步，write back可以合并同一个数据的多次操作，IO性能极高，但因为要保证数据一致性，write back的实现就会很复杂，它需要知道哪些数据被更新了，然后还要持久化到磁盘上，比如操作系统的write back仅会在当这个缓存需要失效、内存不够、进程退出时，才会真正持久化。</p>
</li>
<li>
<p>不推荐先更新数据库再更新缓存（也称 Write Through 模式），原因是当AB两个操作同时写，两者的操作顺序无法保证，导致数据不一致，即并发写导致脏数据；另外，更新到缓存的数据也不一定被访问；</p>
</li>
<li>
<p>不推荐先删缓存再更新数据库，访问时再进行加载，原因是并发情况下，删除缓存后来不及更新数据库，但旧值已经被其他线程读到了，更新到缓存了；或者数据库操作失败了，但缓存已经没了，导致其他请求还要再读一次数据库，应对的方案是延迟双删：<code>先删缓存 -》更新数据库 -》sleep -》再删除缓存</code></p>
</li>
<li>
<p>推荐先更新数据库再删除缓存（也称为Cache Aside 模式），访问时再进行加载，虽然也可能出现3中的情况，比如读缓存时缓存失效，紧接着一个并发写操作，就有可能出现读操作覆盖了写操作后的数据更新，导致数据不一致，但实际上发生的概率不大，带来的影响会相对小一些，因为写操作通常会比读操作慢，再加上要锁表，而读操作必须在写操作前进入数据库操作，而又要晚于写操作更新缓存，条件就很苛刻了。</p>
<p>如果删除缓存失败了，可以延迟任务进行删除重试，因为删除操作一般是幂等的，所以即使重复删除也没关系，另外，相比Read/Write Through模式（更新数据库后更新缓存操作），不会因为并发读写产生脏数据。还有由于会删除缓存，所以要注意缓存击穿问题。</p>
<p>另外，即使使用了先更新数据库再删除缓存的模式，在主从同步延迟的场景也会导致不一致(对于其他模式也是)，解决方案仍然是延迟双删，只是sleep的时间最好等于延迟时间；</p>
<p>如果还要强一致，就只能使用2PC、3PC、Raft之类的一致性协议或者分布式锁等方案来解决了，但是性能就保证不了了；</p>
</li>
<li>
<p>另外的方案是利用数据库的能力 + 消息队列的方式，如根据MySQL的Bin log来更新缓存；</p>
</li>
</ol>
<p><figure 
	>
	<a href="https://github.com/Nixum/Java-Note/raw/master/picture/Redis%e7%bc%93%e5%ad%98%e6%96%b9%e6%a1%88%e6%93%8d%e4%bd%9c.png" >
		<img src="https://github.com/Nixum/Java-Note/raw/master/picture/Redis%e7%bc%93%e5%ad%98%e6%96%b9%e6%a1%88%e6%93%8d%e4%bd%9c.png"
			
			
			
			loading="lazy"
			alt="Redis缓存方案操作 - 极客时间Redis核心技术与实战">
	</a>
	
	<figcaption>Redis缓存方案操作 - 极客时间Redis核心技术与实战</figcaption>
	
</figure></p>
<h1 id="参考">参考</h1>
<p>极客时间 - Redis核心技术与实战：讲得很不错，推荐。</p>
<p>还有其他看过的别人博客，但是当时忘记把链接贴下来。</p>

</section>


    <footer class="article-footer">
    
    <section class="article-tags">
        
            <a href="/tags/redis/">Redis</a>
        
            <a href="/tags/%E4%B8%BB%E4%BB%8E%E6%9E%B6%E6%9E%84/">主从架构</a>
        
            <a href="/tags/%E7%BC%93%E5%AD%98/">缓存</a>
        
    </section>


    
    <section class="article-copyright">
        <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="12" cy="12" r="9" />
  <path d="M14.5 9a3.5 4 0 1 0 0 6" />
</svg>



        <span>Licensed under CC BY-NC-SA 4.0</span>
    </section>
    </footer>


    
        <link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/katex@0.13.13/dist/katex.min.css"integrity="sha384-RZU/ijkSsFbcmivfdRBQDtwuwVqK7GMOw6IMvKyeWL2K5UAlyp6WonmB8m7Jd0Hn"crossorigin="anonymous"
            ><script 
                src="https://cdn.jsdelivr.net/npm/katex@0.13.13/dist/katex.min.js"integrity="sha384-pK1WpvzWVBQiP0/GjnvRxV4mOb0oxFuyRxJlk6vVw146n3egcN5C925NCP7a7BY8"crossorigin="anonymous"
                defer="true"
                >
            </script><script 
                src="https://cdn.jsdelivr.net/npm/katex@0.13.13/dist/contrib/auto-render.min.js"integrity="sha384-vZTG03m&#43;2yp6N6BNi5iM4rW4oIwk5DfcNdFfxkk9ZWpDriOkXX8voJBFrAO7MpVl"crossorigin="anonymous"
                defer="true"
                >
            </script><script>
    window.addEventListener("DOMContentLoaded", () => {
        renderMathInElement(document.querySelector(`.article-content`), {
            delimiters: [
                { left: "$$", right: "$$", display: true },
                { left: "$", right: "$", display: false },
                { left: "\\(", right: "\\)", display: false },
                { left: "\\[", right: "\\]", display: true }
            ]
        });})
</script>
    
</article>

    

    <aside class="related-contents--wrapper">
    
    
        <h2 class="section-title">Related contents</h2>
        <div class="related-contents">
            <div class="flex article-list--tile">
                
                    
<article class="">
    <a href="/p/mongodb/">
        
        

        <div class="article-details">
            <h2 class="article-title">MongoDB</h2>
        </div>
    </a>
</article>
                
                    
<article class="">
    <a href="/p/mysql/">
        
        

        <div class="article-details">
            <h2 class="article-title">MySQL</h2>
        </div>
    </a>
</article>
                
            </div>
        </div>
    
</aside>

     
    
        
    <script src="https://utteranc.es/client.js" 
        repo="Nixum/blog"
        issue-term="pathname"
        
        crossorigin="anonymous"
        async
        >
</script>

<style>
    .utterances {
        max-width: unset;
    }
</style>

<script>
    function setUtterancesTheme(theme) {
        let utterances = document.querySelector('.utterances iframe');
        if (utterances) {
            utterances.contentWindow.postMessage(
                {
                    type: 'set-theme',
                    theme: `github-${theme}`
                },
                'https://utteranc.es'
            );
        }
    }

    addEventListener('message', event => {
        if (event.origin !== 'https://utteranc.es') return;
        setUtterancesTheme(document.documentElement.dataset.scheme)
    });

    window.addEventListener('onColorSchemeChange', (e) => {
        setUtterancesTheme(e.detail)
    })
</script>


    

    <footer class="site-footer">
    <section class="copyright">
        &copy; 
        
            2020 - 
        
        2025 Nixum Blog
    </section>
    
    <section class="powerby">
        Built with <a href="https://gohugo.io/" target="_blank" rel="noopener">Hugo</a> <br />
        Theme <b><a href="https://github.com/CaiJimmy/hugo-theme-stack" target="_blank" rel="noopener" data-version="3.6.0">Stack</a></b> designed by <a href="https://jimmycai.com" target="_blank" rel="noopener">Jimmy</a>
    </section>
</footer>


    
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    
    <div class="pswp__bg"></div>

    
    <div class="pswp__scroll-wrap">

        
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                
                
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div><script 
                src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js"integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo="crossorigin="anonymous"
                defer="true"
                >
            </script><script 
                src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js"integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU="crossorigin="anonymous"
                defer="true"
                >
            </script><link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.css"integrity="sha256-c0uckgykQ9v5k&#43;IqViZOZKc47Jn7KQil4/MP3ySA3F8="crossorigin="anonymous"
            ><link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.css"integrity="sha256-SBLU4vv6CA6lHsZ1XyTdhyjJxCjPif/TRkjnsyGAGnE="crossorigin="anonymous"
            >

            </main>
    
        <aside class="sidebar right-sidebar sticky">

            <section class="widget archives">
                <form action="/search/" class="search-form widget" >
        <p>
            <label>Search</label>
            <input name="keyword" required placeholder="Type something..." />
        
            <button title="Search">
                <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="10" cy="10" r="7" />
  <line x1="21" y1="21" x2="15" y2="15" />
</svg>



            </button>
        </p>
    </form>
            </section>

            <section class="widget archives">
                <h2 class="widget-title section-title">Contents</h2>

                <div class="widget--toc">
                    <nav id="TableOfContents">
  <ol>
    <li><a href="#数据类型及结构">数据类型及结构</a>
      <ol>
        <li><a href="#数据类型">数据类型</a></li>
        <li><a href="#底层数据结构">底层数据结构</a>
          <ol>
            <li><a href="#简单动态字符串---sds">简单动态字符串 - SDS</a></li>
            <li><a href="#哈希表---dict">哈希表 - Dict</a>
              <ol>
                <li><a href="#rehash触发条件">rehash触发条件</a></li>
                <li><a href="#rehash过程">rehash过程</a></li>
                <li><a href="#底层的两种实现">底层的两种实现</a></li>
              </ol>
            </li>
            <li><a href="#压缩列表---ziplist">压缩列表 - ZipList</a></li>
            <li><a href="#快表---quick-list">快表 - Quick List</a></li>
            <li><a href="#跳表---skip-list">跳表 - Skip List</a></li>
            <li><a href="#时间复杂度">时间复杂度</a></li>
          </ol>
        </li>
      </ol>
    </li>
    <li><a href="#与memcached的区别">与Memcached的区别</a></li>
    <li><a href="#redis的线程模型">Redis的线程模型</a>
      <ol>
        <li><a href="#单线程模型">单线程模型</a></li>
        <li><a href="#多线程模型">多线程模型</a></li>
        <li><a href="#影响性能的场景">影响性能的场景</a></li>
        <li><a href="#使用规范和优化">使用规范和优化</a></li>
        <li><a href="#监控">监控</a></li>
      </ol>
    </li>
    <li><a href="#过期时间和数据淘汰策略">过期时间和数据淘汰策略</a>
      <ol>
        <li><a href="#key过期删除原理">key过期删除原理</a></li>
        <li><a href="#淘汰策略">淘汰策略</a>
          <ol>
            <li><a href="#淘汰策略中的lru算法">淘汰策略中的LRU算法</a></li>
            <li><a href="#淘汰策略中的lfu算法">淘汰策略中的LFU算法</a></li>
            <li><a href="#淘汰执行时机">淘汰执行时机</a></li>
          </ol>
        </li>
      </ol>
    </li>
    <li><a href="#存储与持久化">存储与持久化</a>
      <ol>
        <li><a href="#rdb快照redis-database">RDB快照（Redis DataBase）</a>
          <ol>
            <li><a href="#相关命令和配置">相关命令和配置</a></li>
            <li><a href="#原理">原理</a></li>
            <li><a href="#优点">优点</a></li>
            <li><a href="#潜在风险">潜在风险</a></li>
          </ol>
        </li>
        <li><a href="#aofappend-only-file">AOF（Append Only File）</a>
          <ol>
            <li><a href="#相关命令和配置-1">相关命令和配置</a></li>
            <li><a href="#原理-1">原理</a></li>
            <li><a href="#潜在风险-1">潜在风险</a></li>
            <li><a href="#重写机制">重写机制</a>
              <ol>
                <li><a href="#原理-2">原理</a></li>
                <li><a href="#潜在风险-2">潜在风险</a></li>
              </ol>
            </li>
          </ol>
        </li>
      </ol>
    </li>
    <li><a href="#高可用集群">高可用集群</a>
      <ol>
        <li><a href="#主从复制---保证数据一致性">主从复制 - 保证数据一致性</a>
          <ol>
            <li><a href="#相关命令">相关命令</a></li>
            <li><a href="#过程">过程</a></li>
          </ol>
        </li>
        <li><a href="#主从库命令传播时网络中断">主从库命令传播时网络中断</a></li>
        <li><a href="#哨兵机制">哨兵机制</a>
          <ol>
            <li><a href="#原理-3">原理</a></li>
            <li><a href="#如何监控如何判断主库不可用">如何监控，如何判断主库不可用</a></li>
            <li><a href="#如何选举">如何选举</a></li>
            <li><a href="#如何通知">如何通知</a></li>
            <li><a href="#主从切换时可能产生脑裂">主从切换时，可能产生脑裂</a></li>
            <li><a href="#哨兵集群的高可用">哨兵集群的高可用</a>
              <ol>
                <li><a href="#哨兵节点间与主从库间的相互发现机制">哨兵节点间、与主从库间的相互发现机制</a></li>
                <li><a href="#哨兵节点leader选举原理">哨兵节点Leader选举原理</a></li>
              </ol>
            </li>
          </ol>
        </li>
        <li><a href="#几个注意点">几个注意点</a></li>
      </ol>
    </li>
    <li><a href="#高可用扩展集群">高可用扩展集群</a>
      <ol>
        <li><a href="#扩展">扩展</a></li>
        <li><a href="#分片">分片</a>
          <ol>
            <li><a href="#原理-4">原理</a></li>
          </ol>
        </li>
      </ol>
    </li>
    <li><a href="#事务">事务</a>
      <ol>
        <li><a href="#redis中的原子性">Redis中的原子性</a></li>
        <li><a href="#redis中的隔离性">Redis中的隔离性</a></li>
        <li><a href="#redis中的一致性">Redis中的一致性</a></li>
        <li><a href="#redis中的持久性">Redis中的持久性</a></li>
      </ol>
    </li>
    <li><a href="#应用场景">应用场景</a>
      <ol>
        <li><a href="#聚合统计---统计每日新增用户">聚合统计 - 统计每日新增用户</a></li>
        <li><a href="#排序统计---统计最新评论排行榜时间段内在线数等">排序统计 - 统计最新评论、排行榜、时间段内在线数等</a></li>
        <li><a href="#二值状态统计---统计是否签到存不存在有没有问题">二值状态统计 - 统计是否签到、存不存在、有没有问题</a></li>
        <li><a href="#基数统计---统计一个集合中不重复的元素">基数统计 - 统计一个集合中不重复的元素</a></li>
        <li><a href="#geo---lbs应用">GEO - LBS应用</a></li>
        <li><a href="#保存时间序列数据">保存时间序列数据</a></li>
        <li><a href="#消息队列">消息队列</a></li>
      </ol>
    </li>
    <li><a href="#缓存可能引发的问题以及应对方法">缓存可能引发的问题以及应对方法</a>
      <ol>
        <li><a href="#缓存雪崩">缓存雪崩</a></li>
        <li><a href="#缓存击穿">缓存击穿</a></li>
        <li><a href="#缓存穿透">缓存穿透</a></li>
        <li><a href="#缓存无底洞">缓存无底洞</a></li>
        <li><a href="#缓存污染">缓存污染</a></li>
        <li><a href="#主动更新缓存要注意的点">主动更新缓存要注意的点</a></li>
      </ol>
    </li>
    <li><a href="#参考">参考</a></li>
  </ol>
</nav>
                </div>
            </section>

            <section class="widget archives">
                <h2 class="widget-title section-title">Other Article Tags</h2>
                <section class="widget tagCloud">
    <div class="tagCloud-tags">
        
            <a href="/tags/%E4%B8%BB%E4%BB%8E%E6%9E%B6%E6%9E%84/" class="font_size_3">
                主从架构
            </a>
        
            <a href="/tags/javase/" class="font_size_2">
                JavaSE
            </a>
        
            <a href="/tags/%E4%B8%9A%E5%8A%A1/" class="font_size_2">
                业务
            </a>
        
            <a href="/tags/%E6%80%BB%E7%BB%93/" class="font_size_2">
                总结
            </a>
        
            <a href="/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/" class="font_size_2">
                数据库
            </a>
        
            <a href="/tags/%E6%95%B0%E6%8D%AE%E5%BA%93-%E9%94%81/" class="font_size_2">
                数据库-锁
            </a>
        
            <a href="/tags/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BA%8B%E5%8A%A1/" class="font_size_2">
                数据库事务
            </a>
        
            <a href="/tags/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/" class="font_size_2">
                数据库优化
            </a>
        
            <a href="/tags/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/" class="font_size_2">
                系统设计
            </a>
        
            <a href="/tags/%E7%B4%A2%E5%BC%95/" class="font_size_2">
                索引
            </a>
        
            <a href="/tags/%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/" class="font_size_2">
                解决方案
            </a>
        
            <a href="/tags/ai/" class="font_size_1">
                AI
            </a>
        
            <a href="/tags/context%E5%8E%9F%E7%90%86/" class="font_size_1">
                context原理
            </a>
        
            <a href="/tags/docker/" class="font_size_1">
                docker
            </a>
        
            <a href="/tags/etcd/" class="font_size_1">
                etcd
            </a>
        
            <a href="/tags/git/" class="font_size_1">
                git
            </a>
        
            <a href="/tags/go/" class="font_size_1">
                Go
            </a>
        
            <a href="/tags/go-channel%E5%8E%9F%E7%90%86/" class="font_size_1">
                Go channel原理
            </a>
        
            <a href="/tags/go-gc/" class="font_size_1">
                Go GC
            </a>
        
            <a href="/tags/go-gin%E5%8E%9F%E7%90%86/" class="font_size_1">
                Go Gin原理
            </a>
        
            <a href="/tags/go-slice%E5%92%8Cmap%E5%8E%9F%E7%90%86/" class="font_size_1">
                Go slice和map原理
            </a>
        
            <a href="/tags/go-sync%E5%8C%85/" class="font_size_1">
                Go sync包
            </a>
        
            <a href="/tags/goroutine/" class="font_size_1">
                Goroutine
            </a>
        
            <a href="/tags/go%E5%B9%B6%E5%8F%91/" class="font_size_1">
                Go并发
            </a>
        
            <a href="/tags/http/" class="font_size_1">
                HTTP
            </a>
        
            <a href="/tags/ioc%E5%92%8Caop/" class="font_size_1">
                IOC和AOP
            </a>
        
            <a href="/tags/istio/" class="font_size_1">
                Istio
            </a>
        
            <a href="/tags/java-bio/" class="font_size_1">
                Java BIO
            </a>
        
            <a href="/tags/java-gc/" class="font_size_1">
                Java GC
            </a>
        
            <a href="/tags/java-nio/" class="font_size_1">
                Java NIO
            </a>
        
            <a href="/tags/java%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B/" class="font_size_1">
                Java内存模型
            </a>
        
            <a href="/tags/java%E5%B9%B6%E5%8F%91/" class="font_size_1">
                Java并发
            </a>
        
            <a href="/tags/java%E9%9B%86%E5%90%88%E7%B1%BB%E5%8E%9F%E7%90%86/" class="font_size_1">
                Java集合类原理
            </a>
        
            <a href="/tags/juc/" class="font_size_1">
                JUC
            </a>
        
            <a href="/tags/jvm/" class="font_size_1">
                JVM
            </a>
        
            <a href="/tags/jwt/" class="font_size_1">
                JWT
            </a>
        
            <a href="/tags/kubernetes/" class="font_size_1">
                Kubernetes
            </a>
        
            <a href="/tags/linux/" class="font_size_1">
                Linux
            </a>
        
            <a href="/tags/mongodb/" class="font_size_1">
                MongoDB
            </a>
        
            <a href="/tags/mysql/" class="font_size_1">
                MySQL
            </a>
        
            <a href="/tags/netty/" class="font_size_1">
                Netty
            </a>
        
            <a href="/tags/orm/" class="font_size_1">
                ORM
            </a>
        
            <a href="/tags/rag/" class="font_size_1">
                RAG
            </a>
        
            <a href="/tags/redis/" class="font_size_1">
                Redis
            </a>
        
            <a href="/tags/rpc/" class="font_size_1">
                RPC
            </a>
        
            <a href="/tags/select%E5%8E%9F%E7%90%86/" class="font_size_1">
                select原理
            </a>
        
            <a href="/tags/session%E5%92%8Ccookie/" class="font_size_1">
                session和cookie
            </a>
        
            <a href="/tags/socket/" class="font_size_1">
                socket
            </a>
        
            <a href="/tags/spring/" class="font_size_1">
                Spring
            </a>
        
            <a href="/tags/spring-security/" class="font_size_1">
                Spring Security
            </a>
        
    </div>
</section>
            </section>

        </aside>
    

        </div>
        <script 
                src="https://cdn.jsdelivr.net/npm/node-vibrant@3.1.5/dist/vibrant.min.js"integrity="sha256-5NovOZc4iwiAWTYIFiIM7DxKUXKWvpVEuMEPLzcm5/g="crossorigin="anonymous"
                defer="false"
                >
            </script><script type="text/javascript" src="/ts/main.js" defer></script>
<script>
    (function () {
        const customFont = document.createElement('link');
        customFont.href = "https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap";

        customFont.type = "text/css";
        customFont.rel = "stylesheet";

        document.head.appendChild(customFont);
    }());
</script>


    </body>
</html>
