<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>AI on Nixum Blog</title>
    <link>http://nixum.cc/tags/ai/</link>
    <description>Recent content in AI on Nixum Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 22 Jun 2024 00:00:00 +0000</lastBuildDate><atom:link href="http://nixum.cc/tags/ai/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>向量数据库在 RAG 中的应用</title>
      <link>http://nixum.cc/p/%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E5%9C%A8-rag-%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/</link>
      <pubDate>Sat, 22 Jun 2024 00:00:00 +0000</pubDate>
      
      <guid>http://nixum.cc/p/%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E5%9C%A8-rag-%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/</guid>
      <description>[TOC]
一、理解几个基本概念 https://www.bilibili.com/video/BV1CVAUeuECE?spm_id_from=333.788.videopod.sections&amp;vd_source=a870d050aec1403366ebea0f42b4cdaf
https://www.bilibili.com/video/BV1smXUYSEGi/?spm_id_from=333.1387.upload.video_card.click&amp;vd_source=a870d050aec1403366ebea0f42b4cdaf
https://www.bilibili.com/video/BV1bfoQYCEHC/?spm_id_from=333.1387.upload.video_card.click&amp;vd_source=a870d050aec1403366ebea0f42b4cdaf
https://www.bilibili.com/video/BV1CpAnebEpJ/?spm_id_from=333.1387.upload.video_card.click&amp;vd_source=a870d050aec1403366ebea0f42b4cdaf
二、GPT的局限性 虽然目前ChatGPT等大语言模型已经十分好用了，无论是响应速度和回答的质量，基本上能解决我们日常一些问题和简单的工作，但不可否认，目前的大语言模型仍然有很多缺陷，比如：
  回答幻觉：大语言模型回答问题的本质上是基于其已有的训练数据，预测(概率计算)出哪些可能的文字作为答案，所以难免会出现张冠李戴、胡说八道的情况，特别是在大模型不擅长的领域。
最典型的比如你在 ChatGPT-3.5问他“西红柿炒钢丝球要怎么做“，它会十分正经的回答出让人哭笑不得的答案，又或者问一些代码问题，它有时会回答出一些不存在的语法或者方法的调用，产生不正确的答案；
  上下文限制：由于硬件限制和模型底层架构限制，上下文越长，计算时，其内存需求、计算量等会剧增，硬件资源难以负荷，另外，Transformer架构在处理长序列时，如果信息距离太远，会出现信息稀释或丢失，导致生成的内容连贯性和准确性降低，因此大模型都会限制上下文的长度，以保证生成的结果。
比如Chat GPT-3.5 Turbo的上下文限制是4K tokens（大概3000字），GPT-4 Turbo的上下文限制是128K tokens（大概9.6万字），这意味着其最多只能处理（记忆）这么多字的内容，且随着处理的上下文越多，响应速度也会越来越慢，成本越来越高；
  训练的语料更新不够及时：比如Chat GPT-3.5 Turbo训练的语料库只记录了2021年9月之前的数据，GPT-4 Turbo则是2023年4月，这意味着在此之后产生的数据模型是不知道的；
  在某些领域还不够专业：比如某些垂直领域的训练语料往往比较封闭，不对外公开，又或者是企业的内部数据，处于对数据的安全性的考量，并不希望上传到第三方平台进行训练，大模型无法获取这些数据进行训练，此时只依赖通用大模型的能力，回答的质量就会大打折扣；
  为了优化上述问题，提升大语言模型回答的质量，其中一种解决方案就是外挂一个知识库，在提问时先根据问题，检索出相关更加准确且核心的资料，指导大语言模型生成更加准确的答案。
二、RAG的基本原理 下面是一个最简单的RAG基本流程：
 
阶段一  结构化数据并进行文本分割：将大量文档（可能是pdf、word、文本、网页等等）进行结构化，统一数据结构，分割成多个文本块； 将文本块向量化：使用Embedding模型，将分割后的文本块转换成向量，通过向量将不同文本块进行关联； 存入向量数据库：将向量以及对应的文本块（元数据），选择合适的算法，存入到向量数据库中；  阶段二  用户提问向量化：用户提出问题时，使用阶段一中相同的Embedding模型，将问题转成向量； 检索召回：将问题转换后的向量，在向量数据库中进行检索，选择合适的算法，计算向量间的距离，得到与之相似的向量以及对应的文本块； 提示词增强：将用户的问题以及上一步检索到的文本数据，进行提示词优化，构建出最终的提示词，发送给大模型，由大模型生成最终的结果并返回；  核心步骤 在上面整个流程中，有几个核心步骤决定了最终RAG的质量，包括后续的优化，也是从这三个步骤入手：
  文本的处理和索引：如何更好的把文本数据存起来
文本分割的目的，一个是因为解决大模型输入长度的限制，另一个在保持语义连贯的同时，减少嵌入内容的噪声，更加有效的检索到用户问题更相关的文本资料；
怎么分割是一个取舍的问题，如果分块太大，可能会导致分块包含了太多信息，降低检索的准确性，分块太小又可能会丢失必要的上下文信息，导致最终生成的回答缺乏连贯性或深度；
分割后的文本最终需要被检索，因此需要将文本转换为向量，这也依赖embedding模型的能力，而embedding模型的训练语料、参数的数量级，决定了转换出来的向量的关联性，最终影响文本间的语义相似度；
  检索与召回：如何在大量的文本数据中，找到一小部分有用的数据，给到模型参考
向量和对应文本的存储和检索，又依赖向量数据库，需要解决不同数量级维度的向量要如何存储，如何才能快速计算其相似度，快速精确的定位和检索数据的问题，甚至为了进一步提升检索的质量，除了需要提供相似度检索，还需要提供传统的关键字检索等；
单纯的向量召回存在精度问题，因此可能需要多种召回的方式，比如分词召回、图谱召回等，对于召回出来的数据，可能还需要进一步的处理，进行各种去重、合并和重排等，检索出到更加精确的数据；
  内容的生成：如何让大模型生成更有用的答案
通过提示词优化，指导大模型如何利用这些检索出来的数据，如何排除无关的数据，如何更好的回答问题等；</description>
    </item>
    
  </channel>
</rss>
