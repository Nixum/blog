<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Nixum Blog</title>
    <link>http://nixum.cc/post/</link>
    <description>Recent content in Posts on Nixum Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 01 Oct 2024 00:00:00 +0000</lastBuildDate><atom:link href="http://nixum.cc/post/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>公告</title>
      <link>http://nixum.cc/p/%E5%85%AC%E5%91%8A/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://nixum.cc/p/%E5%85%AC%E5%91%8A/</guid>
      <description></description>
    </item>
    
    <item>
      <title>向量数据库在 RAG 中的应用</title>
      <link>http://nixum.cc/p/%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E5%9C%A8-rag-%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/</link>
      <pubDate>Sat, 22 Jun 2024 00:00:00 +0000</pubDate>
      
      <guid>http://nixum.cc/p/%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E5%9C%A8-rag-%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/</guid>
      <description>[TOC]
一、从场景出发 虽然目前ChatGPT等大语言模型已经十分好用了，无论是响应速度和回答的质量，基本上能解决我们日常一些问题和简单的工作，但不可否认，目前的大语言模型仍然有很多缺陷，比如：
 回答幻觉：大语言模型回答问题的本质上是基于其已有的训练数据，预测(概率计算)出哪些可能的文字作为答案，所以难免会出现张冠李戴、胡说八道的情况，特别是在大模型不擅长的领域，最典型的比如你在 ChatGPT-3.5问他“西红柿炒钢丝球要怎么做“，它会十分正经的回答出让人哭笑不得的答案，又或者问一些代码问题，它有时会回答出一些不存在的语法或者方法的调用，产生不正确的答案； 上下文限制：比如Chat GPT-3.5 Turbo的上下文限制是4K tokens（大概3000字），GPT-4 Turbo的上下文限制是128K tokens（大概9.6万字），这意味着其最多只能处理（记忆）这么多字的内容，且随着处理的上下文越多，响应速度也会越来越慢，成本越来越高； 训练的语料更新不够及时：比如Chat GPT-3.5 Turbo训练的语料库只记录了2021年9月之前的数据，GPT-4 Turbo则是2023年4月，这意味着在此之后产生的数据模型是不知道的； 在某些领域还不够专业：比如某些垂直领域的训练语料往往比较封闭，不对外公开，又或者是企业的内部数据，处于对数据的安全性的考量，并不希望上传到第三方平台进行训练，大模型无法获取这些数据进行训练，此时只依赖通用大模型的能力，回答的质量就会大打折扣；  为了优化上述问题，提升大语言模型回答的质量，其中一种解决方案就是外挂一个知识库，在提问时先根据问题，检索出相关更加准确且核心的资料，指导大语言模型生成更加准确的答案。
二、RAG的基本原理 下面是一个最简单的RAG基本流程：
 
阶段一  结构化数据并进行文本分割：将大量文档（可能是pdf、word、文本、网页等等）进行结构化，统一数据结构，分割成多个文本块； 将文本块向量化：使用Embedding模型，将分割后的文本块转换成向量，通过向量将不同文本块进行关联； 存入向量数据库：将向量以及对应的文本块（元数据），选择合适的算法，存入到向量数据库中；  阶段二  用户提问向量化：用户提出问题时，使用阶段一中相同的Embedding模型，将问题转成向量； 检索召回：将问题转换后的向量，在向量数据库中进行检索，选择合适的算法，计算向量间的距离，得到与之相似的向量以及对应的文本块； 提示词增强：将用户的问题以及上一步检索到的文本数据，进行提示词优化，构建出最终的提示词，发送给大模型，由大模型生成最终的结果并返回；  核心步骤 在上面整个流程中，有几个核心步骤决定了最终RAG的质量，包括后续的优化，也是从这三个步骤入手：
  文本的处理和索引：如何更好的把文本数据存起来
文本分割的目的，一个是因为解决大模型输入长度的限制，另一个在保持语义连贯的同时，减少嵌入内容的噪声，更加有效的检索到用户问题更相关的文本资料；
怎么分割是一个取舍的问题，如果分块太大，可能会导致分块包含了太多信息，降低检索的准确性，分块太小又可能会丢失必要的上下文信息，导致最终生成的回答缺乏连贯性或深度；
分割后的文本最终需要被检索，因此需要将文本转换为向量，这也依赖embedding模型的能力，而embedding模型的训练语料、参数的数量级，决定了转换出来的向量的关联性，最终影响文本间的语义相似度；
  检索召回：如何在大量的文本数据中，找到一小部分有用的数据，给到模型参考
向量和对应文本的存储和检索，又依赖向量数据库，需要解决不同数量级维度的向量要如何存储，如何才能快速计算其相似度，快速精确的定位和检索数据的问题，甚至为了进一步提升检索的质量，除了需要提供相似度检索，还需要提供传统的关键字检索等；
单纯的向量召回存在精度问题，因此可能需要多种召回的方式，比如分词召回、图谱召回等，对于召回出来的数据，可能还需要进一步的处理，进行各种去重、合并和重排等，检索出到更加精确的数据；
  内容的生成：如何让大模型生成更有用的答案
通过提示词优化，指导大模型如何利用这些检索出来的数据，如何排除无关的数据，如何更好的回答问题等；
   
三、为什么要使用向量数据库 或许你可能会疑惑，如果用传统数据库或者es等搜索出关联的信息，再跟着问题一起发送给大语言模型，也能实现类似的效果，这样行不行？答案当然是可以，但它不是最优的，出来的效果也并不好，原因在于传统数据库的搜索功能都是基于关键字搜索，只能匹配出对应的文本，语义上的联系其实非常弱。
传统数据库都是基于B+树或者分词+倒排索引的方式进行关键字匹配和排序，得到最终结果，例如，通过传统数据库搜索”布偶猫“，只能匹配得到带有”布偶猫“这个关键字相关的结果，无法得到”银渐层“、”蓝猫“等结果，因为他们是不同的词，传统数据库无法识别他们的语义关系。
 
而向量数据库是基于向量搜索的，需要我们事先将”蓝猫“，”银渐层“，”布偶“，根据他们的特征比如大小、毛发长短、颜色、习性、脸型等维度，计算出一组数字后作为他们的代表进行存储（这组数字也被称为向量），只要分解的维度足够多，就能将所有猫区分出来，然后通过计算向量间的距离来判断他们的相似度，产生语义上的联系；
 
向量数据库并不是什么特别新的技术，早在机器学习场景中就有广泛应用，比如人脸识别、以图搜图、音乐软件的听音识曲等都有应用到，只是最近被大模型带火了一把。
 向量数据库用专门的数据结构和算法来处理向量之间的相似性计算和查询。 通过构建索引结构，向量数据库可以快速找到最相似的向量，以满足各种应用场景中的查询需求。
 上面是AWS上找到的对向量数据库的描述，在RAG的场景下，向量数据库的核心作用，就是将用户准备好的强相关性的文本转成向量，存储到数据库中，当用户输入问题时，也将问题转成向量，然后在数据库中进行相似性搜索，找到相关联的向量和上下文，进而找到对应的文本，最后跟着问题一起发送给大语言模型，从而达到减少模型的计算量，提升理解能力和响应速度，降低成本，绕过tokens限制，提高回答质量的目的。</description>
    </item>
    
    <item>
      <title>系统设计</title>
      <link>http://nixum.cc/p/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/</link>
      <pubDate>Tue, 01 Oct 2024 00:00:00 +0000</pubDate>
      
      <guid>http://nixum.cc/p/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/</guid>
      <description>[TOC]
思考的维度  明确需求，确定核心功能和非核心功能 容量估算，比如用户数，qps，读写比例，DB存储容量，网络带宽 架构设计，确定有什么模块，服务的定位和功能，DB，缓存，MQ，与外部服务的交互，API与通信协议， 针对某一个模块深入思考细节 扩展设计，需要考虑可靠性、可扩展性、安全性、成本等方面  参考 https://github.com/ByteByteGoHq/system-design-101
https://github.com/checkcheckzz/system-design-interview
https://github.com/ashishps1/awesome-system-design-resources
https://github.com/donnemartin/system-design-primer/blob/master/README-zh-Hans.md</description>
    </item>
    
    <item>
      <title>毕业后四年工作总结 - 第一阶段结束</title>
      <link>http://nixum.cc/p/%E6%AF%95%E4%B8%9A%E5%90%8E%E5%9B%9B%E5%B9%B4%E5%B7%A5%E4%BD%9C%E6%80%BB%E7%BB%93-%E7%AC%AC%E4%B8%80%E9%98%B6%E6%AE%B5%E7%BB%93%E6%9D%9F/</link>
      <pubDate>Tue, 09 May 2023 00:00:00 +0000</pubDate>
      
      <guid>http://nixum.cc/p/%E6%AF%95%E4%B8%9A%E5%90%8E%E5%9B%9B%E5%B9%B4%E5%B7%A5%E4%BD%9C%E6%80%BB%E7%BB%93-%E7%AC%AC%E4%B8%80%E9%98%B6%E6%AE%B5%E7%BB%93%E6%9D%9F/</guid>
      <description>工作经历 从19年毕业的时候，给自己定了一个期限，希望能在第三年做出点成绩，或者能跳到一家好一点的厂子，虽然比预期晚了近一年，但还算基本实现（自认为）。
目前为止(2023.05.09)，主要的技术栈还是围绕着后端 + 云原生展开，经历的业务是广告 + 电商，幸好，毕业之后遇到的团队都非常不错，几任主管都很nice（巧的是他们几乎都是之前UC系的），都给了我非常大的帮助。
  2018.07 ~ 2020.05
从实习到校招乃至毕业的第一年，做的是广告方向的业务，类似网盟平台，但主要是业务框架的开发，比如类GraphQL协议语法糖的实现、账号服务架构、广告主接入流程低代码等方面，量的话，高峰时一天有一亿点击，还是很猛的。
开发使用的是Java，但又不使用 Spring 全家桶，除了底层的Web框架用的是Netty，像微服务间的通信协议、RPC、业务框架啥的，都是团队自研的。CTO带队，当时的Leader和CTO本身对技术很有追求，对方案的设计和代码的合理性都非常严格，这对刚毕业的我来说成长上帮助比较大。
自研的框架在我看来，整体上是一个多Reactor多线程 + 事件驱动 + 状态机的模型（blog上有这个模型的简化版类图），能极大程度压榨CPU的性能，整体上吞吐确实比Spring全家桶那套要高一点，设计上确实挺巧妙的，后来甚至把整个事件驱动抽出来做成一个PaaS框架， 搭配自研的类 GraphQL 接口，实现低代码的功能，任何方向的业务写完配置就能直接往里套，就有CRUD接口可以用了，当然，代价就是实现很复杂，写得我及其痛苦。
这对于刚毕业的我来说真的高维打击，很多东西都不懂，每天都要干得很晚，甚至会为某一个功能实现不出来感到焦虑，足够难，但也足够有趣，是成长得比较快的一个阶段。
  2020.05 ~ 2020.11
由于公司内部原因，之前所在的基础架构部门解散了，当时又由于疫情刚开始，还是有点害怕失业的，还好后面转入业务部门，不过也从Java转成go + gin那一套，从事跨境电商方向的业务开发。
业务方面没什么好说的，难度对比之前真的降维打击，当然成长也比较慢，好处是这个阶段开始接触到云原生、Kubernetes + Istio那一套，这个时候还只是以用为主，初步对这些东西有了概念，当时的Leader也很支持我们自己去探索，就利用公司闲置的KVM搭了一套K8s集群，算是入了个门，开始云原生探索道路。
  2020.11 ~ 2023.04
在当时公司电商业务技术负责人的邀请下一起跳槽到一家做出海的创业公司，主要也是从事跨境电商方向的业务开发，自研电商平台，创业的方向总体还是围绕着电商在做，从数码3c电商平台到本地生活类型的电商平台，因此也有幸参与到了整个业务线、后端基建的从0到1。
得益于之前的经历，进入公司的第一件事就是为后端团队搭建基础设施，使用AWS EKS搭建了kubernetes环境，在此基础上，采用EFK方案做日志收集、采用Prometheus、Grafana方案做指标采集和资源利用率看板等一系列的监控告警工具，基于 Gitlab 搭建整套CI/CD流程，算是基本把整个后端的基建搭建起来，有了监控告警和日志查询，动态扩缩容，基本上服务开发后就没有烦恼，自动化部署和维护起来真的很方便。
在此期间也重新认识了kubernetes，对它整个架构和原理有了更深一步的理解，基本上一些常规的问题和排查思路都非常熟悉，不得不说，Kubernetes真的是一座大山，里面的理念和方案设计真的挖都挖不完，但是，个人感觉像Kubernetes这一块，如果想要更进一步的提升，还得有足够复杂的场景才行，只依赖一两个demo或者我们这种小集群（10台机器）还是远远不够；
基建搭完之后，逐渐转向业务开发，先是基于以前的项目抽出一套业务开发的脚手架，对应的目录结构做分层，团队的小伙伴需要起新服务时直接命令式生成脚手架，可以直接进行业务代码的开发即可；（这里也立一下Flag，未来有时间要继续完善一下那个脚手架，反正后面做副业可能也会用到）
之后才是真正的做业务开发，负责平台的核心交易线，主导开发了订单和支付服务，这里比较好的一点是前期设计的时候就考虑中台的方案，尽量将整个交易流程标准化，并提供一套接口方便各个业务方接入，在后面公司频繁变换方向的时候，仍然能提供很好的订单和支付功能的支撑。
  总之，这四年总结下来，基本上从后端的开发到云原生的开发部署运维这一块，都有一定的理解，对方案的设计，架构，设计模式，代码的组织也有了自己的思考，具备独立规划和完成的能力，在后端中kubernetes还算是玩得比较溜（当然云原生这块还是比不了专门搞容器开发的，但对于一个后端来说暂时够用了）；业务方面也熟悉了交易，履约相关的功能，对电商和广告有一定的认识。
  求职感想 从离职到入职，中间gap一个月，就靠着平时的积累，离职后复习了一周就开始投简历，今年行情确实很差，没那么多机会了，Boss上来来去去也是那几家，然后我还是瞄准了百人以上，有一定规模且盈利的公司，选择就更少了，进面的有13家左右，最终offer四家，还有两家是拿到心仪offer后没有继续推进面试流程的。
在整个求职过程，也是不断发现不足和补齐不足的过程，甚至比上班还累，每一次面完都快虚脱，回头还得复盘和复习，每一次面试没过就意味着少了一次机会，异常焦虑，时刻处于自我怀疑和信心十足的跌宕起伏中&amp;hellip;
今时今日，面试已经不像以前那么容易，机会是面一个少一个，如果想提升面试成功率，拿到更多的offer，平时就要有所积累了。
对于简历，个人推荐是半年更新一次，即使没有跑路的意愿也需要更新，再不济也要记录一下这段时间的工作内容。记录时，以STAR法则作为线索去写，就算是普通的CRUD，也可以通过设计模式去美化它，当然前提还是需要你真的能理解。
记录的时候，需要记两份，一份是用STAR法则记录详细的内容，包括背景和场景、实现、优缺点、可改进的点，这一份是针对面试官询问的时候，能牢牢把握住你经历的项目内容，不会一问三不知，讲述的时候也要可以按照STAR法则去讲，这样就能很清晰的讲出来，面试过程中能流利的表达也是一个很重要的点；另一份是对详细内容的浓缩，提炼成一句有亮点的话写在简历上的。简历通常需要不断修改，可以给其他人看，根据他人的建议进行修改，一份好的简历基本是要迭代个三四遍吧。
另外，简历上不宜出现过多业务名词，除非是对口的业务方向，因为面试的公司不同，业务也不同，不同业务的面试官可能会看不懂这些名词，最好的方式是将业务抽象为技术模型，思考它的优缺点，这样的好处是，如果遇到相同的业务场景，不管是在面试中还是工作中，都可以去套用，也能引导面试官从技术角度提问。
对于基础，数据库、网络、操作系统是必问的，占比大概是50%、30%、20%，这一块就比较吃基础了，微服务、服务治理、分布式架构、云原生，甚至一些业务解决方案，都是在这些基础上进行延申和借鉴的，打好基础真的很重要。
如果想要速成，推荐小林coding那几个专题，应该足够应付大多数场景了。如果想更进一步，就急不来了，一些MIT的课程，一些经典的书，博客文章，慢慢啃吧。
对于八股，说实话我现在还是不太清楚八股是不是指别人整理好的一些的面试题Q&amp;amp;A，如果光靠这些Q&amp;amp;A的话，我觉得是远远不够的，这种稍微问深一点就得露馅了吧。当然，Q还是有很好的提示作用的，至少Q可以抄，但A还是得自己去找，不断的去思考，理解和延申，不断的从Q里进行发散，才能真正转换为自己的东西；
对于system design，这个就比较吃工作经验了，有些场景你没遇到过，没仔细思考过，当场回答起来是比较费时费力的，效果也不太好。
解决办法可以是上面有提到的把自己遇到业务场景转换为技术模型，平时多看点系统设计的书，一些大佬的解决方案，或者是平时自己看到的一些功能，思考一下别人是怎么实现，通过这些方式来积累了，这也是我目前做的不够好的，还需要总结出一个指导思想出来。
对于算法，这个真的是性价比极低的投入，极低的ROI，基本都是靠量堆起来的，靠量变引起质变，反正个人能力有限，跟大佬们还是没得比，基本都是刷了忘，忘了刷，除开那些简单题，很少能达到一次性bug free的程度，但是至少，个人觉得leetcode Top 100还是要过个几遍来保持手感的。</description>
    </item>
    
    <item>
      <title>Kubernetes和Istio</title>
      <link>http://nixum.cc/p/kubernetes%E5%92%8Cistio/</link>
      <pubDate>Wed, 22 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>http://nixum.cc/p/kubernetes%E5%92%8Cistio/</guid>
      <description>[TOC]
Kubernetes 当前Kubernetes社区对外宣传是单个集群最多支持5000个节点，Pod总数不超过150k，容器总数不超过300k，单节点Pod数量不超过100个。
基本  
容器的本质是进程，Kubernetes相当于操作系统，管理这些进程组。
  CNI：Container Network Interface，容器网络接口规范，如 Flannel、Calico、AWS VPC CNI
  CRI：Container Runtime Interface，容器运行时的各项核心操作的接口规范，是一组gRPC接口。包含两类服务，镜像服务和运行时服务。镜像服务提供下载、检查和删除镜像的RPC接口；运行时服务包含用于管理容器生命周期，与容器交互的调用的RPC接口（exec / attach / port-forward等）。dockershim、containerd、cri-o都是遵循CRI的容器运行时，称为高层级运行时。
  CSI：Container Storage Interface，容器存储的接口规范，如PV、PVC
  OCI：Open Container Initiative，容器运行时和镜像操作规范，镜像规范规定高层级运行时会下载一个OCI镜像，并把它解压称OCI运行时文件系统包；运行时规范描述如何从OCI运行时文件系统包运行容器程序，并且定义其配置、运行环境和生命周期。定义新容器的namespaces、cgroups和根文件系统；它的一个参考实现是runC，称为底层级运行时。
  CRD：Custom Resource Definition，自定义的资源对象，即yaml文件中的Kind，如Operator就是实现CRD的控制器，之后直接使用Operator创建的CRD声明对象即可使用
每一个对象都包含两个嵌套对象来描述规格（Spec）和状态（Status），对象的规格就算我们期望的目标状态，而状态描述了对象当前状态，这一部分由Kubernetes本身提供和管理，通过describe才能看到Status的信息。
1 2 3 4 5 6 7  type Deployment struct { metav1.TypeMeta `json:&amp;#34;,inline&amp;#34;` metav1.ObjectMeta `json:&amp;#34;metadata,omitempty&amp;#34; protobuf:&amp;#34;bytes,1,opt,name=metadata&amp;#34;` Spec DeploymentSpec `json:&amp;#34;spec,omitempty&amp;#34; protobuf:&amp;#34;bytes,2,opt,name=spec&amp;#34;` Status DeploymentStatus `json:&amp;#34;status,omitempty&amp;#34; protobuf:&amp;#34;bytes,3,opt,name=status&amp;#34;` }     Master节点作用：编排、管理、调度用户提交的作业</description>
    </item>
    
    <item>
      <title>容器</title>
      <link>http://nixum.cc/p/%E5%AE%B9%E5%99%A8/</link>
      <pubDate>Sat, 06 Nov 2021 00:00:00 +0000</pubDate>
      
      <guid>http://nixum.cc/p/%E5%AE%B9%E5%99%A8/</guid>
      <description>[TOC]
底层原理 容器技术的核心功能，就是通过约束和修改进程的动态表现，从而为其创造出一个边界。
Namespace - 隔离 进程只能看到被规定的视图，即 隔离，比如通过docker启动一个/bin/sh，再在容器里通过ps命令查看该/bin/sh进程的pid，会发现它的pid是1，但是实际上它在外部的宿主机里的pid是10，使得让在容器里运行的进程以为自己就在一个独立的空间里，实际上只是进行了逻辑的划分，本质还是依赖宿主机。
作用：在同一台宿主机上运行多个用户的容器，充分利用系统资源；不同用户之间不能访问对方的资源，保证安全。
常见的Namespace类型有：
 PID Namespace：隔离不同容器的进程 Network Namespace：隔离不同容器间的网络 Mount Namespace：隔离不同容器间的文件系统  与虚拟化的区别：虚拟化是在操作系统和硬件上进行隔离，虚拟机上的应用需要经过虚拟机再经过宿主机，有两个内核，本身就有消耗，而容器化后的应用仅仅只是宿主机上的进程而已，只用到宿主机一个内核；
因为namespace隔离的并不彻底，由于内核共享，容器化应用仍然可以把宿主机的所有资源都吃掉，有些资源不能通过namespace隔离，比如修改了容器上的时间，宿主机上的时间也会被改变，因此需要Cgroups；
Cgroups - 资源限制 是用来制造约束的主要手段，即控制进程组的优先级，设置进程能够使用的资源上限，如CPU、内存、IO设备的流量等
比如，限定容器只能使用宿主机20%的CPU
1  docker run -it --cpu-period=100000 --cpu-quota=20000 ubuntu /bin/bash    Cgroups 通过不同的子系统限制了不同的资源，每个子系统限制一种资源。每个子系统限制资源的方式都是类似的，就是把相关的一组进程分配到一个控制组里，然后通过树结构进行管理，每个控制组都设有自己的资源控制参数。
 相互关系：
每个子系统是一个控制组，每个控制组可以被看作是一个树的节点，每个控制组下可以有多个子节点，比如我们在在CPU子系统中，创建一个DB控制组，然后把所有运行的数据库服务放在其中，然后再在该组下再创建 MySQL和MongoDB两个子组来，分别划分不同的使用资源，所以形成了一颗树，大致就如下图
 
/sys/fs/cgroup/cpu/{task}/目录表示task这个任务挂在了CPU Cgroup下，在这个目录下有很多的配置文件，比如cpu.cfd_quota_us、cgroup.procs等，文件内容是该task所属进程的PID；
/proc/{PID号}/cgroup文件表示这个进程涉及到的所有cgroup子系统的信息
常见的Cgroups子系统
  CPU 子系统，用来限制一个控制组（一组进程，你可以理解为一个容器里所有的进程）可使用的最大 CPU，配合cfs（完全公平调度算法）实现CPU的分配和管理。
cpu share：用于cfs中调度的权重，条件相同的情况下，cpushare值越高，分得的时间片越多。
cpu set：主要用于设置CPU的亲和性，可以限制cgroup中的进程只能在指定的CPU上运行，或者不能在指定的CPU上运行，同时cpuset还能设置内存的亲和性。
  memory 子系统，用来限制一个控制组最大的内存使用量。
  pids 子系统，用来限制一个控制组里最多可以运行多少个进程。
  cpuset 子系统， 这个子系统来限制一个控制组里的进程可以在哪几个物理 CPU 上运行。</description>
    </item>
    
    <item>
      <title>Go Sync包相关</title>
      <link>http://nixum.cc/p/go-sync%E5%8C%85%E7%9B%B8%E5%85%B3/</link>
      <pubDate>Mon, 22 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>http://nixum.cc/p/go-sync%E5%8C%85%E7%9B%B8%E5%85%B3/</guid>
      <description>[TOC]
变量可见性 由于不同的架构和不同的编译器优化，会发生指令重排，导致程序运行时不一定会按照代码的顺序执行，因此两个goroutine在处理共享变量时，能够看到其他goroutine对这个变量进行的写结果。
happens-before：程序的执行顺序和代码的顺序一样，就算真的发生了重排，从行为上也能保证和代码的指定顺序一样。
Go不像Java有volatile关键字实现CPU屏障来保证指令不重排，而是使用不同架构的内存屏障指令来实现同一的并发原语。
Go只保证goroutine内部重排对读写顺序没有影响，如果存在共享变量的访问，则影响另一个goroutine。因此当有多个goroutine对共享变量的操作时，需要保证对该共享变量操作的happens-before顺序。
1 2 3 4 5 6 7 8 9 10 11  // 例子： var a, b int go func() { a := 5 b := 1 } go func() { for b == 1 {} fmt.Println(a) } // 当两个goroutine同时执行时，因为指令重排的缘故，第二个goroutine打印a可能是5，也可能是0   证heppens before的手段   init函数：同一个包下可以有多个init函数，多个签名相同的init函数；main函数一定在导入的包的init函数执行之后执行；当有多个init函数时，从main文件出发，递归找到对应的包 - 包内文件名顺序 - 一个文件内init函数顺序执行init函数。
  全局变量：包级别的变量在同一个文件中是按照声明顺序逐个初始化的；当该变量在初始化时依赖其它的变量时，则会先初始化该依赖的变量。同一个包下的多个文件，会按照文件名的排列顺序进行初始化。
init函数也是如此，当init函数引用了全局变量a，运行main函数时，肯定是先初始化a，再执行init函数。
当init函数和全局变量无引用关系时，先初始化全局变量，再执行init函数
  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37  var ( a = c + b // == 9  b = f() // == 4  c = f() // == 5  d = 3 // 全部初始化完成后 == 5 ) func f() int { d++ return d } --- func init() { a += 1 fmt.</description>
    </item>
    
    <item>
      <title>Go Goroutine和GC</title>
      <link>http://nixum.cc/p/go-goroutine%E5%92%8Cgc/</link>
      <pubDate>Mon, 22 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>http://nixum.cc/p/go-goroutine%E5%92%8Cgc/</guid>
      <description>[TOC]
runtime  不同于Java，Go没有虚拟机，很多东西比如自动GC、对操作系统和CPU相关操作都变成了函数，写在runtime包里。 runtime提供了go代码运行时所需要的基础设施，如协程调度、内存管理、GC、map、channel、string等内置类型的实现、对操作系统和CPU相关操作进行封装。 诸如go、new、make、-&amp;gt;、&amp;lt;-等关键字都被编译器编译成runtime包里的函数 build成可执行文件时，runtime会和用户代码一起进行打包。  pprof 使用net/http/pprof库，进行HTTP服务进行分析，需要主动开启，比如import _ &amp;quot;net/http/pprof&amp;quot;，使用默认的http.DefaultServeMux，默认端口是6060；也可自定义Mux，手动注册路由。
pprof提供应用运行的过程中分析当前应用的各项指标来辅助进行性能优化以及问题排查功能，提供以下功能：
   类型 描述     allocs 查询内存分配情况，所有对象的内存分配，在堆（Heap）分配的时候，记录一下调用堆栈。默认情况下，是每 1000 次分配，取样一次，这个数值可以改变。栈(Stack)分配 由于会随时释放，因此不会被内存分析所记录。由于内存分析是取样方式，并且也因为其记录的是分配内存，而不是使用内存。开启后会对runtime产生压力，通过runtime.MemProfileRate设置采样的内存比例，默认大小是512kb。   blocks 查询阻塞操作情况，类似于 CPU 性能分析，但是它所记录的是 goroutine 等待资源所花的时间。阻塞分析对分析程序并发瓶颈非常有帮助，阻塞性能分析可以显示出什么时候出现了大批的 goroutine 被阻塞了。阻塞性能分析是特殊的分析工具，在排除 CPU 和内存瓶颈前，不应该用它来分析。   cmdline 应用启动命令及参数   goroutine 当前所有协程的堆栈信息，开启时会STW   heap 堆上内存使用情况采样信息，活跃对象的内存分配   mutex 锁持有的堆栈，次数(采样)的信息   profile CPU占用情况采样，启动后会对runtime产生压力，runtime每10ms会STW，记录当前运行的 goroutine 的调用堆栈及相关数据   threadcreate 系统线程创建情况的采样信息，不会STW   trace 程序运行跟踪信息，跟踪GC和G调度      curl http://ip:port/debug/pprof/{上面列表的功能} &amp;gt; profile文件名 把此时的统计下载下来；像trace、profile 默认采集时间是30s，可以使用参数 seconds=xx 来调整采样时间；</description>
    </item>
    
    <item>
      <title>Go Context和Channel</title>
      <link>http://nixum.cc/p/go-context%E5%92%8Cchannel/</link>
      <pubDate>Mon, 22 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>http://nixum.cc/p/go-context%E5%92%8Cchannel/</guid>
      <description>[TOC]
Context 一个接口，包含如下方法，主要用于实现主协程对子协程的控制，作用包括取消执行、设置超时时间、携带键值对等
1 2 3 4 5 6 7 8 9 10  type Context interface { // 获取到期时间，如果没有，ok则返回false 	Deadline() (deadline time.Time, ok bool) // 返回一个chan，表示取消信号，如果通道关闭则代表该 Context 已经被取消；如果返回的为 nil，则代表该 Context 是一个永远不会被取消的 Context。  Done() &amp;lt;-chan struct{} // 返回该 Context 被取消的原因。如果只使用 Context 包的 Context 类型的话，那么只可能返回 Canceled （代表被明确取消）或者 DeadlineExceeded （因超时而取消）  Err() error // 获取Context中的键值对 	Value(key interface{}) interface{} }   一个demo，引用：通知多个子goroutine退出运行
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73  package main import ( &amp;#34;context&amp;#34; &amp;#34;crypto/md5&amp;#34; &amp;#34;fmt&amp;#34; &amp;#34;io/ioutil&amp;#34; &amp;#34;net/http&amp;#34; &amp;#34;sync&amp;#34; &amp;#34;time&amp;#34; ) type favContextKey string func main() { wg := &amp;amp;sync.</description>
    </item>
    
    <item>
      <title>Go</title>
      <link>http://nixum.cc/p/go/</link>
      <pubDate>Sat, 07 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>http://nixum.cc/p/go/</guid>
      <description>[TOC]
以下基于go.1.14
函数内联优化 函数内联优化：在A函数中调用了B函数，内联后，B函数的代码直接在A函数内原地展开，代替这个函数实现，当有多次调用时，就会多次展开
go在编译时会自动判断函数是否可以内联，当函数内包含以下内容时不会被内联：闭包调用，select，for，defer，go关键字创建的协程等。
内联的好处：因为函数调用被内联了，可以减少栈帧的创建，减少读写寄存器的读取，减少参数和函数的拷贝，提升性能
缺点：堆栈panic显示的行数可能不准确、增加编译出来的包的大小
编译时使用go build -gcflags=&amp;quot;-m -m&amp;quot; main.go可以知道编译器的内联优化策略，
go编译时默认会使用内联优化，使用go build --gcflags=&amp;quot;-l&amp;quot; main.go可禁掉全局内联，如果传递两个或以上-l，则会打开内联；
defer   多个defer是栈的关系，以链表的形式挂在G上，先进后出，即在一个函数中，写在前面的defer会比写在后面的defer调用得晚，先进后出的原因是后面定义的函数可能会依赖前面的资源，如果前面的先执行导致依赖没了，会影响后面的执行，导致出错；
  defer和return同时出现时，先return后defer，defer可以修改到return里的变量；
  return 是非原子性的，需要两步，执行前首先要为返回值赋值，然后 return 将返回值返回调用处。
defer 和 return 的执行顺序是：1. 先为返回值赋值；2. 然后执行 defer；3. 然后 return 到函数调用处
要注意defer + 函数 的场景，如果是函数调用，并且使用的变量是传参进去的，那得看入参类型；如果是闭包调用，引用了外边的变量（不管是不是指针），那就是引用
当返回值没有声明变量时，会内置一个隐式的变量来接收return的赋值
  panic被触发时，控制权就交给了defer
遇到panic时，会先遍历此协程内的defer链表，并执行defer，如果在执行过程中遇到recover，则停止panic，返回recover处继续往下执行，如果没遇到recover，则遍历完本协程的defer链表后，向stderr抛出panic信息；
  执行defer过程中出现panic，此时的panic会覆盖它之前的panic，直至被捕获或抛出；
  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61  func main() { fmt.</description>
    </item>
    
    <item>
      <title>Gin框架原理</title>
      <link>http://nixum.cc/p/gin%E6%A1%86%E6%9E%B6%E5%8E%9F%E7%90%86/</link>
      <pubDate>Mon, 22 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>http://nixum.cc/p/gin%E6%A1%86%E6%9E%B6%E5%8E%9F%E7%90%86/</guid>
      <description>[TOC]
标准库net/http demo:
定义了一个路由 /hello，绑定了一个handler，输出当前path，ListenAndServe方法启动web服务，第一个参数表示监听的端口，第二个参数代表 处理所有的HTTP请求 的实例，等于nil时会使用默认的DefaultServeMux。
该demo是基于标准库实现的Web框架入口。
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  func main() { http.HandleFunc(&amp;#34;/hello&amp;#34;, func (w http.ResponseWriter, req *http.Request) { fmt.Fprintf(w, &amp;#34;URL.Path = %q\n&amp;#34;, req.URL.Path) }) log.Fatal(http.ListenAndServe(&amp;#34;:8080&amp;#34;, nil)) } // http.ListenAndServe()方法第二个参数的实现： type Handler interface { ServeHTTP(ResponseWriter, *Request) } // 注册handler默认使用DefaultServeMux，与ListenAndServe第二个参数使用的处理器一致。 // 将path和对应的handler方法保存在DefaultServeMux的map中，等请求进来进行匹配处理。 func HandleFunc(pattern string, handler func(ResponseWriter, *Request)) { DefaultServeMux.HandleFunc(pattern, handler) }   http.</description>
    </item>
    
    <item>
      <title>MySQL</title>
      <link>http://nixum.cc/p/mysql/</link>
      <pubDate>Thu, 09 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>http://nixum.cc/p/mysql/</guid>
      <description>[TOC]
基础架构 MySQL逻辑架构图  
 连接器：负责跟客户端建立连接、获取权限、维持和管理连接。登录进去后修改权限，默认是将在下一次登录后生效 查询缓存：MySQL接收到查询请求后会先查询缓存，key是查询语句，value是查询结果，之后经过执行器的权限判断再返回，如果查不到则往后走。不建议使用，因为若有更新操作，会删除对应表的缓存，可能导致缓存命中低，可以设置query_cache_type=demand，默认不使用缓存，需要在查询时显示指定。MySQL8.0删除此功能 分析器：对SQL语句进行分析，词法分析判断各个字符串代表的含义（包括列是否存在），语法分析判断SQL的语法是否正确，这一层操作之后，MySQL就知道你要做什么了 优化器：决定是否要使用索引，使用哪个索引，决定表的连接顺序 执行器：先判断是否有对该表的操作权限，之后判断要使用哪个引擎提供的接口 引擎：对数据进行具体操作的执行者，事务和索引都是在这层做的，但具体需要引擎支持，例如MyISAM不支持事务，InnoDB支持  日志系统 关于物理日志和逻辑日志：物理日志记录每一个page具体存储的值，在这个数据页上做了什么修改，比如redo log；而逻辑日志记录每一个page中数据的变动过程，比如undo log、bin log、relay log；
比如一个page页中一个数据从 1 改到 2 ，再改到 3，物理日志记录最后一个值是 3 ，逻辑日志记录 1 -&amp;gt; 2, 2-&amp;gt;3 的过程。
  undo log回滚日志：InnoDB独有，逻辑日志，主要用于事务失败时的回滚，以及MVCC中的版本数据查看。当事务被提交后，并不会马上被删除，而是放到待清理链中，等到没有事务用到该版本信息时才可以清理。
undo log和数据页的刷盘策略是一样的，都需要通过redo log保证持久化，Buffer Pool中也有undo 页，对undo页的修改会记录到redo log中，跟着redo log刷盘一起刷盘；
同时，如果在内存中修改undo页，需要更新记录对应的redo log。
  redo log重做日志：InnoDB独有，物理日志，记录这个页做了什么改动，本质上记录了对某个表空间的某个数据页的某个偏移量修改了哪几个字节的值，具体修改的值是什么，一条redo log也就几个字节到十几个字节，格式是 日志类型，表空间ID，数据页号，数据页偏移量，具体修改的数据。
使用二阶段提交保证两份日志逻辑一致。当有日志要写入时，先写到redo log buffer后状态是prepare，开始写bin log cache，bin log 写完后，事务提交，redo log 改为commit状态，redo log写完，此时事务就算完成；这里描述的写redo log和bin log都只写在了缓冲区，何时写进磁盘，是根据innodb_flush_log_at_trx_commit和sync_binlog配置决定，用于实现数据持久化，以及宕机恢复数据。
之所以要使用二阶段提交，是为了保证redo log和bin log的数据一致性，对于处于 prepare 阶段的 redo log，即可以提交事务，也可以回滚事务，这取决于是否能在 binlog 中查找到与 redo log 相同的 XID，如果有就提交事务，如果没有就回滚事务，这样就可以保证 redo log 和 binlog 这两份日志的一致性。</description>
    </item>
    
    <item>
      <title>MongoDB</title>
      <link>http://nixum.cc/p/mongodb/</link>
      <pubDate>Sun, 28 Nov 2021 00:00:00 +0000</pubDate>
      
      <guid>http://nixum.cc/p/mongodb/</guid>
      <description>[TOC]
特点  分布式数据库，Json数据模型，面向对象数据模型，不强制表的scheme 当应用场景不清晰时，可以直接以对象模型直接存储，无需关心字段，表结构灵活，动态增加新字段 不用太过关注表间的关系，可直接嵌套存储，将多种关系存储在同一张表上，同时也加快查表，因为它可以减少磁盘定位次数，如果是关系型数据库，同时查多张表就需要定位多次 原生支持高可用，一般的部署方式是部署三个节点replica set，最多50个；多replica set可以实现自恢复（当主节点挂点后会选出从节点），异地容灾，数据库滚动更新 原生支持横向扩展，通过水平扩展分片实现，外部并不感知有多少个分片，只会当成一个分片使用 支持字段级加密，针对隐私数据，比如身份证、电话等，在入库时可以进行加密，查询时解密 支持地理位置经纬度查询 强大的聚合查询，适合报表、时序数据  NoSQL语句 客户端使用驱动时连接的执行流程
 客户端执行流程 
数据库端执行流程
 数据库端执行流程 
要获取ticket是因为MongoDB默认存储引擎wiredtiger的机制，ticket代表着系统资源的数量，ticket数量有限，读写操作都需要先获得ticket才可以进行下一步操作，机制类似信号量。
连接 连接mongoDB语句，当有多节点或多分片时，连接也要写上，mongodb://节点1的host:port, 节点2的host:port,.../databaseName?[options: maxPoolSize(java默认是100), maxWaitTime(查询的最大等待事件), writeConcern, readConcern]
mongoDB驱动里已提供负载均衡，多节点探测
聚合 作用相当与group by，可作用与多个collection，可进行查询和计算。Mongo的聚合操作发生在pipeline中，由多个stage组成，有点像责任链，通过多个state来过滤，聚合数据，每一个{}代表一个state
demo
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  MySQL中的SELECTdepartment,count(null)asemp_QTYFROMUserWHEREgender=&amp;#39;female&amp;#39;GROUPBYdepartmentHAVINGcount(*)&amp;lt;10等价于mongo中的db.user.aggregate([{$match:{gender:&amp;#39;female&amp;#39;}},{$group:{_id:&amp;#39;$DEPARTMENT&amp;#39;,emp_qty:{$sum:1}}},{$match:{emp_qty:{$lt:10}}}])  几个比较特别的运算符
$unwind：将查询到的数组展开
$grouphLookup：图搜索
$facet/$bucket：分面搜索，根据不同范围条件，多个维度一次性进行分组输出
文档模型设计原则   传统关系型数据库设计，从概念模型 -》逻辑模型 -》物理模型，关系明确，遵循三范式（1.要有主键，列不可分，2.每列与主键相关，3.不能存在传递依赖(不允许字段冗余)），表现形式上，一对多关系，外键在多那张表上，多对多关系，会有第三张表来做关联
对于文档模型，一般对应关系型数据库设计的逻辑模型阶段，通过嵌套实体数组，map或者引用字段来处理实体间的关系，字段冗余限制宽松
  实体间的关系，一对一使用嵌套map来表示；一对多使用嵌套数组表示；多对多使用嵌套数组+冗余字段来表示；此外，也可以通过嵌套数组存id + 另一张表来表示实体间的关系，通过id来进行联表（使用aggregate + $lookup）</description>
    </item>
    
    <item>
      <title>英语学习总结</title>
      <link>http://nixum.cc/p/%E8%8B%B1%E8%AF%AD%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/</link>
      <pubDate>Fri, 23 Jun 2023 00:00:00 +0000</pubDate>
      
      <guid>http://nixum.cc/p/%E8%8B%B1%E8%AF%AD%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/</guid>
      <description>[TOC]
方法论 整体参考视频：自学英语零基础到中高级！超详细学习指南！
初学   找核心学习资料（50%），《走进美国》、《每日英语听力》《新概念一册，Leo老师》《欧陆词典》
 边听边看文本热身 查词学语法点 逐句反复跟读 原速跟读 遮盖原文原速听    背单词（25%）
 在语境下背单词    听说训练（25%）
  发音、音标课《BBC learn all 44 engilsh sounds》 音-词-句，泛听（语音语调、抓单词、重复）
  可利用 博树，多邻国，speak、call annie、talkface、Ainder
  摸鱼时进行泛听，泡耳朵，平时没事多听或者跟读新概念的音频，主要是用来提升语音、语调、语速、变音，在此过程中要多注意里面的单词，语法的习惯用法
跟读时，听一句，读一句，尽可能的模仿，直到满意
    需要设定目标：长期目标 -&amp;gt; 中期 -&amp;gt; 短期，目的是控制学习量
具体计划   核心学习资料-30分钟
 新概念英语一册，一节或半节，搭配leo视频    背单词 - 15分钟
 《欧路词典》《新概念一册、二册》词库    听书训练 - 15分钟</description>
    </item>
    
    <item>
      <title>Redis</title>
      <link>http://nixum.cc/p/redis/</link>
      <pubDate>Sun, 09 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>http://nixum.cc/p/redis/</guid>
      <description>[TOC]
数据类型及结构 Redis里存的key和value都是二进制数据，即 byte数组，本身是二进制安全的（二进制安全的意思是，存进去怎么样，取出来就是怎么样，程序不会对原始数据进行任意的操作）
数据类型 具体的分为5种基本类型和3种特殊类型：
String、List(一般当成队列，尽量少使用随机读写)、Hash、Set、ZSet
  String：简单动态字符串(SDS)
场景：缓存（可以使用json、protobuf等进行序列化反序列化、也可以通过key来分离缓存对象的属性，实现hash的效果，只是是单字段罢了）、token、限流、分布式id
  List：压缩列表（元素数量小于512，且所有元素的长度都小于64字节） + 双向链表，高版本是快表（其他情况使用）
场景：用户消息时间线、消息队列
  Hash：压缩列表（元素数量小于512，且key和value字符串长度都小于64字节） + 哈希表（其他情况使用）
场景：存储对象缓存（可以更方便get、set对应字段）、根据key进行统计
  Set：数组（带有编码类型字段，所以元素可以使用整型表示，少于512个时使用）+ 哈希表（key为set中的元素，value为null，其他情况使用）
场景：交集、并集、点赞、签到、随机弹出获取元素
  ZSet：压缩列表（元素小于128个，且所有元素的长度小于64字节时使用） + 跳表 （其他情况使用）
场景：排行榜
  另外三种扩展类型：
  Bitmap：位存储，基于String，原理：String类型会保存二进制字节数组，只有0和1两个值，对于这个字节数组的每个bit来表示一个元素的二值状态；
场景：二值统计，如签到统计、记录每个月签到情况、判断用户登录状态
  HyperLogLog：基数统计，类似set，不断往里add值，然后判断有总数量；主要作用是使用少量固定的内存（12KB内存即可统计2^64个不同元素）去存储并识别有大量元素的集合中的唯一元素，能快速算出集合内的元素个数，误差率0.81%；版本2.8.9之后才有
场景：百万级别网络的UV计数
  Geo：推算地理位置，比如两地之间的距离，方圆几里的人；版本3.2之后才有
  Stream：5.0之后的版本才有，Stream会在第一次使用 xadd 指令追加消息时自动创建。
 Consumer Group：消费组，一个消费组有多个消费者，这些消费者是竞争关系； Last_delivered_id：游标，每个消费组的游标，组内任意一个消费者读取了消息都会使游标向前移动； pending_ids：消费者的状态变量，用于维护消费者未确认的id，记录当前已经被客户端读取但还没有被ACK的消息。如果客户端没有ACK，这个变量里面的消息ID会越来越多，一旦某个消息被ACK，它就开始减少，用来确保客户端至少消费了消息一次，而不会在网络传输的中途丢失了没处理。 消息ID：组成方式毫秒级时间戳 - 序号，消息ID也可以自定义，但必须是整数-整数，且能后面加入的消息ID要大于前面的消息ID。Redis本身会记录 lastest_generated_id，防止时间回拨导致ID问题； 消息内容：键值对，类似Hash的结构；     
底层数据结构 Redis所有类型有一个顶层的数据结构叫RedisObject，这个RedisObject底层对应着具体对象类型和其编码方式。</description>
    </item>
    
    <item>
      <title>etcd和ZooKeeper</title>
      <link>http://nixum.cc/p/etcd%E5%92%8Czookeeper/</link>
      <pubDate>Wed, 23 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>http://nixum.cc/p/etcd%E5%92%8Czookeeper/</guid>
      <description>[TOC]
ZooKeeper ZooKeeper保证的是CP，不保证每次服务请求的可用性，在极端环境下，ZooKeeper可能会丢弃一些请求，消费者程序需要重新请求才能获得结果。另外在进行leader选举时集群都是不可用，所以说，ZooKeeper不能保证服务可用性。
使用场景  集群管理，监控节点存活状态 主节点选举，当服务以master-salve模式进行部署，当主节点挂掉后选出新的主节点 服务发现 分布式锁，提供独占锁、共享锁 分布式自增id 搭配Kafka、dubbo等使用  特点  顺序一致性：同一客户端发起的事务请求，最终将会严格地按照顺序被应用到 ZooKeeper 中去。 原子性：所有事务请求的处理结果在整个集群中所有机器上的应用情况是一致的，也就是说，要么整个集群中所有的机器都成功应用了某一个事务，要么都没有应用。 单一系统映像：无论客户端连到哪一个 ZooKeeper 服务器上，其看到的服务端数据模型都是一致的。 可靠性：一旦一次更改请求被应用，更改的结果就会被持久化，直到被下一次更改覆盖。  数据模型 类似文件系统，根节点为 / ，每创建一个节点会从根节点开始挂，树形结构，每个数据节点称为znode，可以存储数据，每个znode还有自己所属的节点类型和节点状态
  持久节点：一旦创建就一直存在，直到将其删除。 持久顺序节点：一个父节点可以为其子节点 维护一个创建的先后顺序 ，这个顺序体现在 节点名称 上，是节点名称后自动添加一个由 10 位数字组成的数字串，从 0 开始计数。 临时节点：临时节点的生命周期是与 客户端会话 绑定的，会话消失则节点消失 。临时节点 只能做叶子节点 ，不能创建子节点。 临时顺序节点：父节点可以创建一个维持了顺序的临时节点(和前面的持久顺序性节点一样)。   ZAB协议 通过ZAB协议保证注册到ZooKeeper上的主从节点状态同步，该协议有两种模式
  崩溃恢复
当整个 Zookeeper 集群刚刚启动或者Leader服务器宕机、重启或者网络故障导致不存在过半的服务器与 Leader 服务器保持正常通信时，所有服务器进入崩溃恢复模式，首先选举产生新的 Leader 服务器，然后集群中 Follower 服务器开始与新的 Leader 服务器进行数据同步。
  消息广播
当集群中超过半数机器与该 Leader 服务器完成数据同步之后，退出恢复模式进入消息广播模式，Leader 服务器开始接收客户端的事务请求生成事物提案（超过半数同意）来进行事务请求处理。</description>
    </item>
    
    <item>
      <title>消息队列</title>
      <link>http://nixum.cc/p/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/</link>
      <pubDate>Tue, 22 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>http://nixum.cc/p/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/</guid>
      <description>[TOC]
使用场景  秒杀系统，一般秒杀系统处理包含几个步骤：风险控制、库存锁定、生成订单、短信通知、更新统计数据等，而决定秒杀是否成功只在前两个步骤，后续的操作就可以通过消息队列异步处理完成，加快整个流程的处理，减少等待时间，提升并发量。 隔离网关和后端服务，实现流量控制，保护后端服务，但会增加系统调用链，导致总体响应变长，异步增加系统复杂性。 令牌桶，目的也是进行流量控制。 服务解耦，数据同步，比如订单系统在订单状态发生变化时发出消息通知，其他服务订阅后做相应处理。 连接流计算任务和数据，比如集群日志处理，大数据统计 将消息广播给其他接收者  好处 流量削峰和流量控制、异步处理、解耦、广播、最终一致性
缺点 可用性降低、复杂度提高、一致性问题、消息延迟
常见消息队列    特性 ActiveMQ RabbitMQ RocketMQ Kafaka     单机吞吐量 万级，吞吐量比RocketMQ和Kafka要低了一个数量级 万级，吞吐量比RocketMQ和Kafka要低了一个数量级 10万级，RocketMQ也是可以支撑高吞吐的一种MQ 10万级别，这是kafka最大的优点，就是吞吐量高。一般配合大数据类的系统来进行实时数据计算、日志采集等场景   topic数量对吞吐量的影响  使用队列模型，通过Exchange模块实现发布-订阅模型，Exchange位于生产者和队列之间，由Exchange决定将详细投递到哪个队列。 topic可以达到几百，几千个的级别，吞吐量会有较小幅度的下降这是RocketMQ的一大优势，在同等机器下，可以支撑大量的topic topic从几十个到几百个的时候，吞吐量会大幅度下降。所以在同等机器下，kafka尽量保证topic数量不要过多。如果要支撑大规模topic，需要增加更多的机器资源   可用性 高，基于主从架构实现高可用性 高，基于主从架构实现高可用性 非常高，分布式架构 非常高，kafka是分布式的，一个数据多个副本，少数机器宕机，不会丢失数据，不会导致不可用   消息可靠性 有较低的概率丢失数据  经过参数优化配置，可以做到0丢失 经过参数优化配置，消息可以做到0丢失   时效性 ms级 微秒级，这是rabbitmq的一大特点，延迟是最低的 ms级 延迟在ms级以内   功能支持 MQ领域的功能极其完备 基于erlang开发，所以并发能力很强，性能极其好，延时很低 MQ功能较为完善，还是分布式的，扩展性好 功能较为简单，主要支持简单的MQ功能，在大数据领域的实时计算以及日志采集被大规模使用，是事实上的标准   优劣势总结 非常成熟，功能强大，在业内大量的公司以及项目中都有应用。偶尔会有较低概率丢失消息，而且现在社区以及国内应用都越来越少，官方社区现在对ActiveMQ 5.</description>
    </item>
    
    <item>
      <title>网络</title>
      <link>http://nixum.cc/p/%E7%BD%91%E7%BB%9C/</link>
      <pubDate>Sun, 22 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nixum.cc/p/%E7%BD%91%E7%BB%9C/</guid>
      <description>[TOC]
基本    OSI七层模型 对应网络协议 作用     应用层 HTTP、TFTP、FTP、NFS、SMTP、Telnet 应用程序间通信的网络协议   表示层 Rlogin、SNMP、Gopher 数据格式化、加密、解密   会话层 SMTP、DNS 建立、维护、管理会话连接   传输层 TCP、UDP 建立、维护、管理端到端连接   网络层 IP、ICMP、ARP、RARP、AKP、UUCP IP寻址和路由选择   数据链路层 FDDI、Ethernet、Arpanet、PDN、SLIP、PPP 控制网络层与物理层间的通信   物理层 IEEE 802.1A、IEEE 802.2到802.11 比特流传输    数据链路层：
 数据包叫Frame，“帧”； 由两部分组成：标头和数据，标头标明数据发送者、接收者、数据类型； 用MAC地址定位数据包路径； 相关设备是交换机；  网络层：
  数据包叫packet，“包”；
  IPv4：32个二进制，4字节*8位；IPv6：1同一子网28个二进制，8字节*16位；
  子网掩码与IP的and运算判断是否为同一子网下；
  路由：把数据从原地址转发到目标地址，同一局域网内，通过广播的方式找到，不同局域网内，原主机先将包根据网关添加路由器/主机地址，通过交换机的广播方式发给目标主机，原主机将数据包传输给目标主机，再由目标主机根据MAC广播交给对应目标</description>
    </item>
    
    <item>
      <title>分布式相关</title>
      <link>http://nixum.cc/p/%E5%88%86%E5%B8%83%E5%BC%8F%E7%9B%B8%E5%85%B3/</link>
      <pubDate>Fri, 14 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>http://nixum.cc/p/%E5%88%86%E5%B8%83%E5%BC%8F%E7%9B%B8%E5%85%B3/</guid>
      <description>[TOC]
分布式理论 一个分布式系统最多只能满足 C、A、P 这三项中的两项。
CAP理论  C：Consistency，一致性，数据状态转化一致，写操作完成后的读操作，可以获取到最新的值； A：Availability，可用性，指的是服务一直可用，可以正常响应，或者在规定时间内可以获取到响应； P：Partition tolerance，分区容错，指的是当有节点故障不连通时(比如网络出问题)，就会分区，但仍然能对外提供服务；  矛盾在于这三个特性不能同时满足，比如
 当分布式集群内有两个主从服务发生网络故障，但此时服务仍然可以访问，此时具有分区容错性。
当对主服务对数据进行修改时，由于网络问题，无法同步到从服务，当访问到从服务时，无法获取到最新的值，此时满足可用性，但是无法满足一致性。
当主从服务间网络恢复，写操作的数据虽然能在服务间同步了，但还未同步完成，此时访问从服务无法获取最新值，此时满足了一致性，但是无法满足可用性。
简单概括，只要满足分区容错，就会设置复制集，复制集同时也保证了可用，但是复制集又会有数据同步，此时又有一致性问题
 所以，一般只会满足其中两个
 1、满足CA舍弃P，也就是满足一致性和可用性，舍弃容错性。但是这也就意味着你的系统不是分布式的了，因为涉及分布式的想法就是把功能分开，部署到不同的机器上，而且如果出现了分区错误，必定会导致部分功能不可用，此时也无法满足A，所以 P 其实是必然存在的，只有单机是CA。
2、满足CP舍弃A，也就是满足一致性和容错性，舍弃可用性。如果你的系统允许有段时间的访问失效等问题，这个是可以满足的。就好比多个人并发买票，后台网络出现故障，你买的时候系统就崩溃了。真正的强一致性在做同步的过程中会阻塞所有请求，导致性能会特别差，此时可用性就降低了，所以像ZooKeeper这种允许同步到一半节点以上就算成功的，不算是真正的强一致性。
3、满足AP舍弃C，也就是满足可用性和容错性，舍弃一致性。这也就是意味着你的系统在并发访问的时候可能会出现数据不一致的情况。
 所以为了分布式服务能正常使用，一般时会满足分区容错性和可用性，在一致性上不追求强一致性，而是一个逐渐一致的过程。
BASE理论 BASE理论是对CAP三者均衡的结果，基于CAP理论演化而来，通过牺牲强一致性来获得高可用。
 Basically Available（基本可用）: 允许暂时不可用，比如访问时可以等待返回，服务降级，保证核心可用等。 Soft state（软状态）: 允许系统存在中间状态，而该中间状态不会影响系统整体可用性，比如允许复制集副本间的数据存在延时，数据库的数据同步过程。 Eventually consistent（最终一致性）: 系统中的所有数据副本经过一定时间后，最终能够达到一致的状态。  与数据库ACID类似，只是强度减弱了
参考：CAP 定理的含义
关于可靠性、可用性、稳定性   可靠性Reliability：不出事故，故障率低，关注的是系统无故障地持续运行的概率，比如
  MTBF（Mean Time Between Failure）：即平均无故障时间，是指从新的产品在规定的工作环境条件下开始工作到出现第一个故障的时间的平均值。MTBF越长表示可靠性越高，正确工作能力越强 。
  MTTR（Mean Time To Repair）：即平均修复时间，是指可修复产品的平均修复时间，就是从出现故障到修复中间的这段时间。MTTR越短表示易恢复性越好。
  MTTF（Mean Time To Failure）：即平均失效时间。系统平均能够正常运行多长时间，才发生一次故障。系统的可靠性越高，平均无故障时间越长。
  与可用性的关系：Availability = UpTime/(UpTime+DownTime) = MTBF / (MTBF + MTTR)</description>
    </item>
    
    <item>
      <title>微服务</title>
      <link>http://nixum.cc/p/%E5%BE%AE%E6%9C%8D%E5%8A%A1/</link>
      <pubDate>Wed, 20 Oct 2021 00:00:00 +0000</pubDate>
      
      <guid>http://nixum.cc/p/%E5%BE%AE%E6%9C%8D%E5%8A%A1/</guid>
      <description>[TOC]
一些概念理解   微服务：http://dockone.io/article/3687
  中间件（Middleware）：是处于操作系统和应用程序之间的软件，用来屏蔽底层的技术细节，以自身的复杂性换来了应用程序开发的简单。广义中间件的定义是非常广泛的，比如消息、注册配置中心、网关、数据库访问、集成平台等等，都属于中间件的范畴。
  云原生：应用程序从设计之初即考虑到云的环境，原生为云而设计，在云上以最佳状态运行，充分利用和发挥云平台的弹性和分布式优势。代表技术包括容器、服务网格、微服务、不可变基础设施和声明式API（如K8s），组合起来就算服务容器化，整体使用微服务架构，应用支持容器编排调度。
云原生的本质其实是基础设施与业务的解耦，以及基础设施自身的标准化。
  IaaS：基础结构即服务，基础设施，如AWS的EC2、S3等，只提供比较原始的硬件功能，用户不用买服务器，自己去构建网络，防火墙、硬盘存储等基础设施，即提供基础环境配备。剩下的由用户自己完成。
  PaaS：平台即服务，中间件、解决方案、工具和服务的集合，如AWS的DocDB、Redis、SQS、SNS等设施，让用户更专注自己业务逻辑的开发，对于使用的工具，拿来即用。
  FaaS：功能即服务，service less，如AWS的lambda，用户只需要写对应的业务方法就能提供对应的服务，其他都不用管
  SaaS：软件即服务，应用层面了，比如Shopify、moka，提供某一业务领域的解决方案，直接注册使用即可
  DevOps：一种模式，与敏捷挂钩，集文化理念、实践和工具于一身，快速迭代和部署，提供组织快速交付应用的能力。自动化部署、自动化运维，适合敏捷开发和快速迭代，解决传统开发和运维相互独立，沟通频繁，效率低等问题
  限流 下面的方案都是单机版本的，在分布式环境下可以把限流的实例放到Redis里，或者直接使用Lua脚本实现，保证并发安全。
固定窗口 规定单位时间内可访问的次数，比如规定接口一分钟内只能访问10次，以第一次请求为起始，计数1，一分钟内计数超过10后，后续的请求直接拒绝，只能等到这一分钟结束后，重置计数，重新开始计数。
但是这样有个问题，如果在大部分请求集中在第一个窗口的后10s内，和第二个窗口的前10s内，虽然他们都符合限流策略，但是在临界的20s内，请求还是有可能压垮系统。
算法Demo：
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47  type fixWinLimiter struct { lock *sync.</description>
    </item>
    
    <item>
      <title>操作系统</title>
      <link>http://nixum.cc/p/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/</link>
      <pubDate>Mon, 09 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>http://nixum.cc/p/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/</guid>
      <description>[TOC]
内核 PC机启动流程 以Ubuntu Linux + GRUB引导程序为例：
PC机加电后，加载BIOS固件， 触发PC机BIOS固件发送指令 检测和初始化CPU、内存及主板平台，加载引导设备(比如硬盘)中的第一个扇区数据到0x7c00地址开始的内存空间，再接着跳转到0x7c00处执行指令，加载GRUB引导程序，加载硬盘分区中的OS文件，启动操作系统。
内核结构分类 内核：计算机资源的管理者。计算资源分为硬件资源和软件资源
  硬件资源：CPU、内存、硬盘、网卡、显卡、IO设备、总线，他们之间通过总线进行联系；
  软件资源：对上述各种硬件资源的管理程序、设备的驱动程序
  宏内核结构 - 类似单体服务 将上述所有软件资源进行整合，链接在一起，形成一个大的可执行程序，控制所有硬件资源。这个大程序会在处理器的特权模式下运行，对外提供系统调用函数，供其他程序、进程调用。
当应用层有程序要调用进行内存分配时，就会调用宏内核进行内存分配
 应用程序调用内核内存分配API函数 处理器切换到特权模式，开始运行内核代码 内核的内存管理代码按照特定的算法，分配内存 内存分配函数把分配的内存块的首地址返回给应用程序 应用程序接收到返回后，处理器开始运行用户模式下的应用程序，应用程序使用得到的内存首地址，开始使用这块内存  优点：由于所有硬件管理程序都整合在一起，相互调用时性能极高
缺点：所有硬件管理程序都整合在一起，没有模块化，扩展性差，移植性差，牵一发而动全身，每次修改都需要重新安装，其中一个模块有问题就会影响其他模块。
Linux就属于宏内核
 Linux 的基本思想是一切都是文件：每个文件都有确定的用途，包括用户数据、命令、配置参数、硬件设备等对于操作系统内核而言，都被视为各种类型的文件。Linux 支持多用户，各个用户对于自己的文件有自己特殊的权利，保证了各用户之间互不影响。多任务则是现代操作系统最重要的一个特点，Linux 可以使多个程序同时并独立地运行。
 
Linux使用宏内核架构，主要分为上述五大模块，模块间的通信通过函数调用，函数间的调用没有层次关系，所以函数的调用路径纵横交错，如果有函数出问题，那就会影响到调用它的模块，存在安全隐患，但优点是存内核调用，性能极高
Linux高清全结构图：https://makelinux.github.io/kernel/map/
 微内核结构 - 类似微服务 内核仅处理进程调度、中断、内存空间映射、进程间通信等，控制硬件资源的软件资源，转成一个个服务进程，比如进程管理、内存管理、设备管理、文件管理等，和用户进程一样，只是它们提供了宏内核的那些功能。
微内核内，进程间通过消息进行通信，应用程序每次要申请资源都需要发送消息到微内核，微内核再把这条消息转发给相关服务进程，直到完成这次调用。
当应用层有程序要调用进行内存分配时
 应用程序发送内存分配的消息（发送消息这个函数由微内核提供） 处理器切换到特权模式，执行内核代码 微内核让当前进程停止运行，并根据消息包中的数据，推送给对应的消息接收者，比如这里是内存管理服务进程。 内存管理服务进程收到消息，分配一块内存 内存管理服务进程，处理完成后，通过消息的形式返回分配内存块的地址给内核，然后继续等待下一条消息。 微内核把包含内存地址的消息返回发送给内存分配消息的应用程序 处理器开始运行用户模式下的应用程序，应用程序收到这条消息，得到内存首地址，开始使用这块内存。  优点：系统结构清晰，移植性、伸缩性、扩展性强，微内核代码少，容易替换，各种系统服务进程可随时替换
缺点：进程间消息依赖微内核进行消息传递，会频繁进行服务进程切换，模式切换，导致性能较差。
分离硬件的相关性 分离硬件的相关性其实就是屏蔽底层硬件操作细节，形成一个独立的软件抽象层，对外提供接口，方便应用层接入。
是内核设计的一种指导思想，所以在设计操作系统内核的时候，就可以分为
 内核接口层：向应用层提供系统接口函数； 内核功能层：系统函数的主要实现，实现进程管理、内存管理、中断管理、设备管理、驱动、文件系统等； 内核硬件层：对硬件资源的操作，比如初始化CPU、内存、中断控制、其他IO设备  混合内核 混合内核在微内核的基础上进行改进，层次分明，动态加载模块到内核，兼具宏内核和微内核的优点。</description>
    </item>
    
    <item>
      <title>理财方案收集</title>
      <link>http://nixum.cc/p/%E7%90%86%E8%B4%A2%E6%96%B9%E6%A1%88%E6%94%B6%E9%9B%86/</link>
      <pubDate>Sat, 05 Aug 2023 00:00:00 +0000</pubDate>
      
      <guid>http://nixum.cc/p/%E7%90%86%E8%B4%A2%E6%96%B9%E6%A1%88%E6%94%B6%E9%9B%86/</guid>
      <description>初期：
  理财软件：支付宝、微信、各个银行 app (如招商银行)、微众银行
  活钱理财，比如余额宝、余利宝、活期，银行app里的各自xx宝、各种货币基金、微众银行的活期、活期plus，优点是随时可以转入转出，收益率大概是3%
  定期理财，跨度在 1/3/6/12 个月
  纯债基金，会有短期波动
  指数基金、债券基金、黄金基金
 境外的指数，如美国的标普 500 、纳斯达克 100 指数、德国的 DAX 指数、越南指数 国内的指数，如中证 1000 、中证 500 、上证 50 等 黄金，黄金的 ETF 指数    </description>
    </item>
    
    <item>
      <title>JVM</title>
      <link>http://nixum.cc/p/jvm/</link>
      <pubDate>Tue, 18 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nixum.cc/p/jvm/</guid>
      <description>JVM [TOC]
JVM内存模型  JVM内存模型 
方法区也叫永久代，持久代，非堆，不算在堆里面
年轻代也叫新生代
注意区别于Java内存模型
JVM内存模型描述的是线程运行时的数据在内存的分布
Java内存模型是多线程情况下数据的分布
引用类型  强引用：通过new的方式创建，不会被轻易回收 软引用（SoftReference）：被软引用关联的对象只有在内存不够时才会被回收 弱引用（WeakReference）：被弱引用关联的对象一定会被回收，只能存活至下次垃圾回收发生之前 虚引用（PhantomReference）：比如将对象引用设置为null，该引用指向的对象就会被回收，相当于告知JVM可以回收该对象  软引用、弱引用、虚引用均可以搭配引用队列使用，且虚引用必须搭配引用队列使用。使用引用队列时，这些引用对象被垃圾收集器回收之后会进入引用队列，等待二次回收。引用队列一般用于与GC交互的场景，比如，垃圾回收时进行通知。
可达性分析 以 GC Roots 为起始点进行搜索，可达的对象都是存活的，不可达的对象可被回收，不可达指的是游离在GC Root外的对象。
GC Roots包括：
  java虚拟机栈中引用的对象
方法执行时，JVM会创建一个相应的栈帧进入java虚拟机栈，栈帧中包括操作数栈、局部变量表、运行时常量池的引用、方法内部产生的对象的引用，当方法执行结束后，栈帧出栈，方法内部产生的对象的引用就不存在了，此时这些对象就是不可达对象，因为无法从GC Roots找到，这些对象将在下次GC时回收。
比如，方法内部创建一个对象A，并持有另一个对象B，对象B引用也同时被其他线程持有，然后在方法里设置对象A=null或者方法结束后，个人认为对象A会被回收，对象B不会被回收，如果是方法外有一个对象C引用了对象A，设置对象A=null或方法结束后，对象A不会被回收
  方法区中类静态属性引用的对象、常量引用的对象
静态属性或者静态变量，是class的属性，不属于任何实例，该属性会作为GC Roots，只要该class存在，该引用指向的对象也会一直存在，只有该class被卸载时，才会被回收。对于常量池里的字面量，当没有其他地方引用这个字面量时，也会被清除。
  本地方法栈中Native方法引用的对象
这部分属于其他语言写的方法所使用到的对象，道理跟上面是java虚拟机栈是类似的
  垃圾回收算法 引用计数法 为对象添加一个引用计数器，当对象增加一个引用时，计数器加 1，引用失效时，计数器减 1。引用计数为 0 的对象可被回收。
比较轻便，效率较高，不需要STW，可以很快进行回收，但维护引用计数也有一定的成本
但有可能出现循环引用，JVM没有使用该判断算法，可能因为编译的时候并不会检测对象是否存在循环引用？go的话会在编译期检测是否存在循环引用，但是它垃圾回收使用三色标记法，本质是标记清除
复制 标记-清理 标记 - 整理 三色标记   把所有对象放到白色的集合中 从根节点开始遍历对象，遍历到的白色对象从白色集合中放到灰色集合中 遍历灰色集合对象，把灰色对象引用的白色集合的对象放入到灰色集合中，同时把遍历过的灰色集合中的对象放到黑色集合中 循环步骤3，直到灰色集合中没有对象 步骤4结束后，白色集合中的对象为不可达对象，进行回收   参考：深入理解Go-垃圾回收机制
垃圾收集器 CMS 执行过程   初始标记(STW initial mark)：这个过程从垃圾回收的&amp;quot;根对象&amp;quot;开始，只扫描到能够和&amp;quot;根对象&amp;quot;直接关联的对象，并作标记。所以这个过程虽然暂停了整个JVM，但是很快就完成了。 并发标记(Concurrent marking)：这个阶段紧随初始标记阶段，在初始标记的基础上继续向下追溯标记。并发标记阶段，应用程序的线程和并发标记的线程并发执行，所以用户不会感受到停顿。 并发预清理(Concurrent precleaning)：并发预清理阶段仍然是并发的。在这个阶段，虚拟机查找在执行并发标记阶段新进入老年代的对象(可能会有一些对象从新生代晋升到老年代， 或者有一些对象被分配到老年代)。通过重新扫描，减少下一个阶段&amp;quot;重新标记&amp;quot;的工作，因为下一个阶段会Stop The World。 重新标记(STW remark)：这个阶段会暂停虚拟机，收集器线程扫描在CMS堆中剩余的对象。扫描从&amp;quot;跟对象&amp;quot;开始向下追溯，并处理对象关联。 并发清理(Concurrent sweeping)：清理垃圾对象，这个阶段收集器线程和应用程序线程并发执行。 并发重置(Concurrent reset)：这个阶段，重置CMS收集器的数据结构状态，等待下一次垃圾回收。   G1 执行过程   标记阶段：首先是初始标记(Initial-Mark),这个阶段也是停顿的(stop-the-word)，并且会稍带触发一次yong GC。 并发标记：这个过程在整个堆中进行，并且和应用程序并发运行。并发标记过程可能被yong GC中断。在并发标记阶段，如果发现区域对象中的所有对象都是垃圾，那个这个区域会被立即回收(图中打X)。同时，并发标记过程中，每个区域的对象活性(区域中存活对象的比例)被计算。 再标记：这个阶段是用来补充收集并发标记阶段产新的新垃圾。与之不同的是，G1中采用了更快的算法:SATB。 清理阶段：选择活性低的区域(同时考虑停顿时间)，等待下次yong GC一起收集，对应GC log: [GC pause (mixed)]，这个过程也会有停顿(STW)。 回收/完成：新的yong GC清理被计算好的区域。但是有一些区域还是可能存在垃圾对象，可能是这些区域中对象活性较高，回收不划算，也肯能是为了迎合用户设置的时间，不得不舍弃一些区域的收集。   内存分配和回收策略  1.</description>
    </item>
    
    <item>
      <title>RPC与异步设计</title>
      <link>http://nixum.cc/p/rpc%E4%B8%8E%E5%BC%82%E6%AD%A5%E8%AE%BE%E8%AE%A1/</link>
      <pubDate>Wed, 09 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>http://nixum.cc/p/rpc%E4%B8%8E%E5%BC%82%E6%AD%A5%E8%AE%BE%E8%AE%A1/</guid>
      <description>[TOC]
RPC  
一个RPC框架的基本实现，高性能网络传输、序列化和反序列化、服务注册和发现，如果是实现客户端级别的服务注册和发现，还可以在SDK中提供容错、负载均衡、熔断、降级等功能。
客户端发起RPC调用，实际上是调用该RPC方法的桩，它和服务端提供的RPC方法有相同的方法签名，或者说实现了相同的接口，只是这个桩在客户端承担的是请求转发的功能，向客户端屏蔽调用细节（比如向发现与注册中心查询要请求的服务方的url），使其像在使用本地方法一样；服务端在收到请求后，由其RPC框架解析出服务名和请求参数，调用在RPC框架中注册的该接口的真正实现者，最后将结果返回给客户端。
一个简单的RPC实现可以由三部分组成：规定远程的接口和其实现，服务端提供接口注册和IO连接，客户端IO连接和接口代理
  首先是定义要提供的远程接口和其实现类
  服务端使用线程池处理IO，实现多路复用，使用socket去循环accept()，每个请求建立一个线程
线程里注册远程接口实例，使用InputStream接收客户端发送的参数，如接口的字节文件，判断是哪个接口，哪个方法，什么参数；接收后反射调用接口方法，将结果通过OutputStream发送回客户端
客户端在发送参数可以做一个封装，加入id，服务端处理得到结果后也加入此id，返回回去，表示此次调用完成
  客户端使用接口，动态代理的方式调用方法，在动态代理的实现里使用IO连接服务端，将远程接口字节码、方法参数这些东西做一个封装发送给服务端，等待返回结果，IO接收是阻塞的
  参考【Java】java实现的远程调用例子 rpc原理
RPC原理及RPC实例分析
异步通信 优点：解耦，减少服务间的依赖，获得更大的吞吐量，削峰，把抖动的吞吐量变得均匀。
缺点：业务处理变得复杂，比如引入新的中间件，意味着要维护多一套东西，有时可能还得保证消息顺序，失败重传，幂等等处理，比较麻烦；异步也导致了debug的时候比较麻烦；
定时轮询 发送方请求接收方进行业务处理，接收方先直接返回，之后接收方在自己处理，最后将结果保存起来，发送方定时轮询接收方，获取处理结果。
回调 发送方请求接收方进行业务处理时，带上发送方结果回调的url，接收方接收到请求后先立刻返回，之后接收方在自己处理，当处理结果出来时，调用发送方带过来的回调url，将处理结果发送给发送方。
同理在于服务内部的异步回调，也是如此，只是把url换成了callback方法，比如Java中的Future类+Callable类。
发布订阅 主要靠消息队列实现，不过比较适合发送方不太care处理结果的，如果care处理结果，可以再通过一条队列将结果传递下去，执行后面的处理。
事件驱动 + 状态机 可以依靠消息队列，本质还是发布订阅那一套，只是将触发的条件换成事件，消费者根据不同的事件触发不同的逻辑，然后再通过状态机保证处理事件顺序。
比较常见的场景是电商业务中围绕订单服务的一系列业务处理，比如订单创建完成后，订单服务发出订单创建的事件，对应库存服务，收到该事件，就会进行锁库操作等
事件驱动模型 实际上是使用了观察者模式和状态模式来实现的，比较直观的例子就是android的EventBus，chrome的V8引擎都有用到此模型，这里仅总结并进行简单介绍
 
这里的demo是项目中使用到的组件的一个简化，真实的组件要比这个复杂的多，这里只简单罗列出基本的原理和优缺点。
原理：
 事件驱动-状态机的异步模型，本质上是底层controller维护一个阻塞队列，将外部请求转化为事件，通过事件在内部传递。 controller接收到请求，从对象复用池中获取一个上下文context并init，然后将事件交由context处理。context内有一套状态的扭转的控制流程，在不同的状态接收事件对业务逻辑进行处理，最后将处理结果交由注册的回调函数异步或者同步返回。 每一个状态在处理完当前逻辑操作后将发送事件给阻塞队列，并扭转为下一个状态，等待下一个事件的到来。 由于controller是单线程的，各个状态在处理的时候要求速率尽可能的快，以至于不会阻塞主线程，因此在controller内部还维护了一个延迟队列，用来接收延迟事件，状态通常在进行业务处理前会起一个定时器，如果超时将发送延迟事件给到延迟队列，来避免当前操作过长导致阻塞主线程，定时器由下一个状态来取消。 一般会为每个请求分配id，每个id对应一个上下文context，上下文一般使用id + Map来实现同一个请求下的上下文切换、保存和恢复，使用对象复用池来避免上下文对象频繁初始化 这套模型一般应用在中间件的设计上，当然也可以抽成通用框架，在写的时候就会发现，其实变化最多的是状态流程那一块，所以完全可以把这块抽出来 + netty进行网络通信就能搭出一套web框架出来了  优点：
  是一个单线程的模型，本身就是线程安全的。
  理论上一套业务逻辑拆分成小逻辑，交由不同的状态操作，各个状态的操作时间要求尽可能的短，不然会阻塞主线程
  各个状态在进行逻辑操作时，如果处理的时间过长，一般会使用线程池+回调+事件的方式处理
  状态机模式对应业务逻辑流程有比较强的控制，各个状态对应不同的职责
  对CPU的利用率比较高，吞吐量比较高，因为可以一次处理多种业务请求，每个业务请求都能进行拆分进行异步处理，速率比较快，因此性能会比常用的Spring全家桶好很多吧，至少在项目使用中的感受是这样</description>
    </item>
    
    <item>
      <title>Java并发</title>
      <link>http://nixum.cc/p/java%E5%B9%B6%E5%8F%91/</link>
      <pubDate>Sat, 02 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nixum.cc/p/java%E5%B9%B6%E5%8F%91/</guid>
      <description>[TOC]
Java线程的状态 1.状态转换  线程状态转换 
“阻塞”与“等待”的区别： “阻塞”状态是等待着获取到一个排他锁，进入“阻塞”状态都是被动的，离开“阻塞”状态是因为其它线程释放了锁，不阻塞了； “等待”状态是在等待一段时间 或者 唤醒动作的发生，进入“等待”状态是主动的
2. 状态  New（新建）：通过new创建一个新线程，但还没运行，还有一些其他基础工作要做 Runnable（可运行，就绪）：线程调用start方法，可能处于正在运行也可能处于没有运行，取决于操作系统提供的运行时间 Running（运行） Blocked（阻塞）：线程已经被挂起，等待锁的释放，直到另一个线程走完临界区或发生了相应锁对象wait()操作后，它才有机会去争夺进入临界区的权利  等待阻塞：运行的线程执行wait()方法，JVM会把该线程放入等待池中。 同步阻塞：运行的线程在获取对象的同步锁时，若该同步锁被别的线程占用，则JVM会把该线程放入锁池中。 其他阻塞：运行的线程执行sleep()或join()方法，或者发出了I/O请求时，JVM会把该线程置为阻塞状态。当sleep()状态超时、join()等待线程终止或者超时、或者I/O处理完毕时，线程重新转入就绪状态。   Waiting（无限期等待）： 处于此状态的线程会等待另外一个线程，不会被分配CPU执行时间，直到被其他线程唤醒  没有设置timeout参数的Object.wait() 没有设置timeout参数的Thread.join() LockSupport.park() 以上方法会使线程进入无限等待状态   Timed_waiting（限期等待）：不会被分配CPU执行时间，不过无需等待被其它线程显示的唤醒  Thread.sleep()方法 设置了timeout参数的Object.wait()方法 设置了timeout参数的Thread.join()方法 LockSupport.parkNanos()方法 LockSupport.parkUntil()方法   TERMINATED（结束，死亡）：已终止线程的线程状态，线程已经结束执行，run()方法走完了，线程就处于这种状态或者出现没有捕获异常终止run方法意外死亡  死锁 死锁产生的条件  互斥条件：一个资源每次只能被一个线程使用； 请求与保持条件：一个线程因请求资源而阻塞时，对已获得的资源保持不放； 不剥夺条件：进程已经获得的资源，在未使用完之前，不能强行剥夺； 循环等待条件：若干线程之间形成一种头尾相接的循环等待资源关系。  避免死锁 一般场景发生在共享资源的使用上：
 线程1对资源A加锁后，进行业务操作，线程2对资源B加锁后进行业务操作，线程1业务处理需要用到资源B，线程2业务处理需要用到资源A，此时发生死锁 线程1对资源A加锁后进行业务操作，线程2也需要用到资源A，但是线程1一直不释放锁，  互斥条件是保证线程安全的条件，因此不能破环，只能尽量破坏其他造成死锁的条件，比如提前分配各个线程所需资源；设置等待时间或者自旋次数，超时中断；分配好获得锁的顺序；避免逻辑中出现复数个线程相互持有对方线程所需的独占锁的情况；
比如:
 在合适的场景使用合适的锁类型，是否允许锁可重入的，共享还是排他 避免多个线程操作多个共享资源，注意锁的申请顺序，比如给资源设置序号，顺序取放 获取锁时设置超时时间 减少共享资源的使用，使用ThreadLocal，消息队列，共享资源在方法内复制(set回去的时候cas)，或者设计一种模式对共享资源的访问 jstack检查线程与状态  死锁检测工具 Jconsole, Jstack, visualVM</description>
    </item>
    
    <item>
      <title>Java IO</title>
      <link>http://nixum.cc/p/java-io/</link>
      <pubDate>Tue, 22 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>http://nixum.cc/p/java-io/</guid>
      <description>[TOC]
BIO 特点
 BIO是同步阻塞的，以流的形式处理，基于字节流和字符流 每个请求都需要创建独立的线程，处理Read和Write 并发数较大时，就算是使用了线程池，也需要创建大量的线程来处理 连接建立后，如果处理线程被读操作阻塞了，那就阻塞了，只能等到读完才能进行其他操作  以基于TCP协议的Socket，编写服务端Demo
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55  package com.nixum.bio; import java.io.InputStream; import java.</description>
    </item>
    
    <item>
      <title>Java List Map</title>
      <link>http://nixum.cc/p/java-list-map/</link>
      <pubDate>Mon, 18 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nixum.cc/p/java-list-map/</guid>
      <description>[TOC]
以下笔记如没指定版本，都是基于JDK1.8
Collection  javaCollection类图简版 
Set HashSet 1.基本   底层是HashMap，因此初始容量，默认负载因子、扩容倍数这些都和HashMap一样
  由于HashSet只需要key，因此value统一使用静态不可变的Object对象来装，即所有key共享这一个对象
  1 2  private transient HashMap&amp;lt;E,Object&amp;gt; map; private static final Object PRESENT = new Object();    HashSet允许存入null 不是线程安全的 不保证插入元素的顺序  List ArrayList 1.基本   底层：Object数组
  默认大小：10 （调用空参构造方法时）
最大是Integer.MAX_VALUE - 8（2^31 - 1，一些虚拟器需要在数组前加个头标签，所以减去 8 ）
调用此构造方法时，
1  public ArrayList(Collection&amp;lt;? extends E&amp;gt; c)   其中要注意的是，里面有这样一句话
1 2 3  // c.</description>
    </item>
    
    <item>
      <title>Spring和SpringBoot</title>
      <link>http://nixum.cc/p/spring%E5%92%8Cspringboot/</link>
      <pubDate>Wed, 17 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nixum.cc/p/spring%E5%92%8Cspringboot/</guid>
      <description>[TOC]
SpringBoot Spring 和 Spring Boot区别 Spring Boot实现了自动配置，降低了项目搭建的复杂度。它主要是为了解决使用Spring框架需要进行大量的配置太麻烦的问题，所以它并不是用来替代Spring的解决方案，而是和Spring框架紧密结合用于提升Spring开发者体验的工具。同时它集成了大量常用的第三方库配置(例如Jackson, JDBC, Mongo, Redis, Mail等等)，做到零配置即用。内置Tomcat作为Web服务器，不像之前还要把服务部署到Tomcat在进行启动。
SpringBoot整个启动流程  构建SpringApplication对象，执行其run方法 加载properties/yaml等配置文件 创建ApplicationContext（也可以称为Bean、IOC容器） 将扫描到的Bean或者xml中的bean，先解析成BeanDefinition，注册到ApplicationContext中的BeanFactory中（即自动配置过程，也是IOC容器的refresh方法执行过程） 实例化Bean，进行依赖注入，（AOP也是在此处实现，创建代理实例加入IOC容器）   SpringBoot启动流程 
参考SpringBoot启动流程解析
SpringBoot启动流程
SpringBoot自动配置流程 自动配置流程只是SpringBoot启动中的一个环节，该环节只是在告诉Spring要在哪里找到Bean的声明。
启动类main方法为入口，main方法所在的类会被**@SpringBootApplication**修饰， 通过main方法里执行**SpringApplication.run(Application.class, args)**进行启动，Spring启动时会解析出@SpringBootApplication注解，进行Bean的加载和注入。
  @SpringBootApplication里包含了
  @SpringBootConfiguration：作用类似于**@Configuration**，JavaConfig配置类，相当一个xml文件，配合@Bean注解让IOC容器管理声明的Bean
  @ComponentScan：配上包路径，用于扫描指定包及其子包下所有类，如扫描@Component、@Server、@Controller等，并注入到IOC容器中
  @EnableAutoConfiguration：自动配置的核心注解，主要用于找出所有自动配置类。该注解会使用**@Import(EnableAutoConfigurationImportSelector.class**)帮助SpringBoot应用将所有符合条件的@Configuration配置都加载到当前SpringBoot创建并使用的IoC容器。
    EnableAutoConfigurationImportSelector类里有个SpringFactoriesLoader工厂加载器，通过里面的loadFactoryNames方法，传入工厂类名称和对应的类加载器，加载该类加载器搜索路径下的指定文件spring.factories文件，传入的工厂类为接口，而文件中对应的类则是接口的实现类，或最终作为实现类，得到这些类名集合后，通过反射获取这些类的类对象、构造方法，最终生成实例。
因此只要在maven中加入了所需依赖，根据spring.factories文件里的key-value，能够在类路径下找到对应的class文件，就会触发自动配置
  自定义starter 实际上就是编写自动配置类，会使用到一系列配置注解，如@Configuration、@EnableConfigurationProperties、@Component、@Bean、@ConditionOnXX、@AutoConfigureOrder等，让IOC容器加载我们自定义的Bean进去；
另外就是必须在META-INF文件夹下创建spring.factories，告知Spring在哪找到配置类。
org.springframework.boot.autoconfigure.EnableAutoConfiguration=[自定义配置类的全限定名称] 自定义Starter可以理解为一个Jar包，该Jar包在Maven或Gradle注册后，服务启动时，IOC容器会去自动加载。
自定义Starter内也可以使用配置文件，设定默认配置的key-value，当本项目里有配置的key与starter里定义的配置key重复时可以被替换
ContextLoaderListener 【Spring】浅谈ContextLoaderListener及其上下文与DispatcherServlet的区别
 作为Spring启动入口 实现了ServletContextListener 接口，监听ServletContext，如果 ServletContext 发生变化（如服务器启动时ServletContext 被创建，服务器关闭时 ServletContext 将要被销毁）时，执行监听器里的方法 为IOC容器提供环境，扫描包，将带有注解的Bean加入到容器用于依赖注入，或者加载xml文件，将xml注册的bean加入容器用于依赖注入  常用注解 @Controller与@RestController  @Controller 默认是返回视图，即方法的return返回的是视图层的路径，只有+@ResponseBody才会返回Json格式的数据 @RestController实际上是@Controller + @ResponseBody组合，默认返回json格式的数据  @Autowired与@Resource   @Autowired 注解，修饰类成员变量、方法及构造方法，完成自动装配的工作，默认按 byType 自动注入。只有一个required属性，默认是true，表示必须注入，不能为null</description>
    </item>
    
    <item>
      <title>SpringMVC</title>
      <link>http://nixum.cc/p/springmvc/</link>
      <pubDate>Fri, 15 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nixum.cc/p/springmvc/</guid>
      <description>SpringMVC工作原理 SpringMVC工作原理详解
流程图看链接里的即可
简单来说各个组件的作用
 前端控制器DispatcherServlet：请求的入口，可以看成是中央处理器、转发器，负责调度其他组件，接收请求，完成响应 处理器映射器HandlerMapping：根据请求的url查找Handler，找到url对应的controller类，返回一条执行链，其中就包含拦截器和处理器（具体的controller类）；有配置文件方式，实现接口方式，注解方式等方式实现映射 处理器适配器HandlerAdapter：HandlerMapping找到对应的controller类后，再根据url找到对应的执行方法 处理器Handler：具体的处理方法，也就是我们所写具体的Controller类 视图解析器View resolver：根据逻辑View名称，找到对应的View，根据处理器返回的ModelAndView，将数据渲染到View上 视图View：例如jsp，freemarker之类的视图模板  拦截器在什么时候执行？
拦截器，是属于HandlerMapping级别的，可以有多个HandlerMapping ，每个HandlerMapping可以有自己的拦截器，拦截器可以设置优先级。一个请求交给一个HandlerMapping时，这个HandlerMapping先找有没有处理器来处理这个请求，如何找到了，就执行拦截器，执行完拦截后，交给目标处理器。如果没有找到处理器，那么这个拦截器就不会被执行。
实现HandlerInterceptor接口或者继承HandlerInterceptor，重写boolean preHandle()、void postHandle()、void afterCompletion()方法
  preHandle() 方法：该方法会在控制器方法前执行，其返回值表示是否中断后续操作。
当其返回值为true时，表示继续向下执行；当其返回值为false时，会中断后续的所有操作（包括调用下一个拦截器和控制器类中的方法执行等）。
  postHandle()方法：该方法会在控制器方法调用之后，且解析视图之前执行。可以通过此方法对请求域中的模型和视图做出进一步的修改。
  afterCompletion()方法：该方法会在整个请求完成，即视图渲染结束之后执行。可以通过此方法实现一些资源清理、记录日志信息等工作。
  Spring Security 简单工作流程
请求(包含用户名，密码之类)——&amp;gt;登陆信息封装成一个Authentication对象——&amp;gt;AuthenticationManager，调用authenticate ()方法处理——&amp;gt;该方法会将对象传递给一系列AuthenticationAdapter（一系列Filter），每一个AuthenticationAdapter会调用它们配置的UserDetailsService处理</description>
    </item>
    
    <item>
      <title>Java SE</title>
      <link>http://nixum.cc/p/java-se/</link>
      <pubDate>Mon, 18 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nixum.cc/p/java-se/</guid>
      <description>[TOC]
一、面向对象 面向对象的特征： 抽象(注意与当前目标有关的，选择一部分，暂时不用部分细节，分为过程抽象、数据抽象) 继承：联结类的层次模型、允许和鼓励类的重用，派生类可以从它的基类那里继承方法和实例变量，进行修改和新增使其更适合 封装：封装是把过程和数据包围起来，对数据的访问只能通过已定义的界面，这些对象通过一个受保护的接口访问其他对象 多态：允许不同类的对象对同一消息作出响应，包括参数化多态性和包含多态性，灵活、抽象、行为共享、代码共享，解决程序函数同名问题
二、基础类型及其包装类型    基本类型 boolean byte char short int float long double     包装类型 Boolean Byte Character Short Integer Float Long Double   位数 1 8 16 16 32 32 64 64   字节数  1 2 2 4 4 8 8      字符集
unicode是字符集，一种标准，UTF-8、UTF-16、GBK之类的是编码方式，是字符集的具体实现
UTF-16：定长,固定2字节， UTF-8：变长,中文占3字节,英文占1字节
char可以保存一个中文字符
java中采用unicode编码，无论中文、英文都是占2个字节
java虚拟机中使用UTF-16编码方式
java的字节码文件(.class)文件采用的是UTF-8编码，但是在java 运行时会使用UTF-16编码。
参考Java中的UTF-8、UTF-16编码字符所占字节数</description>
    </item>
    
    <item>
      <title>MyBatis</title>
      <link>http://nixum.cc/p/mybatis/</link>
      <pubDate>Tue, 12 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nixum.cc/p/mybatis/</guid>
      <description>[TOC]
ORM 普通JDBC使用sql的prepareStatement + sql + 占位符 + 参数的方式执行sql语句
ORM其实就是在先编写类与数据库表字段的映射，可以是xml配置，也可以是注解配置，之后再使用JDBC执行sql时，通过对类的反射获得其属性的值和对应的字段名，拼接sql+占位符+属性值，执行sql语句
MyBatis #{}和${}区别
#{}：预编译，底层是PrepareStatement ，可防止SQL注入
${}：参数替换，不能防止SQL注入
dao接口与mapper的映射  通过动态代理实现 实际上XML在定义Mapper的时候就相当于在编写dao类了，dao接口类相当于编写调用入口 XML中的配置信息会被存放在Configuration类中，SqlSessionFactoryBuilder会读取Configuration类中的信息创建SqlSessionFactory，之后由SqlSessionFactory创建sqlSession 在启动时先扫描并加载所有定义Mapper的XML，解析XML，根据XML中的namespace找到对应的接口，为这些接口生成对应的代理工厂MapperProxyFactory。 sqlSession.getMapper时，会通过传入的类/接口名（即被代理类）找到对应的MapperProxyFactory，生成代理类MapperProxy，并注入sqlSession，MapperProxy实现InvocationHandler接口进行代理，通过MapperMethod执行SQL，MapperMethod使用注入的sqlSession和解析XML中配置的SQL语句得到的参数，调用对应的executor执行SQL  缓存  一级缓存的作用域是同一个SqlSession，在同一个sqlSession中两次执行相同的sql语句，第一次执行完毕会将数据库中查询的数据写到缓存（内存），第二次会从缓存中获取数据将不再从数据库查询，从而提高查询效率。当一个sqlSession结束后该sqlSession中的一级缓存也就不存在了。Mybatis默认开启一级缓存。 二级缓存是mapper级别的缓存，多个SqlSession去操作同一个Mapper的sql语句，多个SqlSession去操作数据库得到数据会存在二级缓存区域，多个SqlSession可以共用二级缓存，二级缓存是跨SqlSession的。不同的sqlSession两次执行相同namespace下的sql语句且向sql中传递参数也相同即最终执行相同的sql语句，第一次执行完毕会将数据库中查询的数据写到缓存（内存），第二次会从缓存中获取数据将不再从数据库查询，从而提高查询效率。Mybatis默认没有开启二级缓存需要在setting全局参数中配置开启二级缓存  参考 MyBatis的通俗理解：SqlSession.getMapper()源码分析</description>
    </item>
    
    <item>
      <title>常见的业务场景解决方案整理</title>
      <link>http://nixum.cc/p/%E5%B8%B8%E8%A7%81%E7%9A%84%E4%B8%9A%E5%8A%A1%E5%9C%BA%E6%99%AF%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E6%95%B4%E7%90%86/</link>
      <pubDate>Fri, 14 May 2021 00:00:00 +0000</pubDate>
      
      <guid>http://nixum.cc/p/%E5%B8%B8%E8%A7%81%E7%9A%84%E4%B8%9A%E5%8A%A1%E5%9C%BA%E6%99%AF%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E6%95%B4%E7%90%86/</guid>
      <description>[TOC]
系统设计的思路 缓存、异步、多线程、分片、高可用、扩容、分布式集群、并发、锁不锁、对持久化、内存的要求、量大的就想办法把量过滤或者拆小，分治处理、对数据库的写操作量很大时，可以考虑时间窗口合并
API协议设计 其实分成了API和协议两部分
 一般API会符合Restful规范，由行为 + 资源组合而成； 协议一般就包含了请求/响应头和响应/请求体的内容，参数结构化，比如参数类型是Hash，就不要存成String，值是Hash的序列化后的字符串； 响应结果要统一，尽量不要因为参数的不同而返回不同类型的响应结构，个人比较喜欢的做法是，在网络层面，如果接口没有问题，统一返回HTTP code是200，响应体里分为code、msg、data来表示业务响应； 需要考虑认证和安全相关，比如是否需要签名、票据、token等 多服务之间，保证风格一致； 考虑幂等； 加入版本控制，加在URL上，或者请求头有个字段标识； 接口职责单一，一个接口只干一件事； 考虑兼容性；  解决多重if-else嵌套问题 比如有下面这种代码，优化if-else问题
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  func Handle() error { var err error if Operation1(){ if Operation2(){ if Operation3(){ if Operation4(){ // do  }else{ err = OPERATION4FAILED } }else{ err = OPERATION3FAILED } }else{ err = OPERATION2FAILED } }else{ err = OPERATION1FAILED } return err }   或者</description>
    </item>
    
    <item>
      <title>其他</title>
      <link>http://nixum.cc/p/%E5%85%B6%E4%BB%96/</link>
      <pubDate>Tue, 22 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>http://nixum.cc/p/%E5%85%B6%E4%BB%96/</guid>
      <description>[TOC]
Quartz   分为三个部分：e
 Job&amp;amp;Detial(任务)：定时任务的执行方法，与Trigger配套的 Trigger(触发器)：规定什么时候触发，与Job&amp;amp;Detail配套的 Scheduler(调度器)：单例，把Trigger丢里面由调度器调度，只需要一个Scheduler，配置不同的Trigger；可以理解成类似线程池的东西    原理：ScheduledThreadPoolExecutor线程池 + 通过Object类的wait()和notify()或者Condition类的await()\signal()进行等待和唤醒、锁保证线程安全 来进行调度
Scheduler有两个调度线程：regular Scheduler Thread（执行常规调度）和Misfire Scheduler Thread（执行错失的任务），Regular Thread 轮询所有Trigger，如果有将要触发的Trigger（用wait和notifyAll实现），则从任务线程池中获取一个空闲线程，然后执行与改Trigger关联的job；Misfire Thraed则是扫描所有的trigger，查看是否有错失的，如果有的话，根据一定的策略进行处理
  默认是并发的，即如果当前任务没有完成，会自动开一个任务执行
  注意在分布式集群的情况下，多台机子有相同的定时任务，会出错，此时通过共享数据库的方式实现
Quartz的解决方案：
quartz集群分为水平集群和垂直集群，水平集群即将定时任务节点部署在不同的服务器，其最大的问题就是时钟同步问题，若时钟不能同步，则会导致集群中各个节点状态紊乱，造成不可预知的后果；垂直集群则是集群各节点部署在同一台服务器，时钟同步自然不是问题，但存在单点故障问题，服务器宕机会严重影响服务的可用性
在各个节点会上报任务，存到数据库中，执行时会从数据库中取出触发器来执行，如果触发器的名称和执行时间相同，则只有一个节点去执行此任务。
如果此节点执行失败，则此任务则会被分派到另一节点执行，中途也会自动检查失效的定时调度，发现不成功的，其他节点立马接过来继续完成定时任务。Quartz有11个定时任务调度表
  参考
Quartz原理解密
深入解读Quartz的原理
Quartz 2.2 的实现原理和运行过程
其他定时器  Timer：这是java自带的java.util.Timer类，这个类允许你调度一个java.util.TimerTask任务。使用这种方式可以让你的程序按照某一个频度执行，但不能在指定时间运行。一般用的较少。单线程，任务一多会阻塞；一个任务出异常其他任务都受影响；受系统时间影响 ScheduledExecutorService：也jdk自带的一个类；是基于线程池设计的定时任务类,每个调度任务都会分配到线程池中的一个线程去执行,也就是说,任务是并发执行,互不影响。线程池+延时队列DelayedQueue(数组、最小堆, 最近要执行的任务放在堆顶) 实现，如果堆顶任务时间未到就阻塞（通过自旋+condition.await\signal实现）。不受系统时间影响 Spring 中的 @Schedule 注解  参考：Java 定时任务实现原理详解
Java优先级队列DelayedWorkQueue原理分析
CORS 浏览器的同源政策的同源指的是：协议相同、域名相同、端口相同，如果非同源，有三种行为会受到限制：Cookie、LocalStorage和IndexDB无法读取；DOM无法获得、AJAX请求不能发送。
前后端分离的场景下，由于浏览器的同源策略，导致浏览器内的请求不同的源的后端是会失败，常见的解决跨域方法是使用CORS，现在常见的web框架都支持CORS，开启即可。
解决跨域的方法除了CORS，还有jsonp，不过已经很少使用了，jsonp本质是利用浏览器允许加载不同源的js文件即标签等，将跨域请求标签里，返回一段可执行的js代码，其中包含了请求结果，通常是json格式，前端通过返回的js代码执行回调获取结果。
详情见 跨域资源共享 CORS 详解
对于跨域产生的问题，如CSRF跨域请求攻击的解决方案，可参考：美团:如何防止csrf
session和cookie   首先HTTP是无状态的，因此需要通过session、cookie来达到记录用户状态的目的。
  传统的session、cookie：session存用户信息，保存在服务端中，cookie里存session对应的sessionId，保存在客户端中，用于找到对应的session，每次请求都会带上该cookie来表示此用户。</description>
    </item>
    
    <item>
      <title>设计模式</title>
      <link>http://nixum.cc/p/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/</link>
      <pubDate>Tue, 22 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>http://nixum.cc/p/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/</guid>
      <description>[TOC]
只记录常用设计模式
设计模式六大原则  单一职责原则(SRP)：一个类只负责一个功能领域中的相应职责，就一个类而言，应该只有一个引起它变化的原因。 开闭原则(OCP)：一个软件实体应当对扩展开放，对修改关闭。即软件实体应尽量在不修改原有代码的情况下进行扩展。 里氏代换原则(LSP)：所有引用基类（父类）的地方必须能透明地使用其子类的对象。 依赖倒转原则(DIP)：抽象不应该依赖于细节，细节应当依赖于抽象。换言之，要针对接口编程，而不是针对实现编程。如 控制反转和依赖注入 接口隔离原则(ISP)：使用多个专门的接口，而不使用单一的总接口，即客户端不应该依赖那些它不需要的接口。 迪米特法则(LoD)：一个软件实体应当尽可能少地与其他实体发生相互作用。  常见设计模式 创建型模式是将创建和使用代码解耦
结构型模式是将不同功能代码解耦
行为型模式是将不同的行为代码解耦
创建型 单例模式 主要解决：一个全局使用的类被频繁创建和销毁，数据在应用上只保持一份，解决资源访问冲突的问题，就可以使用单例模式
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105  /** 1.</description>
    </item>
    
    <item>
      <title>UML</title>
      <link>http://nixum.cc/p/uml/</link>
      <pubDate>Thu, 11 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nixum.cc/p/uml/</guid>
      <description>[TOC]
类图 类图中的关系其实有多种版本的表示方法，这里仅总结自己常用的画法
访问作用域   + : public
  - : private
  # : protocted
  关系 1. 依赖（dependency） 依赖关系是五种关系中耦合最小的一种关系。
依赖在代码中主要体现为类A的某个成员函数的返回值、形参、局部变量或静态方法的调用，则表示类A引用了类B。
A &amp;mdash;-&amp;gt; B ： A use B （虚线+箭头）
 A use B 
2. 关联（Association） 在程序代码中，具有关联关系的类常常被声明为类的引用类型的成员变量。
因为 关联 是 依赖 的更详细说明， 关联 是专门描述成员属性的关系，所以依赖中所有涉及成员属性的地方更适合使用：关联、聚合、组合
单向关联：
A ——————&amp;gt; B ： A has B （实心线 + 箭头）
 A has B 
3. 聚合（Aggregation） 聚合是关联的一种特殊形式，暗含整体/部分关系，但是对方却不是唯一属于自己的那种关系。 用来表示集体与个体之间的关联关系，例如班级与学生之间存在聚合关系。
A &amp;lt;&amp;gt;—————— B : A是集体，B是个体 （实线 + 空心菱形）</description>
    </item>
    
    <item>
      <title>git</title>
      <link>http://nixum.cc/p/git/</link>
      <pubDate>Tue, 26 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nixum.cc/p/git/</guid>
      <description>git流程 
常用命令   git init
将一个普通文件夹变成git仓库，此时文件夹下多出.git文件夹，表示可以使用git管理，此时这个文件夹称为git工作区
或者
使用git clone url(github上的仓库链接)将仓库从github上下载下来
  当对工作区内的文件做出修改后   git add 文件名
表示将该文件的修改加入到暂存区
  git add .
(注意后面有个 . )表示将当前目录下的所有文件的修改都加入到暂存区
  git commit -m &amp;ldquo;备注信息&amp;rdquo;
表示将暂存区的修改提交到当前分支，提交之后暂存区清空
  git push -u origin master
将分支上的修改更新到github上
  撤回修改   git log 查看提交记录，获取commit id
  git reset &amp;ndash; 文件名 或者 commitId
使用当前分支上的修改覆盖暂存区，用来撤销最后一次 git add files
  git checkout &amp;ndash; 文件名</description>
    </item>
    
    <item>
      <title>README</title>
      <link>http://nixum.cc/p/readme/</link>
      <pubDate>Tue, 12 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>http://nixum.cc/p/readme/</guid>
      <description>README  \
为了更好的阅读体验，可前往 个人bolg、gitbook
目录 Java  Java SE JUC Java IO JVM  Go  Go SE Go Goroutine和GC Go Context和Channel Go Sync  框架  Spring SpringMVC MyBatis Gin  数据存储  MySQL MongoDB Redis  微服务与云原生  Kubernetes 容器 etcd 与 ZooKeeper 微服务 分布式相关 RPC与异步设计 其他  消息队列  消息队列基本原理  计算机网络  网络  操作系统  操作系统  设计模式  设计模式  工具  git UML图  </description>
    </item>
    
    <item>
      <title></title>
      <link>http://nixum.cc/p/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://nixum.cc/p/</guid>
      <description>Table of contents  公告 英语学习总结 Gin框架原理 git Go Context和Channel Go Sync包相关 Go Goroutine和GC Go Java并发 JVM Java IO Java List Map Java SE Kubernetes和Istio MongoDB MyBatis MySQL README RPC与异步设计 Redis Spring和SpringBoot SpringMVC UML etcd和ZooKeeper 常见的业务场景解决方案整理 其他 分布式相关 容器 毕业后四年工作总结 - 第一阶段结束 微服务 操作系统 消息队列 网络 设计模式 Algorithm  SwordToOffer  src  main  java  backtracking            </description>
    </item>
    
  </channel>
</rss>
